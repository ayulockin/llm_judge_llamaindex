{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We will be using our Weights and Biases documentation for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "import dotenv\n",
    "import pathlib\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: ayut.\n",
      "View Weave data at https://wandb.ai/ayut/llamaindex-weave/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.weave_client.WeaveClient at 0x17c372050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "\n",
    "weave.init(f\"{WANDB_PROJECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Simple RAG Pipeline\n",
    "\n",
    "Start of cycle\n",
    "\n",
    "- simple iteration over prompts\n",
    "- evaluation by looking at the generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 380\n",
      "\n",
      "First 5 files:\n",
      "data/wandb_docs/guides/app/features/anon.md\n",
      "data/wandb_docs/guides/app/features/custom-charts/intro.md\n",
      "data/wandb_docs/guides/app/features/custom-charts/walkthrough.md\n",
      "data/wandb_docs/guides/app/features/intro.md\n",
      "data/wandb_docs/guides/app/features/notes.md\n"
     ]
    }
   ],
   "source": [
    "docs_dir = \"data/wandb_docs\"\n",
    "\n",
    "docs_dir = pathlib.Path(docs_dir)\n",
    "docs_files = sorted(docs_dir.rglob(\"*.md\"))\n",
    "\n",
    "print(f\"Number of files: {len(docs_files)}\\n\")\n",
    "print(\"First 5 files:\\n{files}\".format(files=\"\\n\".join(map(str, docs_files[:5]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 380\n",
      "\n",
      "[Document(id_='76e3ea77-8b0d-4085-bf13-88f98348294c', embedding=None, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
      " Document(id_='9a4e995d-bb36-4250-bbef-e4ddb9ed52a4', embedding=None, metadata={'source': 'guides/app/features/custom-charts/intro.md', 'raw_tokens': 1904}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='---\\nslug: /guides/app/features/custom-charts\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Custom Charts\\n\\nUse **Custom Charts** to create charts that aren\\'t possible right now in the default UI. Log arbitrary tables of data and visualize them exactly how you want. Control details of fonts, colors, and tooltips with the power of [Vega](https://vega.github.io/vega/).\\n\\n* **What\\'s possible**: Read the[ launch announcement →](https://wandb.ai/wandb/posts/reports/Announcing-the-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n* **Code**: Try a live example in a[ hosted notebook →](https://tiny.cc/custom-charts)\\n* **Video**: Watch a quick [walkthrough video →](https://www.youtube.com/watch?v=3-N9OV6bkSM)\\n* **Example**: Quick Keras and Sklearn [demo notebook →](https://colab.research.google.com/drive/1g-gNGokPWM2Qbc8p1Gofud0\\\\_5AoZdoSD?usp=sharing)\\n\\n![Supported charts from vega.github.io/vega](/images/app_ui/supported_charts.png)\\n\\n### How it works\\n\\n1. **Log data**: From your script, log [config](../../../../guides/track/config.md) and summary data as you normally would when running with W&B. To visualize a list of multiple values logged at one specific time, use a custom`wandb.Table`\\n2. **Customize the chart**: Pull in any of this logged data with a [GraphQL](https://graphql.org) query. Visualize the results of your query with [Vega](https://vega.github.io/vega/), a powerful visualization grammar.\\n3. **Log the chart**: Call your own preset from your script with `wandb.plot_table()`.\\n\\n![](/images/app_ui/pr_roc.png)\\n\\n## Log charts from a script\\n\\n### Builtin presets\\n\\nThese presets have builtin `wandb.plot` methods that make it fast to log charts directly from your script and see the exact visualizations you\\'re looking for in the UI.\\n\\n<Tabs\\n  defaultValue=\"line-plot\"\\n  values={[\\n    {label: \\'Line plot\\', value: \\'line-plot\\'},\\n    {label: \\'Scatter plot\\', value: \\'scatter-plot\\'},\\n    {label: \\'Bar chart\\', value: \\'bar-chart\\'},\\n    {label: \\'Histogram\\', value: \\'histogram\\'},\\n    {label: \\'PR curve\\', value: \\'pr-curve\\'},\\n    {label: \\'ROC curve\\', value: \\'roc-curve\\'},\\n  ]}>\\n  <TabItem value=\"line-plot\">\\n\\n`wandb.plot.line()`\\n\\nLog a custom line plot—a list of connected and ordered points (x,y) on arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(x_values, y_values)]\\ntable = wandb.Table(data=data, columns=[\"x\", \"y\"])\\nwandb.log(\\n    {\\n        \"my_custom_plot_id\": wandb.plot.line(\\n            table, \"x\", \"y\", title=\"Custom Y vs X Line Plot\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log curves on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/line_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"scatter-plot\">\\n\\n`wandb.plot.scatter()`\\n\\nLog a custom scatter plot—a list of points (x, y) on a pair of arbitrary axes x and y.\\n\\n```python\\ndata = [[x, y] for (x, y) in zip(class_x_prediction_scores, class_y_prediction_scores)]\\ntable = wandb.Table(data=data, columns=[\"class_x\", \"class_y\"])\\nwandb.log({\"my_custom_id\": wandb.plot.scatter(table, \"class_x\", \"class_y\")})\\n```\\n\\nYou can use this to log scatter points on any two dimensions. Note that if you\\'re plotting two lists of values against each other, the number of values in the lists must match exactly (i.e. each point must have an x and a y).\\n\\n![](/images/app_ui/demo_scatter_plot.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Scatter-Plots--VmlldzoyNjk5NDQ)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"bar-chart\">\\n\\n`wandb.plot.bar()`\\n\\nLog a custom bar chart—a list of labeled values as bars—natively in a few lines:\\n\\n```python\\ndata = [[label, val] for (label, val) in zip(labels, values)]\\ntable = wandb.Table(data=data, columns=[\"label\", \"value\"])\\nwandb.log(\\n    {\\n        \"my_bar_chart_id\": wandb.plot.bar(\\n            table, \"label\", \"value\", title=\"Custom Bar Chart\"\\n        )\\n    }\\n)\\n```\\n\\nYou can use this to log arbitrary bar charts. Note that the number of labels and values in the lists must match exactly (i.e. each data point must have both).\\n\\n![](@site/static/images/app_ui/line_plot_bar_chart.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Bar-Charts--VmlldzoyNzExNzk)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n  <TabItem value=\"histogram\">\\n\\n`wandb.plot.histogram()`\\n\\nLog a custom histogram—sort list of values into bins by count/frequency of occurrence—natively in a few lines. Let\\'s say I have a list of prediction confidence scores (`scores`) and want to visualize their distribution:\\n\\n```python\\ndata = [[s] for s in scores]\\ntable = wandb.Table(data=data, columns=[\"scores\"])\\nwandb.log({\"my_histogram\": wandb.plot.histogram(table, \"scores\", title=None)})\\n```\\n\\nYou can use this to log arbitrary histograms. Note that `data` is a list of lists, intended to support a 2D array of rows and columns.\\n\\n![](/images/app_ui/demo_custom_chart_histogram.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Custom-Histograms--VmlldzoyNzE0NzM)\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n  </TabItem>\\n    <TabItem value=\"pr-curve\">\\n\\n`wandb.plot.pr_curve()`\\n\\nCreate a [Precision-Recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\\\\_recall\\\\_curve.html#sklearn.metrics.precision\\\\_recall\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.pr_curve(ground_truth, predictions, labels=None, classes_to_plot=None)\\n\\nwandb.log({\"pr\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of the labels to visualize in the plot\\n\\n![](/images/app_ui/demo_average_precision_lines.png)\\n\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-Precision-Recall-Curves--VmlldzoyNjk1ODY)\\n\\n[Run the code →](https://colab.research.google.com/drive/1mS8ogA3LcZWOXchfJoMrboW3opY1A8BY?usp=sharing)\\n\\n  </TabItem>\\n  <TabItem value=\"roc-curve\">\\n\\n`wandb.plot.roc_curve()`\\n\\nCreate an [ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc\\\\_curve.html#sklearn.metrics.roc\\\\_curve) in one line:\\n\\n```python\\nplot = wandb.plot.roc_curve(\\n    ground_truth, predictions, labels=None, classes_to_plot=None\\n)\\n\\nwandb.log({\"roc\": plot})\\n```\\n\\nYou can log this whenever your code has access to:\\n\\n* a model\\'s predicted scores (`predictions`) on a set of examples\\n* the corresponding ground truth labels (`ground_truth`) for those examples\\n* (optionally) a list of the labels/ class names (`labels=[\"cat\", \"dog\", \"bird\"...]` if label index 0 means cat, 1 = dog, 2 = bird, etc.)\\n* (optionally) a subset (still in list format) of these labels to visualize on the plot\\n\\n![](/images/app_ui/demo_custom_chart_roc_curve.png)\\n\\n[See in the app →](https://wandb.ai/wandb/plots/reports/Plot-ROC-Curves--VmlldzoyNjk3MDE)\\n\\n[Run the code →](https://colab.research.google.com/drive/1\\\\_RMppCqsA8XInV\\\\_jhJz32NCZG6Z5t1RO?usp=sharing)\\n\\n  </TabItem>\\n</Tabs>\\n\\n### Custom presets\\n\\nTweak a builtin preset, or create a new preset, then save the chart. Use the chart ID to log data to that custom preset directly from your script.\\n\\n```python\\n# Create a table with the columns to plot\\ntable = wandb.Table(data=data, columns=[\"step\", \"height\"])\\n\\n# Map from the table\\'s columns to the chart\\'s fields\\nfields = {\"x\": \"step\", \"value\": \"height\"}\\n\\n# Use the table to populate the new custom chart preset\\n# To use your own saved chart preset, change the vega_spec_name\\nmy_custom_chart = wandb.plot_table(\\n    vega_spec_name=\"carey/new_chart\",\\n    data_table=table,\\n    fields=fields,\\n)\\n```\\n\\n[Run the code →](https://tiny.cc/custom-charts)\\n\\n![](/images/app_ui/custom_presets.png)\\n\\n## Log data\\n\\nHere are the data types you can log from your script and use in a custom chart:\\n\\n* **Config**: Initial settings of your experiment (your independent variables). This includes any named fields you\\'ve logged as keys to `wandb.config` at the start of your training (e.g. `wandb.config.learning_rate = 0.0001)`\\n* **Summary**: Single values logged during training (your results or dependent variables), e.g. `wandb.log({\"val_acc\" : 0.8})`. If you write to this key multiple times during training via `wandb.log()`, the summary is set to the final value of that key.\\n* **History**: The full time series of the logged scalar is available to the query via the `history` field\\n* **summaryTable**: If you need to log a list of multiple values, use a `wandb.Table()` to save that data, then query it in your custom panel.\\n* **historyTable**: If you need to see the history data, then query `historyTable` in your custom chart panel. Each time you call `wandb.Table()` or log a custom chart, you\\'re creating a new table in history for that step.\\n\\n### How to log a custom table\\n\\nUse `wandb.Table()` to log your data as a 2D array. Typically each row of this table represents one data point, and each column denotes the relevant fields/dimensions for each data point which you\\'d like to plot. As you configure a custom panel, the whole table will be accessible via the named key passed to `wandb.log()`(\"custom\\\\_data\\\\_table\" below), and the individual fields will be accessible via the column names (\"x\", \"y\", and \"z\"). You can log tables at multiple time steps throughout your experiment. The maximum size of each table is 10,000 rows.\\n\\n[Try it in a Google Colab →](https://tiny.cc/custom-charts)\\n\\n```python\\n# Logging a custom table of data\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log(\\n    {\"custom_data_table\": wandb.Table(data=my_custom_data, columns=[\"x\", \"y\", \"z\"])}\\n)\\n```\\n\\n## Customize the chart\\n\\nAdd a new custom chart to get started, then edit the query to select data from your visible runs. The query uses [GraphQL](https://graphql.org) to fetch data from the config, summary, and history fields in your runs.\\n\\n![Add a new custom chart, then edit the query](/images/app_ui/customize_chart.gif)\\n\\n### Custom visualizations\\n\\nSelect a **Chart** in the upper right corner to start with a default preset. Next, pick **Chart fields** to map the data you\\'re pulling in from the query to the corresponding fields in your chart. Here\\'s an example of selecting a metric to get from the query, then mapping that into the bar chart fields below.\\n\\n![Creating a custom bar chart showing accuracy across runs in a project](/images/app_ui/demo_make_a_custom_chart_bar_chart.gif)\\n\\n### How to edit Vega\\n\\nClick **Edit** at the top of the panel to go into [Vega](https://vega.github.io/vega/) edit mode. Here you can define a [Vega specification](https://vega.github.io/vega/docs/specification/) that creates an interactive chart in the UI. You can change any aspect of the chart, from the visual style (e.g. change the title, pick a different color scheme, show curves as a series of points instead of as connected lines) to the data itself (use a Vega transform to bin an array of values into a histogram, etc.). The panel preview will update interactively, so you can see the effect of your changes as you edit the Vega spec or query. The [Vega documentation and tutorials ](https://vega.github.io/vega/)are an excellent source of inspiration.\\n\\n**Field references**\\n\\nTo pull data into your chart from W&B, add template strings of the form `\"${field:<field-name>}\"` anywhere in your Vega spec. This will create a dropdown in the **Chart Fields** area on the right side, which users can use to select a query result column to map into Vega.\\n\\nTo set a default value for a field, use this syntax: `\"${field:<field-name>:<placeholder text>}\"`\\n\\n### Saving chart presets\\n\\nApply any changes to a specific visualization panel with the button at the bottom of the modal. Alternatively, you can save the Vega spec to use elsewhere in your project. To save the reusable chart definition, click **Save as** at the top of the Vega editor and give your preset a name.\\n\\n## Articles and guides\\n\\n1. [The W&B Machine Learning Visualization IDE](https://wandb.ai/wandb/posts/reports/The-W-B-Machine-Learning-Visualization-IDE--VmlldzoyNjk3Nzg)\\n2. [Visualizing NLP Attention Based Models](https://wandb.ai/kylegoyette/gradientsandtranslation2/reports/Visualizing-NLP-Attention-Based-Models-Using-Custom-Charts--VmlldzoyNjg2MjM)\\n3. [Visualizing The Effect of Attention on Gradient Flow](https://wandb.ai/kylegoyette/gradientsandtranslation/reports/Visualizing-The-Effect-of-Attention-on-Gradient-Flow-Using-Custom-Charts--VmlldzoyNjg1NDg)\\n4. [Logging arbitrary curves](https://wandb.ai/stacey/presets/reports/Logging-Arbitrary-Curves--VmlldzoyNzQyMzA)\\n\\n## Frequently asked questions\\n\\n### Coming soon\\n\\n* **Polling**: Auto-refresh of data in the chart\\n* **Sampling**: Dynamically adjust the total number of points loaded into the panel for efficiency\\n\\n### Gotchas\\n\\n* Not seeing the data you\\'re expecting in the query as you\\'re editing your chart? It might be because the column you\\'re looking for is not logged in the runs you have selected. Save your chart and go back out to the runs table, and select the runs you\\'d like to visualize with the **eye** icon.\\n\\n### How to show a \"step slider\" in a custom chart?\\n\\nThis can be enabled on the “Other settings” page of the custom chart editor. If you change your query to use a `historyTable` instead of the `summaryTable`, you\\'ll get an option to “Show step selector” in the custom chart editor. This gives you a slider that lets you select the step.\\n\\n<!-- ![Show step slider in a custom chart](/images/app_ui/step_sllider_custon_charts.mov>) -->\\n\\n### How to delete a custom chart preset?\\n\\nYou can do this by going into the custom chart editor. Then click on the currently selected chart type, this will open up a menu with all your presets. Hover the mouse on a preset you want to delete and then click on the Trash icon.\\n\\n![](/images/app_ui/delete_custome_chart_preset.gif)\\n\\n\\n### Common use cases\\n\\n* Customize bar plots with error bars\\n* Show model validation metrics which require custom x-y coordinates (like precision-recall curves)\\n* Overlay data distributions from two different models/experiments as histograms\\n* Show changes in a metric via snapshots at multiple points during training\\n* Create a unique visualization not yet available in W&B (and hopefully share it with the world)\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "documents = []\n",
    "for file in docs_files:\n",
    "    content = file.read_text()\n",
    "    documents.append(\n",
    "        Document(\n",
    "            text=content,\n",
    "            metadata = {\n",
    "                \"source\": str(file.relative_to(docs_dir)),\n",
    "                \"raw_tokens\": len(content.split()),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Number of documents: {len(documents)}\\n\")\n",
    "pprint(documents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node parsers are a simple abstraction that take a list of documents, and chunk them into Node objects, such that each node is a specific chunk of the parent document. When a document is broken into nodes, all of it's attributes are inherited to the children nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 429.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes/chunks: 1440\n",
      "\n",
      "[TextNode(id_='38ab098e-e0b5-4211-adfa-dc13d6a55673', embedding=None, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='76e3ea77-8b0d-4085-bf13-88f98348294c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, hash='2c3d7c77bbae8091e7fbf90aee7787ddeae36603e3bae1ec5933373d0a620160'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='04efbeac-55cf-42e5-8b7f-f417edfcb5ed', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='be818713d44407b6cf58555b610298971b306f85d65a46669862ac4691fef5e9')}, text='---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.', mimetype='text/plain', start_char_idx=0, end_char_idx=2103, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
      " TextNode(id_='04efbeac-55cf-42e5-8b7f-f417edfcb5ed', embedding=None, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='76e3ea77-8b0d-4085-bf13-88f98348294c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, hash='2c3d7c77bbae8091e7fbf90aee7787ddeae36603e3bae1ec5933373d0a620160'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='38ab098e-e0b5-4211-adfa-dc13d6a55673', node_type=<ObjectType.TEXT: '1'>, metadata={'source': 'guides/app/features/anon.md', 'raw_tokens': 470}, hash='31d917a9d7e57f25544b39443a334a8c48c8d0279d962314c2977e7969b7be70')}, text='If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```', mimetype='text/plain', start_char_idx=1605, end_char_idx=3000, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 128\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)\n",
    "\n",
    "print(f\"Number of nodes/chunks: {len(nodes)}\\n\")\n",
    "pprint(nodes[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embedding = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector stores accept a list of Node objects and build an index from them. By default it stores everything in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 128/128 [00:05<00:00, 23.70it/s]\n",
      "Generating embeddings: 100%|██████████| 72/72 [00:03<00:00, 22.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes[:200], # using small number for demonstration purposes\n",
    "    embed_model=embedding,\n",
    "    show_progress=True,\n",
    "    insert_batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=4096,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    llm=llm,\n",
    "    response_mode=\"compact\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"what can we log with Weights and Biases?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can log various metrics and visualizations with Weights and Biases, such as custom histograms, Precision-Recall curves, and different types of smoothing algorithms like exponential moving average, Gaussian smoothing, and running average.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You change a few things in the pipeline above, \"eye-ball\" the responses and do it till a point where you can package it in a script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better pipeline with `weave.Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 429.21it/s]\n",
      "2024/07/10 22:03:59 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720632839&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Ezffs42GyxwvGqxJ%2Bh7DEU3VoqtCe9F8%2BKELduqPaE4QSVvry9MHdZSdPSXXHAbAtzUrrw8Mq1CLLSuZLqdZOo6cpk%2FDWxJ8bFf7XKSiPKd64Mj2uvdGnTQx%2Bxsya7prelT0%2FlHbe5S37uPmaAkJj70ItoFnb%2B0xAia7inIj0gDUY7QARbaj0QGM1CoI2W4ipb%2FSPvucuVDMcph44S4Pf7HsHG9f5n%2BRl5aVOm1cOAQekoLGvIWXxd26a5YhTXZFzKWSKB%2FQoa9b%2F3c30u%2BmrlMedpkXQUNn0UBBpKRreGmKroIVNqD9Y5SdsSxC%2Byqhhybr1kmCjmphW6IDmXviZw%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    }
   ],
   "source": [
    "from rag import SimpleRAGPipeline\n",
    "\n",
    "rag_pipeline = SimpleRAGPipeline()\n",
    "rag_pipeline.build_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/33ccecf9-2bbd-465f-a9df-f07bb5167af3\n",
      "('With Weights and Biases, you can log various aspects of your machine '\n",
      " 'learning experiments. This includes training and validation metrics, system '\n",
      " 'metrics, and hyperparameters for every experiment. You can also use it for '\n",
      " 'model and dataset versioning, and project collaboration. The platform '\n",
      " 'supports tracking experiments, visualizing predictions, tuning '\n",
      " 'hyperparameters, tracking models and datasets, registering models, and '\n",
      " 'iterating on LLMs. It is compatible with popular ML frameworks and libraries '\n",
      " 'such as PyTorch, PyTorch Lightning, HuggingFace Transformers, Tensorflow, '\n",
      " 'Keras, and XGBoost.')\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline.predict(\"what can we log with Weights and Biases?\")\n",
    "pprint(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 417.12it/s]\n",
      "2024/07/10 22:08:33 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720633113&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=RublCCYhV98UESyfV6nws17bgk9i7h1%2FOlGlNiWnG0m%2FY9Hu%2FxvlvOQkFWGYFbY0k4yVSBe8vBymggGJPSNt%2Bzv91y6pp7Jy3dni8xJMf3ajSYWuqC72YZWrZKeIRYuRsEfZVaMF0UaIv18BkDdns%2FAxXZNQwLwiGUp26cho1TivotpJ6G0UGuNatPNB3QhRWMj%2B4OKOoHwijQvuEp%2Bceu70NqQmuGKM84DqGDfKGyt1K08mmy3p161jgTQo41I9WYxFSJswN%2B1T0mt%2BoiqnNYAQTx7%2BunW1cZZ1KtnedjKEoXSMQqriJ0nWKaQKDpTVxpbsfMdgfjX%2B8unVqkgdFA%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = SimpleRAGPipeline(chat_llm=\"gpt-4o\")\n",
    "rag_pipeline.build_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/547b7ca8-c897-44e7-b09e-c0316f549c38\n",
      "('With Weights and Biases (W&B), you can log a variety of elements essential '\n",
      " 'for machine learning experiment tracking and project collaboration. Here are '\n",
      " 'the key items you can log:\\n'\n",
      " '\\n'\n",
      " '1. **Training and Validation Metrics**: Using the `WandbMetricsLogger` '\n",
      " 'callback, you can log metrics such as accuracy, loss, and other custom '\n",
      " 'metrics during the training and validation phases of your machine learning '\n",
      " 'models.\\n'\n",
      " '\\n'\n",
      " '2. **System Metrics**: Alongside training and validation metrics, W&B can '\n",
      " 'also log system metrics like GPU usage, CPU usage, memory consumption, and '\n",
      " 'other hardware-related metrics to help you monitor the resource utilization '\n",
      " 'of your experiments.\\n'\n",
      " '\\n'\n",
      " '3. **Hyperparameters**: W&B allows you to track hyperparameters for every '\n",
      " 'experiment, which is crucial for reproducibility. You can log '\n",
      " 'hyperparameters using a simple Python `dict` or more advanced configuration '\n",
      " 'systems.\\n'\n",
      " '\\n'\n",
      " '4. **Model and Dataset Versioning**: W&B supports versioning of models and '\n",
      " 'datasets, enabling you to keep track of different versions and iterations of '\n",
      " 'your models and datasets throughout the development lifecycle.\\n'\n",
      " '\\n'\n",
      " '5. **Experiment Tracking**: You can log various aspects of your experiments, '\n",
      " 'including configurations, code versions, and results, to keep a '\n",
      " 'comprehensive record of your work.\\n'\n",
      " '\\n'\n",
      " '6. **Model Evaluation and Predictions**: W&B provides tools to visualize '\n",
      " 'predictions and evaluate model performance, helping you to better understand '\n",
      " 'how your models are performing on different datasets.\\n'\n",
      " '\\n'\n",
      " '7. **Hyperparameter Tuning**: W&B supports hyperparameter sweeps, allowing '\n",
      " 'you to automate the process of hyperparameter tuning and log the results for '\n",
      " 'analysis.\\n'\n",
      " '\\n'\n",
      " '8. **Project Collaboration**: W&B facilitates collaboration by allowing team '\n",
      " 'members to share experiment results, models, datasets, and other artifacts '\n",
      " 'easily.\\n'\n",
      " '\\n'\n",
      " 'By leveraging these logging capabilities, W&B helps you maintain a detailed '\n",
      " 'and organized record of your machine learning experiments, making it easier '\n",
      " 'to reproduce results, collaborate with others, and iterate on your models '\n",
      " 'effectively.')\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline.predict(\"what can we log with Weights and Biases?\")\n",
    "pprint(response[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Published to https://wandb.ai/ayut/llamaindex-weave/weave/objects/eval_data_subset/versions/HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI\n"
     ]
    }
   ],
   "source": [
    "eval_rows = []\n",
    "with open(f\"data/eval_subset.jsonl\", \"r\") as f:\n",
    "    eval_data = f.readlines()\n",
    "    for row in eval_data:\n",
    "        eval_rows.append(json.loads(row))\n",
    "\n",
    "# create a weave dataset\n",
    "eval_dataset = weave.Dataset(name=\"eval_data_subset\", rows=eval_rows)\n",
    "\n",
    "# Publish the dataset\n",
    "weave.publish(eval_dataset)\n",
    "\n",
    "# Retrieve the dataset\n",
    "eval_dataset = weave.ref('eval_data_subset').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Hey I have a question about using wandb with fastapi in a prod environment. is it recommended to initialize wandb within a specific route function, ie\\n\\n`@app.route('/')\\ndef my_function():\\n    wandb.init(...)\\n`\\nor should i initialize beforehand:\\n\\n`wandb.init(...)\\n@app.route('/')\\ndef my_function():\\n    ...`\\n\\nI'm getting a long list of log items in the console and many of them are empty.\",\n",
       " 'answer': 'When integrating `wandb` (Weights & Biases) with a FastAPI application, it\\'s important to consider the nature of your application and how you\\'re using `wandb`. FastAPI is an asynchronous web framework, and initializing `wandb` within a route function could lead to multiple initializations if the route is hit multiple times, which is not ideal.\\n\\nHere are some guidelines to help you decide where to place the `wandb.init()` call:\\n\\n1. **One-time Initialization**: If you need to track metrics across the entire application lifecycle and not just within a specific route, you should initialize `wandb` outside of the route function, preferably at the start of your application. This way, `wandb` is initialized once when your FastAPI app starts.\\n\\n2. **Per-Request Initialization**: If you need to track metrics for a specific route and each request is considered a separate experiment or run, you might initialize `wandb` within the route function. However, this is less common and could lead to a cluttered dashboard with many runs, which might be what you\\'re experiencing with the empty log items.\\n\\n3. **Background Tasks**: If you\\'re running long-running tasks or jobs that are kicked off from a FastAPI route, you might want to use FastAPI\\'s background tasks to initialize and log to `wandb`. This way, the `wandb` run is associated with the background task and not the web request itself.\\n\\nHere\\'s an example of how you might structure it for a one-time initialization:\\n\\n```python\\nimport wandb\\nfrom fastapi import FastAPI\\n\\n# Initialize wandb once when the application starts\\nwandb.init(project=\"my_project\", entity=\"my_entity\")\\n\\napp = FastAPI()\\n\\n@app.get(\"/\")\\nasync def my_function():\\n    # Log something to wandb\\n    wandb.log({\"metric\": value})\\n    return {\"Hello\": \"World\"}\\n```\\n\\nFor per-request initialization (less common):\\n\\n```python\\nfrom fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get(\"/\")\\nasync def my_function():\\n    # Initialize wandb for this specific request/run\\n    run = wandb.init(project=\"my_project\", entity=\"my_entity\", reinit=True)\\n    # Log something to wandb\\n    wandb.log({\"metric\": value})\\n    # Finish the run when done logging\\n    run.finish()\\n    return {\"Hello\": \"World\"}\\n```\\n\\nRemember to finish the run with `run.finish()` if you\\'re initializing `wandb` within a route function to ensure that resources are cleaned up properly.\\n\\nIf you\\'re seeing a lot of empty log items, it could be due to initializing `wandb` multiple times without logging any metrics or due to incorrect usage within an asynchronous environment. Make sure that you\\'re logging the relevant metrics after each initialization and that you\\'re managing the lifecycle of your `wandb` runs correctly.',\n",
       " 'context': 'Source:\\thttps://docs.wandb.ai/guides/track/tracking-faq\\n\\n`InitStartError: Error communicating with wandb process`\\n\\n\\nThis error indicates that the library is having difficulty launching the process which synchronizes data to the server.\\n\\n\\nThe following workarounds can help resolve the issue in certain environments:\\n\\n\\n\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"fork\"))\\n\\n```\\n\\n\\nFor versions prior to `0.13.0` we suggest using:\\n\\n\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"thread\"))\\n\\n```\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/track/log/logging-faqs\\n\\nWhat happens if I pass a class attribute into wandb.log()?\\n\\n\\nIt is generally not recommended to pass class attributes into `wandb.log()` as the attribute may change before the network call is made. If you are storing metrics as the attribute of a class, it is recommended to deep copy the attribute to ensure the metric logged matches the value of the attribute at the time that `wandb.log()` was called.\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/integrations/fastai/\\n\\nLog with W&B\\n\\n\\n**a)** Sign up for a free account at <https://wandb.ai/site> and then log in to your wandb account.\\n\\n\\n**b)** Install the wandb library on your machine in a Python 3 environment using `pip`\\n\\n\\n**c)** log in to the wandb library on your machine. You will find your API key here: <https://wandb.ai/authorize>.\\n\\n\\n\\n\\n```\\npip install wandb\\nwandb login\\n\\n```\\n\\n\\n\\n```\\n!pip install wandb\\n\\nimport wandb\\nwandb.login()\\n\\n```\\n\\n\\nThen add the `WandbCallback` to the `learner` or `fit` method:\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.callback.wandb import *\\n\\n# start logging a wandb run\\nwandb.init(project=\"my_project\")\\n\\n# To log only during one training phase\\nlearn.fit(..., cbs=WandbCallback())\\n\\n# To log continuously for all training phases\\nlearn = learner(..., cbs=WandbCallback())\\n\\n```\\n\\n:::info  \\n\\nIf you use version 1 of Fastai, refer to the Fastai v1 docs.  \\n\\n:::\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/integrations/fastai/\\n\\nLogging only on the main process\\n\\n\\nIn the examples above, `wandb` launches one run per process. At the end of the training, you will end up with two runs. This can sometimes be confusing, and you may want to log only on the main process. To do so, you will have to detect in which process you are manually and avoid creating runs (calling `wandb.init` in all other processes)\\n\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.vision.all import *\\nfrom fastai.distributed import *\\nfrom fastai.callback.wandb import WandbCallback\\n\\nwandb.require(experiment=\"service\")\\npath = rank0_first(lambda: untar_data(URLs.PETS) / \"images\")\\n\\n\\ndef train():\\n    cb = []\\n    dls = ImageDataLoaders.from_name_func(\\n        path,\\n        get_image_files(path),\\n        valid_pct=0.2,\\n        label_func=lambda x: x[0].isupper(),\\n        item_tfms=Resize(224),\\n    )\\n    if rank_distrib() == 0:\\n        run = wandb.init(\"fastai_ddp\", entity=\"capecape\")\\n        cb = WandbCallback()\\n    learn = vision_learner(dls, resnet34, metrics=error_rate, cbs=cb).to_fp16()\\n    with learn.distrib_ctx(sync_bn=False):\\n        learn.fit(1)\\n\\n\\nif __name__ == \"__main__\":\\n    train()\\n\\n```\\n\\nin your terminal call:\\n\\n\\n\\n```\\n$ torchrun --nproc_per_node 2 train.py\\n\\n```\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.vision.all import *\\n\\nfrom accelerate import notebook_launcher\\nfrom fastai.distributed import *\\nfrom fastai.callback.wandb import WandbCallback\\n\\nwandb.require(experiment=\"service\")\\npath = untar_data(URLs.PETS) / \"images\"\\n\\n\\ndef train():\\n    cb = []\\n    dls = ImageDataLoaders.from_name_func(\\n        path,\\n        get_image_files(path),\\n        valid_pct=0.2,\\n        label_func=lambda x: x[0].isupper(),\\n        item_tfms=Resize(224),\\n    )\\n    if rank_distrib() == 0:\\n        run = wandb.init(\"fastai_ddp\", entity=\"capecape\")\\n        cb = WandbCallback()\\n    learn = vision_learner(dls, resnet34, metrics=error_rate, cbs=cb).to_fp16()\\n    with learn.distrib_ctx(in_notebook=True, sync_bn=False):\\n        learn.fit(1)\\n\\n\\nnotebook_launcher(train, num_processes=2)\\n\\n```\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/track/tracking-faq\\n\\nHow can I use wandb with multiprocessing, e.g. distributed training?\\n\\n\\nIf your training program uses multiple processes you will need to structure your program to avoid making wandb method calls from processes where you did not run `wandb.init()`.\\\\  \\n\\n\\\\  \\n\\nThere are several approaches to managing multiprocess training:\\n\\n\\n1. Call `wandb.init` in all your processes, using the group keyword argument to define a shared group. Each process will have its own wandb run and the UI will group the training processes together.\\n2. Call `wandb.init` from just one process and pass data to be logged over multiprocessing queues.\\n\\n\\n:::info  \\n\\nCheck out the Distributed Training Guide for more detail on these two approaches, including code examples with Torch DDP.  \\n\\n:::\\n\\n---\\n\\n',\n",
       " 'correctness': 'correct',\n",
       " 'is_wandb_query': 'YES',\n",
       " 'notes': \"The answer clearly explains the recommended practices for integrating wandb with a FastAPI application, offering both one-time initialization at the application start and per-request initialization within a route function, if necessary. The answer also mentions the possible reasons for seeing many empty log items in the console, such as multiple initializations or incorrect usage within an asynchronous environment, which directly corresponds to the user's observations.\\n\"}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(eval_dataset.rows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric(s) / Scoring Function (Scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator, EvaluationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_llm = OpenAI(\"gpt-4-1106-preview\")\n",
    "evaluator = CorrectnessEvaluator(llm=judge_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Hey I have a question about using wandb with fastapi in a prod environment. is it recommended to initialize wandb within a specific route function, ie\\n\\n`@app.route('/')\\ndef my_function():\\n    wandb.init(...)\\n`\\nor should i initialize beforehand:\\n\\n`wandb.init(...)\\n@app.route('/')\\ndef my_function():\\n    ...`\\n\\nI'm getting a long list of log items in the console and many of them are empty.\",\n",
       " 'answer': 'When integrating `wandb` (Weights & Biases) with a FastAPI application, it\\'s important to consider the nature of your application and how you\\'re using `wandb`. FastAPI is an asynchronous web framework, and initializing `wandb` within a route function could lead to multiple initializations if the route is hit multiple times, which is not ideal.\\n\\nHere are some guidelines to help you decide where to place the `wandb.init()` call:\\n\\n1. **One-time Initialization**: If you need to track metrics across the entire application lifecycle and not just within a specific route, you should initialize `wandb` outside of the route function, preferably at the start of your application. This way, `wandb` is initialized once when your FastAPI app starts.\\n\\n2. **Per-Request Initialization**: If you need to track metrics for a specific route and each request is considered a separate experiment or run, you might initialize `wandb` within the route function. However, this is less common and could lead to a cluttered dashboard with many runs, which might be what you\\'re experiencing with the empty log items.\\n\\n3. **Background Tasks**: If you\\'re running long-running tasks or jobs that are kicked off from a FastAPI route, you might want to use FastAPI\\'s background tasks to initialize and log to `wandb`. This way, the `wandb` run is associated with the background task and not the web request itself.\\n\\nHere\\'s an example of how you might structure it for a one-time initialization:\\n\\n```python\\nimport wandb\\nfrom fastapi import FastAPI\\n\\n# Initialize wandb once when the application starts\\nwandb.init(project=\"my_project\", entity=\"my_entity\")\\n\\napp = FastAPI()\\n\\n@app.get(\"/\")\\nasync def my_function():\\n    # Log something to wandb\\n    wandb.log({\"metric\": value})\\n    return {\"Hello\": \"World\"}\\n```\\n\\nFor per-request initialization (less common):\\n\\n```python\\nfrom fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get(\"/\")\\nasync def my_function():\\n    # Initialize wandb for this specific request/run\\n    run = wandb.init(project=\"my_project\", entity=\"my_entity\", reinit=True)\\n    # Log something to wandb\\n    wandb.log({\"metric\": value})\\n    # Finish the run when done logging\\n    run.finish()\\n    return {\"Hello\": \"World\"}\\n```\\n\\nRemember to finish the run with `run.finish()` if you\\'re initializing `wandb` within a route function to ensure that resources are cleaned up properly.\\n\\nIf you\\'re seeing a lot of empty log items, it could be due to initializing `wandb` multiple times without logging any metrics or due to incorrect usage within an asynchronous environment. Make sure that you\\'re logging the relevant metrics after each initialization and that you\\'re managing the lifecycle of your `wandb` runs correctly.',\n",
       " 'context': 'Source:\\thttps://docs.wandb.ai/guides/track/tracking-faq\\n\\n`InitStartError: Error communicating with wandb process`\\n\\n\\nThis error indicates that the library is having difficulty launching the process which synchronizes data to the server.\\n\\n\\nThe following workarounds can help resolve the issue in certain environments:\\n\\n\\n\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"fork\"))\\n\\n```\\n\\n\\nFor versions prior to `0.13.0` we suggest using:\\n\\n\\n\\n```\\nwandb.init(settings=wandb.Settings(start_method=\"thread\"))\\n\\n```\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/track/log/logging-faqs\\n\\nWhat happens if I pass a class attribute into wandb.log()?\\n\\n\\nIt is generally not recommended to pass class attributes into `wandb.log()` as the attribute may change before the network call is made. If you are storing metrics as the attribute of a class, it is recommended to deep copy the attribute to ensure the metric logged matches the value of the attribute at the time that `wandb.log()` was called.\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/integrations/fastai/\\n\\nLog with W&B\\n\\n\\n**a)** Sign up for a free account at <https://wandb.ai/site> and then log in to your wandb account.\\n\\n\\n**b)** Install the wandb library on your machine in a Python 3 environment using `pip`\\n\\n\\n**c)** log in to the wandb library on your machine. You will find your API key here: <https://wandb.ai/authorize>.\\n\\n\\n\\n\\n```\\npip install wandb\\nwandb login\\n\\n```\\n\\n\\n\\n```\\n!pip install wandb\\n\\nimport wandb\\nwandb.login()\\n\\n```\\n\\n\\nThen add the `WandbCallback` to the `learner` or `fit` method:\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.callback.wandb import *\\n\\n# start logging a wandb run\\nwandb.init(project=\"my_project\")\\n\\n# To log only during one training phase\\nlearn.fit(..., cbs=WandbCallback())\\n\\n# To log continuously for all training phases\\nlearn = learner(..., cbs=WandbCallback())\\n\\n```\\n\\n:::info  \\n\\nIf you use version 1 of Fastai, refer to the Fastai v1 docs.  \\n\\n:::\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/integrations/fastai/\\n\\nLogging only on the main process\\n\\n\\nIn the examples above, `wandb` launches one run per process. At the end of the training, you will end up with two runs. This can sometimes be confusing, and you may want to log only on the main process. To do so, you will have to detect in which process you are manually and avoid creating runs (calling `wandb.init` in all other processes)\\n\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.vision.all import *\\nfrom fastai.distributed import *\\nfrom fastai.callback.wandb import WandbCallback\\n\\nwandb.require(experiment=\"service\")\\npath = rank0_first(lambda: untar_data(URLs.PETS) / \"images\")\\n\\n\\ndef train():\\n    cb = []\\n    dls = ImageDataLoaders.from_name_func(\\n        path,\\n        get_image_files(path),\\n        valid_pct=0.2,\\n        label_func=lambda x: x[0].isupper(),\\n        item_tfms=Resize(224),\\n    )\\n    if rank_distrib() == 0:\\n        run = wandb.init(\"fastai_ddp\", entity=\"capecape\")\\n        cb = WandbCallback()\\n    learn = vision_learner(dls, resnet34, metrics=error_rate, cbs=cb).to_fp16()\\n    with learn.distrib_ctx(sync_bn=False):\\n        learn.fit(1)\\n\\n\\nif __name__ == \"__main__\":\\n    train()\\n\\n```\\n\\nin your terminal call:\\n\\n\\n\\n```\\n$ torchrun --nproc_per_node 2 train.py\\n\\n```\\n\\n\\n\\n```\\nimport wandb\\nfrom fastai.vision.all import *\\n\\nfrom accelerate import notebook_launcher\\nfrom fastai.distributed import *\\nfrom fastai.callback.wandb import WandbCallback\\n\\nwandb.require(experiment=\"service\")\\npath = untar_data(URLs.PETS) / \"images\"\\n\\n\\ndef train():\\n    cb = []\\n    dls = ImageDataLoaders.from_name_func(\\n        path,\\n        get_image_files(path),\\n        valid_pct=0.2,\\n        label_func=lambda x: x[0].isupper(),\\n        item_tfms=Resize(224),\\n    )\\n    if rank_distrib() == 0:\\n        run = wandb.init(\"fastai_ddp\", entity=\"capecape\")\\n        cb = WandbCallback()\\n    learn = vision_learner(dls, resnet34, metrics=error_rate, cbs=cb).to_fp16()\\n    with learn.distrib_ctx(in_notebook=True, sync_bn=False):\\n        learn.fit(1)\\n\\n\\nnotebook_launcher(train, num_processes=2)\\n\\n```\\n\\n---\\n\\nSource:\\thttps://docs.wandb.ai/guides/track/tracking-faq\\n\\nHow can I use wandb with multiprocessing, e.g. distributed training?\\n\\n\\nIf your training program uses multiple processes you will need to structure your program to avoid making wandb method calls from processes where you did not run `wandb.init()`.\\\\  \\n\\n\\\\  \\n\\nThere are several approaches to managing multiprocess training:\\n\\n\\n1. Call `wandb.init` in all your processes, using the group keyword argument to define a shared group. Each process will have its own wandb run and the UI will group the training processes together.\\n2. Call `wandb.init` from just one process and pass data to be logged over multiprocessing queues.\\n\\n\\n:::info  \\n\\nCheck out the Distributed Training Guide for more detail on these two approaches, including code examples with Torch DDP.  \\n\\n:::\\n\\n---\\n\\n',\n",
       " 'correctness': 'correct',\n",
       " 'is_wandb_query': 'YES',\n",
       " 'notes': \"The answer clearly explains the recommended practices for integrating wandb with a FastAPI application, offering both one-time initialization at the application start and per-request initialization within a route function, if necessary. The answer also mentions the possible reasons for seeing many empty log items in the console, such as multiple initializations or incorrect usage within an asynchronous environment, which directly corresponds to the user's observations.\\n\"}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = dict(eval_dataset.rows[0])\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/6f22cbe6-0096-4596-a596-2b4dea9dc224\n",
      "When integrating Weights & Biases (W&B) with FastAPI in a production environment, it is generally recommended to initialize W&B before defining your route functions. This approach ensures that the W&B run is started as early as possible, capturing all relevant logs and metrics from the beginning of your application’s execution. \n",
      "\n",
      "Here’s why initializing W&B beforehand is beneficial:\n",
      "\n",
      "1. **Early Logging**: Initializing W&B early ensures that any output in your console, including error messages, are logged as part of the W&B run. This can be crucial for debugging and monitoring purposes.\n",
      "2. **Single Initialization**: By initializing W&B once at the start, you avoid multiple initializations which can lead to redundant runs and cluttered logs.\n",
      "3. **Consistency**: It provides a consistent and centralized place for configuration and initialization, making the code easier to maintain and understand.\n",
      "\n",
      "Here’s how you can structure your FastAPI application with W&B initialization:\n",
      "\n",
      "```python\n",
      "import wandb\n",
      "from fastapi import FastAPI\n",
      "\n",
      "# Initialize W&B before defining route functions\n",
      "wandb.init(project=\"my_project\", entity=\"my_entity\")\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "@app.get('/')\n",
      "def my_function():\n",
      "    # Your route logic here\n",
      "    wandb.log({\"message\": \"Hello, world!\"})\n",
      "    return {\"message\": \"Hello, world!\"}\n",
      "```\n",
      "\n",
      "By following this structure, you ensure that W&B is properly initialized and ready to log data as soon as your application starts handling requests. This approach helps in maintaining clean and efficient logging, avoiding the issue of having a long list of log items in the console, many of which might be empty due to multiple initializations.\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline.predict(row[\"question\"])\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator.evaluate(\n",
    "    query=row[\"question\"],\n",
    "    response=response[\"response\"],\n",
    "    reference=row[\"answer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contexts': None,\n",
      " 'feedback': 'The generated answer is relevant and provides a correct '\n",
      "             'explanation and guidelines for integrating Weights & Biases '\n",
      "             '(W&B) with FastAPI, which aligns well with the reference answer. '\n",
      "             'It suggests initializing W&B before defining route functions, '\n",
      "             'which is a good practice to avoid multiple initializations and '\n",
      "             'cluttered logs. The answer also includes a code example that '\n",
      "             'demonstrates the recommended practice. The explanation of the '\n",
      "             'benefits of early logging, single initialization, and '\n",
      "             'consistency adds value to the answer. However, it does not '\n",
      "             'explicitly mention the potential issues with asynchronous '\n",
      "             'environments or the use of `run.finish()` in per-request '\n",
      "             'initializations, which were points covered in the reference '\n",
      "             'answer. Despite this, the generated answer is still fully '\n",
      "             'correct within the context it addresses.',\n",
      " 'invalid_reason': None,\n",
      " 'invalid_result': False,\n",
      " 'pairwise_source': None,\n",
      " 'passing': True,\n",
      " 'query': 'Hey I have a question about using wandb with fastapi in a prod '\n",
      "          'environment. is it recommended to initialize wandb within a '\n",
      "          'specific route function, ie\\n'\n",
      "          '\\n'\n",
      "          \"`@app.route('/')\\n\"\n",
      "          'def my_function():\\n'\n",
      "          '    wandb.init(...)\\n'\n",
      "          '`\\n'\n",
      "          'or should i initialize beforehand:\\n'\n",
      "          '\\n'\n",
      "          '`wandb.init(...)\\n'\n",
      "          \"@app.route('/')\\n\"\n",
      "          'def my_function():\\n'\n",
      "          '    ...`\\n'\n",
      "          '\\n'\n",
      "          \"I'm getting a long list of log items in the console and many of \"\n",
      "          'them are empty.',\n",
      " 'response': 'When integrating Weights & Biases (W&B) with FastAPI in a '\n",
      "             'production environment, it is generally recommended to '\n",
      "             'initialize W&B before defining your route functions. This '\n",
      "             'approach ensures that the W&B run is started as early as '\n",
      "             'possible, capturing all relevant logs and metrics from the '\n",
      "             'beginning of your application’s execution. \\n'\n",
      "             '\\n'\n",
      "             'Here’s why initializing W&B beforehand is beneficial:\\n'\n",
      "             '\\n'\n",
      "             '1. **Early Logging**: Initializing W&B early ensures that any '\n",
      "             'output in your console, including error messages, are logged as '\n",
      "             'part of the W&B run. This can be crucial for debugging and '\n",
      "             'monitoring purposes.\\n'\n",
      "             '2. **Single Initialization**: By initializing W&B once at the '\n",
      "             'start, you avoid multiple initializations which can lead to '\n",
      "             'redundant runs and cluttered logs.\\n'\n",
      "             '3. **Consistency**: It provides a consistent and centralized '\n",
      "             'place for configuration and initialization, making the code '\n",
      "             'easier to maintain and understand.\\n'\n",
      "             '\\n'\n",
      "             'Here’s how you can structure your FastAPI application with W&B '\n",
      "             'initialization:\\n'\n",
      "             '\\n'\n",
      "             '```python\\n'\n",
      "             'import wandb\\n'\n",
      "             'from fastapi import FastAPI\\n'\n",
      "             '\\n'\n",
      "             '# Initialize W&B before defining route functions\\n'\n",
      "             'wandb.init(project=\"my_project\", entity=\"my_entity\")\\n'\n",
      "             '\\n'\n",
      "             'app = FastAPI()\\n'\n",
      "             '\\n'\n",
      "             \"@app.get('/')\\n\"\n",
      "             'def my_function():\\n'\n",
      "             '    # Your route logic here\\n'\n",
      "             '    wandb.log({\"message\": \"Hello, world!\"})\\n'\n",
      "             '    return {\"message\": \"Hello, world!\"}\\n'\n",
      "             '```\\n'\n",
      "             '\\n'\n",
      "             'By following this structure, you ensure that W&B is properly '\n",
      "             'initialized and ready to log data as soon as your application '\n",
      "             'starts handling requests. This approach helps in maintaining '\n",
      "             'clean and efficient logging, avoiding the issue of having a long '\n",
      "             'list of log items in the console, many of which might be empty '\n",
      "             'due to multiple initializations.',\n",
      " 'score': 4.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(result.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wandb.ai/ayut/llamaindex-weave/weave/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing `CorrectnessEvaluator` for our usecase\n",
    "\n",
    "https://github.com/run-llama/llama_index/blob/29ece9b058f6b9a1cf29bc723ed4aa3a39879ad5/llama-index-core/llama_index/core/evaluation/correctness.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = \"\"\"You are a Weight & Biases support expert tasked with evaluating the correctness of answers to questions asked by users to a a technical support chatbot.\n",
    "\n",
    "You are given the following information:\n",
    "- a user query,\n",
    "- a reference answer\n",
    "- a generated answer.\n",
    "\n",
    "Your job is to judge the relevance and correctness of the generated answer.\n",
    "Your score has to be between 1 and 3, where 1 is the worst and 3 is the best.\n",
    "\n",
    "Output your final verdict by strictly following JSON format:\n",
    "{{\n",
    "    \"reason\": <<Provide a brief explanation for your decision here>>,\n",
    "    \"score\": <<Provide a score as per the above guidelines>>,\n",
    "    \"decision\": <<Provide your final decision here, either 'correct', or 'incorrect'>>\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_TEMPLATE = \"\"\"\n",
    "## User Query\n",
    "{query}\n",
    "\n",
    "## Reference Answer\n",
    "{reference_answer}\n",
    "\n",
    "## Generated Answer\n",
    "{generated_answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "EVALUATOR_TEMPLATE = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=SYSTEM_TEMPLATE),\n",
    "        ChatMessage(role=MessageRole.USER, content=USER_TEMPLATE),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from ragas.llms.json_load import json_loader\n",
    "\n",
    "\n",
    "async def safe_parse_eval_response(eval_response, passing_decision):\n",
    "    try:\n",
    "        eval_response_dict = await json_loader.safe_load(\n",
    "            eval_response, llm=OpenAI()\n",
    "        )\n",
    "        score = eval_response_dict.get(\"score\")\n",
    "        reasoning = eval_response_dict.get(\"reason\")\n",
    "        decision = eval_response_dict.get(\"decision\") == passing_decision\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(eval_response)\n",
    "        score = 0\n",
    "        reasoning = \"Unable to parse response\"\n",
    "        decision = False\n",
    "    return decision, reasoning, score\n",
    "\n",
    "\n",
    "class WandbCorrectnessEvaluator(CorrectnessEvaluator):\n",
    "    async def aevaluate(\n",
    "        self,\n",
    "        query = None,\n",
    "        response = None,\n",
    "        contexts = None,\n",
    "        reference = None,\n",
    "        sleep_time_in_seconds: int = 0,\n",
    "        **kwargs,\n",
    "    ) -> EvaluationResult:\n",
    "        await asyncio.sleep(sleep_time_in_seconds)\n",
    "\n",
    "        if query is None or response is None or reference is None:\n",
    "            print(query, response, reference, flush=True)\n",
    "            raise ValueError(\"query, response, and reference must be provided\")\n",
    "\n",
    "        eval_response = await self._llm.apredict(\n",
    "            prompt=self._eval_template,\n",
    "            query=query,\n",
    "            generated_answer=response,\n",
    "            reference_answer=reference,\n",
    "        )\n",
    "\n",
    "        passing, reasoning, score = await safe_parse_eval_response(\n",
    "            eval_response, \"correct\"\n",
    "        )\n",
    "\n",
    "        return EvaluationResult(\n",
    "            query=query,\n",
    "            response=response,\n",
    "            passing=passing,\n",
    "            score=score,\n",
    "            feedback=reasoning,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_evaluator = WandbCorrectnessEvaluator(\n",
    "    llm=judge_llm,\n",
    "    eval_template=EVALUATOR_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = correctness_evaluator.evaluate(\n",
    "    query=row[\"question\"],\n",
    "    response=response[\"response\"],\n",
    "    reference=row[\"answer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contexts': None,\n",
      " 'feedback': 'The generated answer is relevant and correct. It provides a '\n",
      "             'clear explanation of why initializing W&B before defining route '\n",
      "             \"functions is beneficial, aligning with the reference answer's \"\n",
      "             'guidelines. It also includes an example of how to structure the '\n",
      "             'FastAPI application with W&B initialization, which is helpful '\n",
      "             'for the user.',\n",
      " 'invalid_reason': None,\n",
      " 'invalid_result': False,\n",
      " 'pairwise_source': None,\n",
      " 'passing': True,\n",
      " 'query': 'Hey I have a question about using wandb with fastapi in a prod '\n",
      "          'environment. is it recommended to initialize wandb within a '\n",
      "          'specific route function, ie\\n'\n",
      "          '\\n'\n",
      "          \"`@app.route('/')\\n\"\n",
      "          'def my_function():\\n'\n",
      "          '    wandb.init(...)\\n'\n",
      "          '`\\n'\n",
      "          'or should i initialize beforehand:\\n'\n",
      "          '\\n'\n",
      "          '`wandb.init(...)\\n'\n",
      "          \"@app.route('/')\\n\"\n",
      "          'def my_function():\\n'\n",
      "          '    ...`\\n'\n",
      "          '\\n'\n",
      "          \"I'm getting a long list of log items in the console and many of \"\n",
      "          'them are empty.',\n",
      " 'response': 'When integrating Weights & Biases (W&B) with FastAPI in a '\n",
      "             'production environment, it is generally recommended to '\n",
      "             'initialize W&B before defining your route functions. This '\n",
      "             'approach ensures that the W&B run is started as early as '\n",
      "             'possible, capturing all relevant logs and metrics from the '\n",
      "             'beginning of your application’s execution. \\n'\n",
      "             '\\n'\n",
      "             'Here’s why initializing W&B beforehand is beneficial:\\n'\n",
      "             '\\n'\n",
      "             '1. **Early Logging**: Initializing W&B early ensures that any '\n",
      "             'output in your console, including error messages, are logged as '\n",
      "             'part of the W&B run. This can be crucial for debugging and '\n",
      "             'monitoring purposes.\\n'\n",
      "             '2. **Single Initialization**: By initializing W&B once at the '\n",
      "             'start, you avoid multiple initializations which can lead to '\n",
      "             'redundant runs and cluttered logs.\\n'\n",
      "             '3. **Consistency**: It provides a consistent and centralized '\n",
      "             'place for configuration and initialization, making the code '\n",
      "             'easier to maintain and understand.\\n'\n",
      "             '\\n'\n",
      "             'Here’s how you can structure your FastAPI application with W&B '\n",
      "             'initialization:\\n'\n",
      "             '\\n'\n",
      "             '```python\\n'\n",
      "             'import wandb\\n'\n",
      "             'from fastapi import FastAPI\\n'\n",
      "             '\\n'\n",
      "             '# Initialize W&B before defining route functions\\n'\n",
      "             'wandb.init(project=\"my_project\", entity=\"my_entity\")\\n'\n",
      "             '\\n'\n",
      "             'app = FastAPI()\\n'\n",
      "             '\\n'\n",
      "             \"@app.get('/')\\n\"\n",
      "             'def my_function():\\n'\n",
      "             '    # Your route logic here\\n'\n",
      "             '    wandb.log({\"message\": \"Hello, world!\"})\\n'\n",
      "             '    return {\"message\": \"Hello, world!\"}\\n'\n",
      "             '```\\n'\n",
      "             '\\n'\n",
      "             'By following this structure, you ensure that W&B is properly '\n",
      "             'initialized and ready to log data as soon as your application '\n",
      "             'starts handling requests. This approach helps in maintaining '\n",
      "             'clean and efficient logging, avoiding the issue of having a long '\n",
      "             'list of log items in the console, many of which might be empty '\n",
      "             'due to multiple initializations.',\n",
      " 'score': 3.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(result.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using `weave.Evaluate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorating the scoring metric with `weave.op()` allows us to track the inputs and outputs. The function itself will be traced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def get_answer_correctness(\n",
    "    question: str,\n",
    "    answer: str,\n",
    "    model_output: dict\n",
    ") -> dict:\n",
    "    result = await correctness_evaluator.aevaluate(\n",
    "        query=question,\n",
    "        response=model_output[\"response\"],\n",
    "        reference=answer,\n",
    "    )\n",
    "    return {\n",
    "        \"answer_correctness\": result.dict()[\"passing\"],\n",
    "        \"feedback\": result.dict()[\"feedback\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(name='eval_data_subset-evaluation', description=None, dataset=Dataset(name='eval_data_subset', description=None, rows=<weave.table.Table object at 0x32c7fe7a0>), scorers=[Op(get_answer_correctness)], preprocess_model_input=None, trials=1)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = weave.Evaluation(\n",
    "    dataset=eval_dataset, scorers=[get_answer_correctness]\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'get_answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.65</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.07438259124756</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'get_answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m13\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.65\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m17.07438259124756\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/4dc425c7-952e-41e6-8622-e4e72ca1fba1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_answer_correctness': {'answer_correctness': {'true_count': 13,\n",
       "   'true_fraction': 0.65}},\n",
       " 'model_latency': {'mean': 17.07438259124756}}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await evaluation.evaluate(rag_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try aligning the Judge LLM (`gpt-4o`)\n",
    "\n",
    "Judge alignment is nothing more than improving the system prompt of the LLM you are using as an evaluator. \n",
    "\n",
    "It means:\n",
    "\n",
    "- adding instructions to the system prompt to capture what you want?\n",
    "    - Is the tone correct? \n",
    "    - Is there gender reference which you don't want?\n",
    "    - Is there code snippets?\n",
    "    - It can mean anything!\n",
    "\n",
    "- adding examples (few-shot) to the system prompt for cases which you find as edge cases or cases where you feel your judge is not doing a good job.\n",
    "\n",
    "Both the method requires going back and forth with a tooling in place. The tooling should:\n",
    "\n",
    "- allow you to give feedbacks\n",
    "- allow you to programatically pull in feedbacks\n",
    "- allow you to compare two or more evaluations\n",
    "- allow you to adapt to a new technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the criteria with better instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 437.86it/s]\n",
      "2024/07/10 16:52:43 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720614163&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=ivp1r2bV51BFFzfQyIGwlcGAE%2Bh8k%2FB3KvP7rcYuVhTqzpd%2BcTgUNnlXb7hgpXWzChiwzqjxoP325SDsM5JNZG9KnH6pa%2Bcnjga3SQwcMMu9xUkxat95MlJ%2F3OnYxaK1sLA1XoiKJUozzXqxatMTfX6WAMgPfe0QQdhyluDb61J2t25p%2BZzV8QQiM5mpGZeVennvtnV%2FGcBs055gvj0hoSOtlPnO0IMTXa%2BVYzCYQ7X5ixDH0MY%2BK7yHUBLT%2Bpy9ngKO8XpxCsuxtvhQBjSGXWmQU4dCqm%2BfHbzMznOwH%2BJUPyAE7lNQ4lYc6CxHN4J%2BSV%2BaQ1%2FagcvQ8uH6bv89Hg%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    }
   ],
   "source": [
    "from eval import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'get_answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compare_length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_code_block_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'code_block_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.85</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_bullet_points_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'bullet_points_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.491464567184448</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'get_answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m19\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compare_length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_code_block_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'code_block_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m17\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.85\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m19\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_bullet_points_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'bullet_points_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m19\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m19\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m15.491464567184448\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/4a72b196-7fe8-4392-9c7f-3d5d53bc4bd8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_answer_correctness': {'answer_correctness': {'true_count': 19,\n",
       "   'true_fraction': 0.95}},\n",
       " 'compare_length_within_95_percentile': {'length_within_95_percentile': {'true_count': 4,\n",
       "   'true_fraction': 0.2}},\n",
       " 'check_code_block_presence': {'code_block_presense': {'true_count': 17,\n",
       "   'true_fraction': 0.85},\n",
       "  'has_code_block_gt': {'true_count': 16, 'true_fraction': 0.8},\n",
       "  'has_code_block_gen': {'true_count': 19, 'true_fraction': 0.95}},\n",
       " 'check_bullet_points_presence': {'bullet_points_presense': {'true_count': 19,\n",
       "   'true_fraction': 0.95},\n",
       "  'has_bullet_points_gt': {'true_count': 18, 'true_fraction': 0.9},\n",
       "  'has_bullet_points_gen': {'true_count': 19, 'true_fraction': 0.95}},\n",
       " 'model_latency': {'mean': 15.491464567184448}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await evaluator.evaluate(rag_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update system prompt with better instructions:\n",
    "\n",
    "diff:\n",
    "\n",
    "\"\"\"<br>\n",
    "Follow these guidelines for scoring:\n",
    "- Your score has to be between 1 and 3, where 1 is the worst and 3 is the best.\n",
    "- If the generated answer is not correct in comparison to the reference, you should give a score of 1.\n",
    "- If the generated answer is correct in comparison to the reference but contains mistakes, you should give a score of 2.\n",
    "- If the generated answer is correct in comparision to the reference and completely answer's the user's query, you should give a score of 3.<br>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 453.89it/s]\n",
      "2024/07/10 17:18:02 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720615681&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=wUTAkFFumad9kJLf6zUOAtIJX%2Fc8%2FkxbcoYY8ofWp0xYiJRgTgXQS7ZVmTc7VFxwjT4UVEZjba16NIVWA3nx2ZluZ9Ys0LZHw1gSrCmid2iQVMU9g0A%2FLCOf6wPKTxpni%2BbKt9ZZU6o0IuZHmGvigCZDdrYcGx6oquloSxRJrGCWEQT2EWZc1RzxfEPyNpE%2F0Ho3UKaREx%2FK7M5ScPfUfMY7aWNG9SgyqQSdPwSECfEXa75Km6L7h6bOCdcHmeXNTNOEI3CJwXmJm7T6h%2FLoFLwiYTv%2B3uKhWuDyN%2B7aQXtM2ojVBcyDDbBNNZOFnN5zY3GAQoGBEC1vU61oBsXNFw%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'get_answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compare_length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_code_block_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'code_block_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_bullet_points_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'bullet_points_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.661026763916016</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'get_answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compare_length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.05\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_code_block_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'code_block_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_bullet_points_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'bullet_points_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m20\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m13.661026763916016\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/39a684e9-31b7-477f-8445-8ce0ce4b20e2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_answer_correctness': {'answer_correctness': {'true_count': 18,\n",
       "   'true_fraction': 0.9}},\n",
       " 'compare_length_within_95_percentile': {'length_within_95_percentile': {'true_count': 1,\n",
       "   'true_fraction': 0.05}},\n",
       " 'check_code_block_presence': {'code_block_presense': {'true_count': 18,\n",
       "   'true_fraction': 0.9},\n",
       "  'has_code_block_gt': {'true_count': 16, 'true_fraction': 0.8},\n",
       "  'has_code_block_gen': {'true_count': 18, 'true_fraction': 0.9}},\n",
       " 'check_bullet_points_presence': {'bullet_points_presense': {'true_count': 18,\n",
       "   'true_fraction': 0.9},\n",
       "  'has_bullet_points_gt': {'true_count': 18, 'true_fraction': 0.9},\n",
       "  'has_bullet_points_gen': {'true_count': 20, 'true_fraction': 1.0}},\n",
       " 'model_latency': {'mean': 13.661026763916016}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import evaluator\n",
    "\n",
    "await evaluator.evaluate(rag_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the criteria with few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: ayut.\n",
      "View Weave data at https://wandb.ai/ayut/llamaindex-weave/weave\n"
     ]
    }
   ],
   "source": [
    "# Get the eval with feedbacks\n",
    "client = weave.init(\"ayut/llamaindex-weave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbs_down = client.feedback(reaction=\"👎\")\n",
    "calls = thumbs_down.refs().calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='1f32e8ff-e8f4-4479-a71b-56775f04b269', project_id='ayut/llamaindex-weave', parent_id='27025708-d381-436a-b1ab-c65c7e74e84e', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='VdRdiqyuDGeDJqixF5QCdDdv5WkjPqqU3VXLFAfLuPM', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='b1OEC1BzWkLgEFqj0aubhncBXHiSTmAC9PPXiEYLvXg', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'QPl3QIGcbj06cGvsYqvMJvFMIlUPXyBrKehVVUGp4Vo'])}, id='8e3defe8-334f-41db-b3b1-539a1c47a0d3', output={'model_output': {'response': \"Yes, you can copy runs from one project to another. However, since you have used all the free tracked hours provided by Weights and Biases for the team entity and are being redirected to the billing page, you might not be able to access the runs through the GUI.\\n\\nIn this case, you can use the `wandb sync` command to sync the runs to another project. The `wandb sync` command is used to send data stored on your local machine to the Weights and Biases server. Here's how you can do it:\\n\\n1. First, you need to find the path to your run. The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.\\n\\n2. Once you have the path, you can run the following command in your terminal:\\n\\n```shell\\nwandb sync wandb/path-to-your-run\\n```\\n\\nReplace `path-to-your-run` with the actual path to your run.\\n\\nPlease note that you need to have the necessary permissions to log to the project you're trying to send runs to. If you don't have the permissions, you might get a `LaunchError: Permission denied` error. In this case, you can ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\", 'context_str': 'Source ID: 6b334ba6-9049-45fc-bd89-bb47c3cb2fb2\\n\\n---\\ndisplayed_sidebar: default\\n---\\n\\n# Manage Runs\\n\\n### Move runs to a team\\n\\nOn the project page:\\n\\n1. Click the table tab to expand the runs table\\n2. Click the checkbox to select all runs\\n3. Click **Move**: the destination project can be in your personal account or any team that you\\'re a member of.\\n\\n![](/images/app_ui/demo_move_runs.gif)\\n\\n### Send new runs to a team\\n\\nIn your script, set the entity to your team. \"Entity\" just means your username or team name. Create an entity (personal account or team account) in the web app before sending runs there.\\n\\n```python\\nwandb.init(entity=\"example-team\")\\n```\\n\\nYour **default entity** is updated when you join a team. This means that on your [settings page](https://app.wandb.ai/settings), you\\'ll see that the default location to create a new project is now the team you\\'ve just joined. Here\\'s an example of what that [settings page](https://app.wandb.ai/settings) section looks like:\\n\\n![](/images/app_ui/send_new_runs_to_team.png)\\n-----------\\nSource ID: 81fe9292-033b-4f9a-9586-0239e0b3959b\\n\\n[](/images/experiments/sample_terminal_output.png)\\n\\nAnd once you\\'re ready, just run a sync command to send that folder to the cloud.\\n\\n```shell\\nwandb sync wandb/dryrun-folder-name\\n```\\n\\n![](/images/experiments/sample_terminal_output_cloud.png)\\n\\n### What is the difference between wandb.init modes?\\n\\nModes can be \"online\", \"offline\" or \"disabled\", and default to online.\\n\\n`online`(default): In this mode, the client sends data to the wandb server.\\n\\n`offline`: In this mode, instead of sending data to the wandb server, the client will store data on your local machine which can be later synced with the [`wandb sync`](../../ref/cli/wandb-sync.md) command.\\n\\n`disabled`: In this mode, the client returns mocked objects and prevents all network communication. The client will essentially act like a no-op. In other words, all logging is entirely disabled. However, stubs out of all the API methods are still callable. This is usually used in tests.\\n\\n### My run\\'s state is \"crashed\" on the UI but is still running on my machine. What do I do to get my data back?\\n\\nYou most likely lost connection to your machine while training. You can recover your data by running [`wandb sync [PATH_TO_RUN]`](../../ref/cli/wandb-sync.md). The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.\\n\\n### `LaunchError: Permission denied`\\n\\nIf you\\'re getting the error message `Launch Error: Permission denied`, you don\\'t have permissions to log to the project you\\'re trying to send runs to. This might be for a few different reasons.\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': False, 'feedback': \"The generated answer provides an alternative solution using the `wandb sync` command, which is relevant and could be helpful for the user's situation. However, it does not address the user's inability to access the GUI due to billing restrictions, nor does it provide a complete solution for copying runs from a team to a non-team project. The reference answer provides a more thorough solution using the W&B API, which is likely necessary in this case due to the billing issue.\"}}, 'model_latency': 20.584635257720947}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 1, 'completion_tokens': 274, 'prompt_tokens': 909, 'total_tokens': 1183}, 'gpt-4-1106-preview': {'requests': 1, 'completion_tokens': 119, 'prompt_tokens': 1146, 'total_tokens': 1265}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='1f32e8ff-e8f4-4479-a71b-56775f04b269', project_id='ayut/llamaindex-weave', parent_id='27025708-d381-436a-b1ab-c65c7e74e84e', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='VdRdiqyuDGeDJqixF5QCdDdv5WkjPqqU3VXLFAfLuPM', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='b1OEC1BzWkLgEFqj0aubhncBXHiSTmAC9PPXiEYLvXg', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'bhssXwhqXS64UEYzMHi3PbluVgeLy1F6OXYO8fMoFr4'])}, id='d2619d6a-aa21-430e-b440-b999a51fcfc4', output={'model_output': {'response': \"The error you're encountering might be due to several reasons. Here are a few things you can check:\\n\\n1. **CORS Configuration**: If you're using a private bucket to store your artifacts, ensure that you have allowed listing `app.wandb.ai` in your bucket's CORS settings. This allows the W&B App UI to properly render and access your artifacts.\\n\\n2. **Bucket Access Policy**: If your company uses a VPN, you might need to update your bucket's access policy to whitelist IPs within your VPN.\\n\\n3. **Object Versioning**: If your bucket has object versioning enabled, W&B will retrieve the object version corresponding to the state of the file at the time an artifact was logged. If you overwrite files as part of your workflow, W&B recommends enabling 'Object Versioning' on your storage buckets. This ensures that artifacts with references to files that have been overwritten will still be intact because the older object versions are retained.\\n\\n4. **Artifact Reference**: Ensure that the artifact reference you're using in your code is correct. The artifact reference should be in the format `project/artifact:alias`.\\n\\nIf you're still encountering issues, you might want to try downloading the artifact using the W&B CLI with the `wandb artifact get` command. You can also try to partially download the artifact based on a prefix using the `path_prefix` parameter in the `artifact.download()` function.\\n\\nIf none of these solutions work, please provide more details about your setup and the error message you're receiving for further assistance.\", 'context_str': 'Source ID: d38139e7-c899-4f77-9608-bf4d9348c829\\n\\n:::caution\\nRich media such as images, audio, video, and point clouds may fail to render in the App UI depending on the CORS configuration of your bucket. Allow listing **app.wandb.ai** in your bucket\\'s CORS settings will allow the App UI to properly render such rich media.\\n\\nPanels might fail to render in the App UI for private buckets. If your company has a VPN, you could update your bucket\\'s access policy to whitelist IPs within your VPN.\\n:::\\n\\n### Download a reference artifact\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = run.use_artifact(\"mnist:latest\", type=\"dataset\")\\nartifact_dir = artifact.download()\\n```\\n\\nW&B will use the metadata recorded when the artifact was logged to retrieve the files from the underlying bucket when it downloads a reference artifact. If your bucket has object versioning enabled, W&B will retrieve the object version corresponding to the state of the file at the time an artifact was logged. This means that as you evolve the contents of your bucket, you can still point to the exact iteration of your data a given model was trained on since the artifact serves as a snapshot of your bucket at the time of training.\\n\\n:::info\\nW&B recommends that you enable \\'Object Versioning\\' on your storage buckets if you overwrite files as part of your workflow. With versioning enabled on your buckets, artifacts with references to files that have been overwritten will still be intact because the older object versions are retained. \\n\\nBased on your use case, read the instructions to enable object versioning: [AWS](https://docs.aws.amazon.com/AmazonS3/latest/userguide/manage-versioning-examples.html), [GCP](https://cloud.google.com/storage/docs/using-object-versioning#set), [Azure](https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-enable).\\n:::\\n\\n### Tying it together\\n\\nThe following code example demonstrates a simple workflow you can use to track a dataset in Amazon S3, GCS, or Azure that feeds into a training job:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\n\\nartifact = wandb.Artifact(\"mnist\", type=\"dataset\")\\nartifact.add_reference(\"s3://my-bucket/datasets/mnist\")\\n\\n# Track the artifact and mark it as an input to\\n# this run in one swoop.\\n-----------\\nSource ID: e3eefbb5-42dc-4298-8b5e-86ef2bb02530\\n\\nFor more information, see the [API Reference Guide](../../ref/python/artifact.md#download).\\n  \\n  </TabItem>\\n  <TabItem value=\"CLI\">\\n\\nUse the `wandb artifact get` command to download an artifact from the W&B server.\\n\\n```\\n$ wandb artifact get project/artifact:alias --root mnist/\\n```\\n  </TabItem>\\n</Tabs>\\n\\n### Partially download an artifact\\n\\nYou can optionally download part of an artifact based on a prefix. Using the `path_prefix` parameter, you can download a single file or the content of a sub-folder.\\n\\n```python\\nartifact = run.use_artifact(\"bike-dataset:latest\")\\n\\nartifact.download(path_prefix=\"bike.png\") # downloads only bike.png\\n```\\n\\nAlternatively, you can download files from a certain directory:\\n\\n```python\\nartifact.download(path_prefix=\"images/bikes/\") # downloads files in the images/bikes directory\\n```\\n### Use an artifact from a different project\\n\\nSpecify the name of artifact along with its project name to reference an artifact. You can also reference artifacts across entities by specifying the name of the artifact with its entity name.\\n\\nThe following code example demonstrates how to query an artifact from another project as input to the current W&B run.\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init(project=\"<example>\", job_type=\"<job-type>\")\\n# Query W&B for an artifact from another project and mark it\\n# as an input to this run.\\nartifact = run.use_artifact(\"my-project/artifact:alias\")\\n\\n# Use an artifact from another entity and mark it as an input\\n# to this run.\\nartifact = run.use_artifact(\"my-entity/my-project/artifact:alias\")\\n```\\n\\n### Construct and use an artifact simultaneously\\n\\nSimultaneously construct and use an artifact. Create an artifact object and pass it to use\\\\_artifact. This creates an artifact in W&B if it does not exist yet. The [`use_artifact`](../../ref/python/run.md#use_artifact) API is idempotent, so you can call it as many times as you like.\\n\\n```python\\nimport wandb\\n\\nartifact = wandb.Artifact(\"reference model\")\\nartifact.add_file(\"model.h5\")\\nrun.use_artifact(artifact)\\n```\\n\\nFor more information about constructing an artifact, see [Construct an artifact](../../guides/artifacts/construct-an-artifact.md).\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': False, 'feedback': \"The generated answer provides relevant troubleshooting steps that are different from the reference answer, but they are also valid considerations when dealing with server errors related to artifact downloads in W&B. However, the generated answer does not address the specific 'Internal Server Error' message as thoroughly as the reference answer does.\"}}, 'model_latency': 31.140495777130127}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 1, 'completion_tokens': 310, 'prompt_tokens': 1107, 'total_tokens': 1417}, 'gpt-4-1106-preview': {'requests': 1, 'completion_tokens': 83, 'prompt_tokens': 1177, 'total_tokens': 1260}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='b643803b-0d26-4835-b06c-1e6af765037a', project_id='ayut/llamaindex-weave', parent_id='3e851ecb-28f6-4bce-941c-ab60ddd90905', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='zTMb0xzdwy2RUNETg5mD2ybdF0F899rYgIJUBs574ek', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='S6Ns3HTYXGPLBqFxPRmUaxXH6UrfujrE8kL7bN6I8V8', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'bhssXwhqXS64UEYzMHi3PbluVgeLy1F6OXYO8fMoFr4'])}, id='1700544f-a27a-4a44-9094-dd0b1ac1a20a', output={'model_output': {'response': 'The \"Internal Server Error\" you\\'re encountering might be due to several reasons. Here are a few things you can check:\\n\\n1. **Artifact Name**: Ensure that the artifact name you\\'re using in `run.use_artifact(f\\'{params.PROCESSED_DATA_AT}:latest\\')` is correct and exists in your W&B project.\\n\\n2. **Bucket Configuration**: If your artifact is stored in an external bucket (like AWS S3, GCP, or Azure), make sure that the CORS configuration of your bucket allows `app.wandb.ai`. Also, if your bucket has object versioning enabled, W&B will retrieve the object version corresponding to the state of the file at the time an artifact was logged.\\n\\n3. **Credentials**: W&B uses the default mechanism to look for credentials based on the cloud provider you use. Make sure your credentials are correctly set up.\\n\\n4. **Server Issues**: The error might be due to temporary server issues. You can try again after some time.\\n\\nIf the issue persists, it would be helpful to provide more details or contact W&B support for further assistance.', 'context_str': 'Source ID: d38139e7-c899-4f77-9608-bf4d9348c829\\n\\n:::caution\\nRich media such as images, audio, video, and point clouds may fail to render in the App UI depending on the CORS configuration of your bucket. Allow listing **app.wandb.ai** in your bucket\\'s CORS settings will allow the App UI to properly render such rich media.\\n\\nPanels might fail to render in the App UI for private buckets. If your company has a VPN, you could update your bucket\\'s access policy to whitelist IPs within your VPN.\\n:::\\n\\n### Download a reference artifact\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = run.use_artifact(\"mnist:latest\", type=\"dataset\")\\nartifact_dir = artifact.download()\\n```\\n\\nW&B will use the metadata recorded when the artifact was logged to retrieve the files from the underlying bucket when it downloads a reference artifact. If your bucket has object versioning enabled, W&B will retrieve the object version corresponding to the state of the file at the time an artifact was logged. This means that as you evolve the contents of your bucket, you can still point to the exact iteration of your data a given model was trained on since the artifact serves as a snapshot of your bucket at the time of training.\\n\\n:::info\\nW&B recommends that you enable \\'Object Versioning\\' on your storage buckets if you overwrite files as part of your workflow. With versioning enabled on your buckets, artifacts with references to files that have been overwritten will still be intact because the older object versions are retained. \\n\\nBased on your use case, read the instructions to enable object versioning: [AWS](https://docs.aws.amazon.com/AmazonS3/latest/userguide/manage-versioning-examples.html), [GCP](https://cloud.google.com/storage/docs/using-object-versioning#set), [Azure](https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-enable).\\n:::\\n\\n### Tying it together\\n\\nThe following code example demonstrates a simple workflow you can use to track a dataset in Amazon S3, GCS, or Azure that feeds into a training job:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\n\\nartifact = wandb.Artifact(\"mnist\", type=\"dataset\")\\nartifact.add_reference(\"s3://my-bucket/datasets/mnist\")\\n\\n# Track the artifact and mark it as an input to\\n# this run in one swoop.\\n-----------\\nSource ID: e3eefbb5-42dc-4298-8b5e-86ef2bb02530\\n\\nFor more information, see the [API Reference Guide](../../ref/python/artifact.md#download).\\n  \\n  </TabItem>\\n  <TabItem value=\"CLI\">\\n\\nUse the `wandb artifact get` command to download an artifact from the W&B server.\\n\\n```\\n$ wandb artifact get project/artifact:alias --root mnist/\\n```\\n  </TabItem>\\n</Tabs>\\n\\n### Partially download an artifact\\n\\nYou can optionally download part of an artifact based on a prefix. Using the `path_prefix` parameter, you can download a single file or the content of a sub-folder.\\n\\n```python\\nartifact = run.use_artifact(\"bike-dataset:latest\")\\n\\nartifact.download(path_prefix=\"bike.png\") # downloads only bike.png\\n```\\n\\nAlternatively, you can download files from a certain directory:\\n\\n```python\\nartifact.download(path_prefix=\"images/bikes/\") # downloads files in the images/bikes directory\\n```\\n### Use an artifact from a different project\\n\\nSpecify the name of artifact along with its project name to reference an artifact. You can also reference artifacts across entities by specifying the name of the artifact with its entity name.\\n\\nThe following code example demonstrates how to query an artifact from another project as input to the current W&B run.\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init(project=\"<example>\", job_type=\"<job-type>\")\\n# Query W&B for an artifact from another project and mark it\\n# as an input to this run.\\nartifact = run.use_artifact(\"my-project/artifact:alias\")\\n\\n# Use an artifact from another entity and mark it as an input\\n# to this run.\\nartifact = run.use_artifact(\"my-entity/my-project/artifact:alias\")\\n```\\n\\n### Construct and use an artifact simultaneously\\n\\nSimultaneously construct and use an artifact. Create an artifact object and pass it to use\\\\_artifact. This creates an artifact in W&B if it does not exist yet. The [`use_artifact`](../../ref/python/run.md#use_artifact) API is idempotent, so you can call it as many times as you like.\\n\\n```python\\nimport wandb\\n\\nartifact = wandb.Artifact(\"reference model\")\\nartifact.add_file(\"model.h5\")\\nrun.use_artifact(artifact)\\n```\\n\\nFor more information about constructing an artifact, see [Construct an artifact](../../guides/artifacts/construct-an-artifact.md).\\n-----------\\nSource ID: 87294f78-95e7-475b-8f96-23d8b7dbf9fe\\n\\n---\\ndescription: Download and use Artifacts from multiple projects.\\ndisplayed_sidebar: default\\n---\\n\\n# Download and use artifacts\\n\\n<head>\\n  <title>Download and use artifacts</title>\\n</head>\\n\\nDownload and use an artifact that is already stored on the W&B server or construct an artifact object and pass it in to for de-duplication as necessary.\\n\\n:::note\\nTeam members with view-only seats cannot download artifacts.\\n:::\\n\\n\\n### Download and use an artifact stored on W&B\\n\\nDownload and use an artifact stored in W&B either inside or outside of a W&B Run. Use the Public API ([`wandb.Api`](../../ref/python/public-api/api.md)) to export (or update data) already saved in W&B. For more information, see the W&B [Public API Reference guide](../../ref/python/public-api/README.md).\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n<Tabs\\n  defaultValue=\"insiderun\"\\n  values={[\\n    {label: \\'During a run\\', value: \\'insiderun\\'},\\n    {label: \\'Outside of a run\\', value: \\'outsiderun\\'},\\n    {label: \\'W&B CLI\\', value: \\'CLI\\'},\\n  ]}>\\n  <TabItem value=\"insiderun\">\\n\\nFirst, import the W&B Python SDK. Next, create a W&B [Run](../../ref/python/run.md):\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init(project=\"<example>\", job_type=\"<job-type>\")\\n```\\n\\nIndicate the artifact you want to use with the [`use_artifact`](../../ref/python/run.md#use_artifact) method. This returns a run object. In the proceeding code snippet specifies an artifact called `\\'bike-dataset\\'` with the alias `\\'latest\\'`:\\n\\n```python\\nartifact = run.use_artifact(\"bike-dataset:latest\")\\n```\\n\\nUse the object returned to download all the contents of the artifact:\\n\\n```python\\ndatadir = artifact.download()\\n```\\n\\nYou can optionally pass a path to the root parameter to download the contents of the artifact to a specific directory. For more information, see the [Python SDK Reference Guide](../../ref/python/artifact.md#download).\\n-----------\\nSource ID: d3aba1c5-ab68-46c6-abd6-72ee64b20a29\\n\\n# wandb artifact get\\n\\n**Usage**\\n\\n`wandb artifact get [OPTIONS] PATH`\\n\\n**Summary**\\n\\nDownload an artifact from wandb\\n\\n**Options**\\n\\n| **Option** | **Description** |\\n| :--- | :--- |\\n| --root | The directory you want to download the artifact to |\\n| --type | The type of artifact you are downloading |\\n-----------\\nSource ID: 69340818-3acc-4b14-b8ce-e4af3817fe45\\n\\nThis returns a run object. In the proceeding code snippet specifies an artifact called `\\'bike-dataset\\'` with the alias `\\'latest\\'`:\\n\\n```python\\nartifact = run.use_artifact(\"bike-dataset:latest\")\\n```\\n\\nUse the object returned to download all the contents of the artifact:\\n\\n```python\\ndatadir = artifact.download()\\n```\\n\\nYou can optionally pass a path to the root parameter to download the contents of the artifact to a specific directory. For more information, see the [Python SDK Reference Guide](../../ref/python/artifact.md#download).\\n\\nUse the [`get_path`](../../ref/python/artifact.md#get_path) method to download only subset of files:\\n\\n```python\\npath = artifact.get_path(name)\\n```\\n\\nThis fetches only the file at the path `name`. It returns an `Entry` object with the following methods:\\n\\n* `Entry.download`: Downloads file from the artifact at path `name`\\n* `Entry.ref`: If `add_reference` stored the entry as a reference, returns the URI\\n\\nReferences that have schemes that W&B knows how to handle get downloaded just like artifact files. For more information, see [Track external files](../../guides/artifacts/track-external-files.md).\\n  \\n  </TabItem>\\n  <TabItem value=\"outsiderun\">\\n  \\nFirst, import the W&B SDK. Next, create an artifact from the Public API Class. Provide the entity, project, artifact, and alias associated with that artifact:\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\nartifact = api.artifact(\"entity/project/artifact:alias\")\\n```\\n\\nUse the object returned to download the contents of the artifact:\\n\\n```python\\nartifact.download()\\n```\\n\\nYou can optionally pass a path the `root` parameter to download the contents of the artifact to a specific directory. For more information, see the [API Reference Guide](../../ref/python/artifact.md#download).\\n  \\n  </TabItem>\\n  <TabItem value=\"CLI\">\\n\\nUse the `wandb artifact get` command to download an artifact from the W&B server.\\n\\n```\\n$ wandb artifact get project/artifact:alias --root mnist/\\n```\\n  </TabItem>\\n</Tabs>\\n\\n### Partially download an artifact\\n\\nYou can optionally download part of an artifact based on a prefix.\\n-----------\\nSource ID: 808f2880-a648-46ec-a232-f44f288f7620\\n\\nLets track it with an artifact:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = wandb.Artifact(\"mnist\", type=\"dataset\")\\nartifact.add_reference(\"s3://my-bucket/datasets/mnist\")\\nrun.log_artifact(artifact)\\n```\\n:::caution\\nBy default, W&B imposes a 10,000 object limit when adding an object prefix. You can adjust this limit by specifying `max_objects=` in calls to `add_reference`.\\n:::\\n\\nOur new reference artifact `mnist:latest` looks and behaves similarly to a regular artifact. The only difference is that the artifact only consists of metadata about the S3/GCS/Azure object such as its ETag, size, and version ID (if object versioning is enabled on the bucket).\\n\\nW&B will use the default mechanism to look for credentials based on the cloud provider you use. Read the documentation from your cloud provider to learn more about the credentials used:\\n\\n| Cloud provider | Credentials Documentation |\\n| -------------- | ------------------------- |\\n| AWS            | [Boto3 documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html#configuring-credentials) |\\n| GCP            | [Google Cloud documentation](https://cloud.google.com/docs/authentication/provide-credentials-adc) |\\n| Azure          | [Azure documentation](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) |\\n\\nFor AWS, if the bucket is not located in the configured user\\'s default region, you must set the `AWS_REGION` environment variable to match the bucket region.\\n\\nInteract with this artifact similarly to a normal artifact. In the App UI, you can look through the contents of the reference artifact using the file browser, explore the full dependency graph, and scan through the versioned history of your artifact.\\n\\n:::caution\\nRich media such as images, audio, video, and point clouds may fail to render in the App UI depending on the CORS configuration of your bucket. Allow listing **app.wandb.ai** in your bucket\\'s CORS settings will allow the App UI to properly render such rich media.\\n\\nPanels might fail to render in the App UI for private buckets. If your company has a VPN, you could update your bucket\\'s access policy to whitelist IPs within your VPN.\\n-----------\\nSource ID: d0dbec51-f00e-4054-af4c-0e2a10e19468\\n\\nNow, you may be worrying about the `download` call.\\nIf we download another copy, won\\'t that double the burden on memory?\\n\\nDon\\'t worry friend. Before we actually download anything,\\nwe check to see if the right version is available locally.\\nThis uses the same technology that underlies [torrenting](https://en.wikipedia.org/wiki/Torrent_file) and [version control with `git`](https://blog.thoughtram.io/git/2014/11/18/the-anatomy-of-a-git-commit.html): hashing.\\n\\nAs `Artifact`s are created and logged,\\na folder called `artifacts` in the working directory\\nwill start to fill with sub-directories,\\none for each `Artifact`.\\nCheck out its contents with `!tree artifacts`:\\n\\n\\n```python\\n!tree artifacts\\n```\\n\\n### 🌐 The Artifacts page on [wandb.ai](https://wandb.ai)\\n\\nNow that we\\'ve logged and used an `Artifact`,\\nlet\\'s check out the Artifacts tab on the Run page.\\n\\nNavigate to the Run page URL from the `wandb` output\\nand select the \"Artifacts\" tab from the left sidebar\\n(it\\'s the one with the database icon,\\nwhich looks like three hockey pucks stacked on top of one another).\\n\\nClick a row in either the \"Input Artifacts\" table\\nor in the \"Output Artifacts\" table,\\nthen check out the tabs (\"Overview\", \"Metadata\")\\nto see everything logged about the `Artifact`.\\n\\nWe particularly like the \"Graph View\".\\nBy default, it shows a graph\\nwith the `type`s of `Artifact`s\\nand the `job_type`s of `Run` as the two types of nodes,\\nwith arrows to represent consumption and production.\\n\\n# 3️⃣ Log a Model\\n\\nThat\\'s enough to see how the API for `Artifact`s works,\\nbut let\\'s follow this example through to the end of the pipeline\\nso we can see how `Artifact`s can improve your ML workflow.\\n\\nThis first cell here builds a DNN `model` in PyTorch -- a really simple ConvNet.\\n\\nWe\\'ll start by just initializing the `model`, not training it.\\nThat way, we can repeat the training while keeping everything else constant.\\n-----------\\nSource ID: d371a206-9dc8-4da3-b221-7e4e8d0e96d5\\n\\n## Create an artifact\\n\\nCreate an artifact with four lines of code:\\n1. Create a [W&B Run](../runs/intro.md).\\n2. Create an artifact object with the [`wandb.Artifact`](../../ref/python/artifact.md) API.\\n3. Add one or more files, such as a model file or dataset, to your artifact object. In this example, you\\'ll add a single file.\\n4. Log your artifact to W&B.\\n\\n\\n```python\\nrun = wandb.init(project = \"artifacts-example\", job_type = \"add-dataset\")\\nrun.log_artifact(data = \"./dataset.h5\", name = \"my_data\", type = \"dataset\" ) # Logs the artifact version \"my_data\" as a dataset with data from dataset.h5\\n```\\n\\n:::tip\\nSee the [track external files](./track-external-files.md) page for information on how to add references to files or directories stored in external object storage, like an Amazon S3 bucket. \\n:::\\n\\n## Download an artifact\\nIndicate the artifact you want to mark as input to your run with the [`use_artifact`](../../ref/python/run.md#use_artifact) method, which returns an artifact object:\\n\\n```python\\nartifact = run.use_artifact(\"my_data:latest\") #returns a run object using the \"my_data\" artifact\\n```\\n\\nThen, use the returned object to download all contents of the artifact:\\n\\n```python\\ndatadir = artifact.download() #downloads the full \"my_data\" artifact to the default directory.\\n```\\n\\n:::tip\\nYou can pass a custom path into the `root` [parameter](../../ref/python/artifact.md) to download an artifact to a specific directory. For alternate ways to download artifacts and to see additional parameters, see the guide on [downloading and using artifacts](./download-and-use-an-artifact.md)\\n:::\\n\\n## Next steps\\n* Learn how to [version](./create-a-new-artifact-version.md), [update](./update-an-artifact.md), or [delete](./delete-artifacts.md) artifacts.\\n* Learn how to trigger downstream workflows in response to changes to your artifacts with [artifact automation](./project-scoped-automations.md).\\n* Learn about the [model registry](../model_registry/intro.md), a space that houses trained models.\\n* Explore the [Python SDK](../../ref/python/artifact.md) and [CLI](../../ref/cli/wandb-artifact/README.md) reference guides.\\n-----------\\nSource ID: ff32c7e7-a1a7-4b6b-86ab-0963cf00287f\\n\\n```python\\n# Create a W&B Run. Here we specify \\'training\\' for \\'type\\'\\n# because we will use this run to track training.\\nrun = wandb.init(project=\"artifacts-example\", job_type=\"training\")\\n\\n# Query W&B for an artifact and mark it as input to this run\\nartifact = run.use_artifact(\"bicycle-dataset:latest\")\\n\\n# Download the artifact\\'s contents\\nartifact_dir = artifact.download()\\n```\\n\\nAlternatively, you can use the Public API (`wandb.Api`) to export (or update data) data already saved in a W&B outside of a Run. See [Track external files](./track-external-files.md) for more information.\\n-----------\\nSource ID: d007d314-7ddb-452f-8b00-56a776dfe23a\\n\\n![Searching a run cluster](../../../static/images/artifacts/lineage3b.gif)\\n\\n## Use the API to track lineage\\nYou can also navigate a graph using the [W&B API](../../ref/python/public-api/api.md). \\n\\nCreate an artifact. First, create a run with `wandb.init`. Then,create a new artifact or retrieve an existing one with `wandb.Artifact`. Next, add files to the artifact with `.add_file`. Finally, log the artifact to the run with `.log_artifact`. The finished code looks something like this:\\n\\n```python\\nwith wandb.init() as run:\\n    artifact = wandb.Artifact(\"artifact_name\", \"artifact_type\")\\n\\n    # Add Files and Assets to the artifact using\\n    # `.add`, `.add_file`, `.add_dir`, and `.add_reference`\\n    artifact.add_file(\"image1.png\")\\n    run.log_artifact(artifact)\\n```\\n\\nUse the artifact object\\'s [`logged_by`](../../ref/python/artifact.md#logged_by) and [`used_by`](../../ref/python/artifact.md#used_by) methods to walk the graph from the artifact:\\n\\n```python\\n# Walk up and down the graph from an artifact:\\nproducer_run = artifact.logged_by()\\nconsumer_runs = artifact.used_by()\\n```\\n## Next steps\\n- [Explore artifacts in more detail](../artifacts/artifacts-walkthrough.md)\\n- [Manage artifact storage](../artifacts/delete-artifacts.md)\\n- [Explore an artifacts project](https://wandb.ai/wandb-smle/artifact_workflow/artifacts/raw_dataset/raw_data/v0/lineage)\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': True, 'feedback': \"The generated answer addresses several potential causes for the 'Internal Server Error' and provides actionable steps to troubleshoot the issue. It mentions checking the artifact name, bucket configuration, credentials, and potential server issues, which are relevant to the user's problem. However, it could be more comprehensive by including steps like checking W&B status, retrying the request, reviewing API limits, and ensuring proper authentication, which are also important troubleshooting steps.\"}}, 'model_latency': 55.043330669403076}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 2, 'completion_tokens': 444, 'prompt_tokens': 4931, 'total_tokens': 5375}, 'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 106, 'prompt_tokens': 5306, 'total_tokens': 5412}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='b643803b-0d26-4835-b06c-1e6af765037a', project_id='ayut/llamaindex-weave', parent_id='3e851ecb-28f6-4bce-941c-ab60ddd90905', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='zTMb0xzdwy2RUNETg5mD2ybdF0F899rYgIJUBs574ek', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='S6Ns3HTYXGPLBqFxPRmUaxXH6UrfujrE8kL7bN6I8V8', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'aOBjGSicDwlYIlHM3zR2e3JMnOH5eDgipZ4qd9L3YYE'])}, id='b8a943ae-1a48-4a65-9979-ff9d0ee6288c', output={'model_output': {'response': 'To execute runs in a sweep in parallel, you can initiate multiple agents. You can start up to 20 agents on various machines concurrently if you wish to distribute the workload and complete the sweep task more rapidly. Each agent will execute a separate instance of the training job. \\n\\nHere\\'s how you can do it:\\n\\n1. Firstly, initialize a sweep with your sweep configuration. This can be done using the `wandb.sweep` function in Python:\\n\\n```python\\nsweep_id = wandb.sweep(sweep_config, project=\"your_project_name\")\\n```\\n\\n2. Next, start multiple agents using the `wandb.agent` function. You can do this on different machines or different processes:\\n\\n```python\\nwandb.agent(sweep_id, function=train_function, count=20)\\n```\\n\\nIn this example, `train_function` is the function that outlines your training loop. The `count` parameter indicates the maximum number of runs to execute. \\n\\nYou can also set the number of concurrent runs the scheduler manages using `num_workers` in the sweep configuration.\\n\\nKeep in mind that each agent will display the set of parameters it’s attempting next.', 'context_str': 'Source ID: ab0da8c8-4c0d-4e39-b631-db2234a6f063\\n\\n![](@site/static/images/sweeps/sweep1.png)\\n\\nThe auto-generated configuration guesses values to sweep over based on the runs you have completed. Edit the configuration to specify what ranges of hyperparameters you want to try. When you launch the sweep, it starts a new process on the hosted W&B sweep server. This centralized service coordinates the agents— the machines that are running the training jobs.\\n\\n![](@site/static/images/sweeps/sweep2.png)\\n\\n## 3. Launch agents\\n\\nNext, launch an agent locally. You can launch up to 20 agents on different machines in parallel if you want to distribute the work and finish the sweep job more quickly. The agent will print out the set of parameters it’s trying next.\\n\\n![](@site/static/images/sweeps/sweep3.png)\\n\\nNow you\\'re running a sweep. The following image demonstrates what the dashboard looks like as the example sweep job is running. [View an example project page →](https://app.wandb.ai/carey/pytorch-cnn-fashion)\\n\\n![](https://paper-attachments.dropbox.com/s\\\\_5D8914551A6C0AABCD5718091305DD3B64FFBA192205DD7B3C90EC93F4002090\\\\_1579066494222\\\\_image.png)\\n\\n## Seed a new sweep with existing runs\\n\\nLaunch a new sweep using existing runs that you\\'ve previously logged.\\n\\n1. Open your project table.\\n2. Select the runs you want to use with checkboxes on the left side of the table.\\n3. Click the dropdown to create a new sweep.\\n\\nYour sweep will now be set up on our server. All you need to do is launch one or more agents to start running runs.\\n\\n![](/images/sweeps/tutorial_sweep_runs.png)\\n\\n:::info\\nIf you kick off the new sweep as a bayesian sweep, the selected runs will also seed the Gaussian Process.\\n:::\\n-----------\\nSource ID: 8a775426-506f-4bb6-a062-c6251ff62c8a\\n\\n8. (Optional) Configure override args for the run or sweep scheduler. For example, using the scheduler overrides, configure the number of concurrent runs the scheduler manages using `num_workers`.\\n9. (Optional) Select a project to save the sweep to using the **Destination Project** dropdown menu.\\n10. Click **Save**\\n11. Select **Launch Sweep**.\\n\\n![](/images/launch/create_sweep_with_launch.png)\\n\\n  </TabItem>\\n  <TabItem value=\"cli\">\\n\\nProgrammatically create a W&B Sweep with Launch with the W&B CLI.\\n\\n1. Create a Sweep configuration\\n2. Specify the full job name within your sweep configuration\\n3. Initialize a sweep agent.\\n\\n:::info\\nSteps 1 and 3 are the same steps you normally take when you create a W&B Sweep.\\n:::\\n\\nFor example, in the following code snippet, we specify `\\'wandb/jobs/Hello World 2:latest\\'` for the job value:\\n\\n```yaml\\n# launch-sweep-config.yaml\\n\\njob: \\'wandb/jobs/Hello World 2:latest\\'\\ndescription: sweep examples using launch jobs\\n\\nmethod: bayes\\nmetric:\\n  goal: minimize\\n  name: loss_metric\\nparameters:\\n  learning_rate:\\n    max: 0.02\\n    min: 0\\n    distribution: uniform\\n  epochs:\\n    max: 20\\n    min: 0\\n    distribution: int_uniform\\n\\n# Optional scheduler parameters:\\n\\n# scheduler:\\n#   num_workers: 1  # concurrent sweep runs\\n#   docker_image: <base image for the scheduler>\\n#   resource: <ie. local-container...>\\n#   resource_args:  # resource arguments passed to runs\\n#     env: \\n#         - WANDB_API_KEY\\n\\n# Optional Launch Params\\n# launch: \\n#    registry: <registry for image pulling>\\n```\\n\\nFor information on how to create a sweep configuration, see the [Define sweep configuration](../sweeps/define-sweep-configuration.md) page.\\n\\n4. Next, initialize a sweep. Provide the path to your config file, the name of your job queue, your W&B entity, and the name of the project.\\n-----------\\nSource ID: 4deb5b3a-71e1-4bab-9385-758ab3aa2c20\\n\\n```python\\nsweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")\\n```\\n\\n# Step 3️⃣. Run the Sweep agent\\n\\n### 💻 Define Your Training Procedure\\n\\nBefore we can actually execute the sweep,\\nwe need to define the training procedure that uses those values.\\n\\nIn the functions below, we define a simple fully-connected neural network in PyTorch, and add the following `wandb` tools to log model metrics, visualize performance and output and track our experiments:\\n* [**`wandb.init()`**](https://docs.wandb.com/library/init) – Initialize a new W&B Run. Each Run is a single execution of the training function.\\n* [**`wandb.config`**](https://docs.wandb.com/library/config) – Save all your hyperparameters in a configuration object so they can be logged. Read more about how to use `wandb.config` [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb).\\n* [**`wandb.log()`**](https://docs.wandb.com/library/log) – log model behavior to W&B. Here, we just log the performance; see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_(Almost)_Anything_with_W%26B_Media.ipynb) for all the other rich media that can be logged with `wandb.log`.\\n\\nFor more details on instrumenting W&B with PyTorch, see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb).\\n-----------\\nSource ID: 39f85e2a-a692-4399-97e9-007068075b65\\n\\n---\\ndescription: Learn how to create configuration files for sweeps.\\ndisplayed_sidebar: default\\n---\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Sweep configuration structure\\n\\n<head>\\n  <title>Define sweep configuration for hyperparameter tuning.</title>\\n</head>\\n\\nA W&B Sweep combines a strategy for exploring hyperparameter values with the code that evaluates them. The strategy can be as simple as trying every option or as complex as Bayesian Optimization and Hyperband ([BOHB](https://arxiv.org/abs/1807.01774)).\\n\\nDefine a sweep configuration either in a [Python dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) or a [YAML](https://yaml.org/) file. How you define your sweep configuration depends on how you want to manage your sweep.\\n\\n:::info\\nDefine your sweep configuration in a YAML file if you want to initialize a sweep and start a sweep agent from the command line. Define your sweep in a Python dictionary if you initialize a sweep and start a sweep entirely within a Python script or Jupyter notebook.\\n:::\\n\\nThe following guide describes how to format your sweep configuration. See [Sweep configuration options](./sweep-config-keys.md) for a comprehensive list of top-level sweep configuration keys.\\n\\n## Basic structure\\n\\nBoth sweep configuration format options (YAML and Python dictionary) utilize key-value pairs and nested structures. \\n\\nUse top-level keys within your sweep configuration to define qualities of your sweep search such as the name of the sweep ([`name`](./sweep-config-keys.md#name) key), the parameters to search through ([`parameters`](./sweep-config-keys.md#parameters) key), the methodology to search the parameter space ([`method`](./sweep-config-keys.md#method) key), and more. \\n\\n\\nFor example, the proceeding code snippets show the same sweep configuration defined within a YAML file and within a Python dictionary. Within the sweep configuration there are five top level keys specified: `program`, `name`, `method`, `metric` and `parameters`.\\n-----------\\nSource ID: b2c93358-6614-4bfa-adaf-dbb1b74df6a3\\n\\n```\\nsweep_id = wandb.sweep(sweep_config)\\n```\\n\\nNext, start the sweep job. Provide the sweep ID generated from sweep initiation. Pass an integer value to the count parameter to set the maximum number of runs to try.\\n\\n```python\\nsweep_id, count = \"dtzl1o7u\", 10\\nwandb.agent(sweep_id, count=count)\\n```\\n\\n:::caution\\nIf you start a new run after the sweep agent has finished, within the same script or notebook, then you should call `wandb.teardown()` before starting the new run.\\n:::\\n\\n\\n  </TabItem>\\n\\n  <TabItem value=\"cli\">\\n\\nFirst, initialize your sweep with the [`wandb sweep`](../../ref/cli/wandb-sweep.md) command. For more information, see [Initialize sweeps](./initialize-sweeps.md).\\n\\n```\\nwandb sweep config.yaml\\n```\\n\\nPass an integer value to the count flag to set the maximum number of runs to try.\\n\\n```\\nNUM=10\\nSWEEPID=\"dtzl1o7u\"\\nwandb agent --count $NUM $SWEEPID\\n```\\n  </TabItem>\\n</Tabs>\\n-----------\\nSource ID: 4e1e65c0-9aeb-4551-84c7-1b849491db98\\n\\n---\\ndescription: Discover how to automate hyperparamter sweeps on launch.\\ndisplayed_sidebar: default\\n---\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\nimport { CTAButtons } from \\'@site/src/components/CTAButtons/CTAButtons.tsx\\';\\n\\n# Sweeps on Launch\\n\\n<CTAButtons colabLink=\"https://colab.research.google.com/drive/1WxLKaJlltThgZyhc7dcZhDQ6cjVQDfil#scrollTo=AFEzIxA6foC7\"/>\\n\\nCreate a hyperparameter tuning job ([sweeps](../sweeps/intro.md)) with W&B Launch. With sweeps on launch, a sweep scheduler is pushed to a Launch Queue with the specified hyperparameters to sweep over. The sweep scheduler starts as it is picked up by the agent, launching sweep runs onto the same queue with chosen hyperparameters. This continues until the sweep finishes or is stopped. \\n\\nYou can use the default W&B Sweep scheduling engine or implement your own custom scheduler:\\n\\n1. Standard sweep scheduler: Use the default W&B Sweep scheduling engine that controls [W&B Sweeps](../sweeps/intro.md). The familiar `bayes`, `grid`, and `random` methods are available.\\n2. Custom sweep scheduler: Configure the sweep scheduler to run as a job. This option enables full customization. An example of how to extend the standard sweep scheduler to include more logging can be found in the section below.\\n \\n:::note\\nThis guide assumes that W&B Launch has been previously configured. If W&B Launch has is not configured, see the [how to get started](./intro.md#how-to-get-started) section of the launch documentation. \\n:::\\n\\n:::tip\\nWe recommend you create a sweep on launch using the \\'basic\\' method if you are a first time users of sweeps on launch. Use a custom sweeps on launch scheduler when the standard W&B scheduling engine does not meet your needs.\\n:::\\n\\n## Create a sweep with a W&B standard scheduler\\nCreate W&B Sweeps with Launch. You can create a sweep interactively with the W&B App or programmatically with the W&B CLI. For advanced configurations of Launch sweeps, including the ability to customize the scheduler, use the CLI.\\n-----------\\nSource ID: 736502b2-d028-4d73-a4fa-95481f2d1726\\n\\n```python title=\"train.py\" showLineNumbers\\ndef main():\\n    run = wandb.init(config={\"nested_param\": {\"manual_key\": 1}})\\n\\n\\nsweep_configuration = {\\n    \"top_level_param\": 0,\\n    \"nested_param\": {\\n        \"learning_rate\": 0.01,\\n        \"double_nested_param\": {\"x\": 0.9, \"y\": 0.8},\\n    },\\n}\\n\\n# Initialize sweep by passing in config.\\nsweep_id = wandb.sweep(sweep=sweep_configuration, project=\"<project>\")\\n\\n# Start sweep job.\\nwandb.agent(sweep_id, function=main, count=4)\\n```\\nThe `nested_param.manual_key` that is passed when the W&B run is initialized (line 2) is not accessible. The `run.config` only possess the key-value pairs that are defined in the sweep configuration dictionary (lines 4-13).\\n:::\\n\\n\\n## Sweep configuration template\\n\\n\\nThe following template shows how you can configure parameters and specify search constraints. Replace `hyperparameter_name` with the name of your hyperparameter and any values enclosed in `<>`.\\n\\n```yaml title=\"config.yaml\"\\nprogram: <insert>\\nmethod: <insert>\\nparameter:\\n  hyperparameter_name0:\\n    value: 0  \\n  hyperparameter_name1: \\n    values: [0, 0, 0]\\n  hyperparameter_name: \\n    distribution: <insert>\\n    value: <insert>\\n  hyperparameter_name2:  \\n    distribution: <insert>\\n    min: <insert>\\n    max: <insert>\\n    q: <insert>\\n  hyperparameter_name3: \\n    distribution: <insert>\\n    values:\\n      - <list_of_values>\\n      - <list_of_values>\\n      - <list_of_values>\\nearly_terminate:\\n  type: hyperband\\n  s: 0\\n  eta: 0\\n  max_iter: 0\\ncommand:\\n- ${Command macro}\\n- ${Command macro}\\n- ${Command macro}\\n- ${Command macro}      \\n```\\n\\n## Sweep configuration examples\\n\\n<Tabs\\n  defaultValue=\"cli\"\\n  values={[\\n    {label: \\'CLI\\', value: \\'cli\\'},\\n    {label: \\'Python script or Jupyter notebook\\', value: \\'notebook\\'},\\n  ]}>\\n  <TabItem value=\"cli\">\\n-----------\\nSource ID: fadc54ba-96dc-4599-91b2-8457c9f949a0\\n\\n:::\\n\\n:::tip\\nWe recommend you create a sweep on launch using the \\'basic\\' method if you are a first time users of sweeps on launch. Use a custom sweeps on launch scheduler when the standard W&B scheduling engine does not meet your needs.\\n:::\\n\\n## Create a sweep with a W&B standard scheduler\\nCreate W&B Sweeps with Launch. You can create a sweep interactively with the W&B App or programmatically with the W&B CLI. For advanced configurations of Launch sweeps, including the ability to customize the scheduler, use the CLI. \\n\\n:::info\\nBefore you create a sweep with W&B Launch, ensure that you first create a job to sweep over. See the [Create a Job](./create-launch-job.md) page for more information. \\n:::\\n\\n\\n<Tabs\\n  defaultValue=\"app\"\\n  values={[\\n    {label: \\'W&B App\\', value: \\'app\\'},\\n    {label: \\'CLI\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"app\">\\nCreate a sweep interactively with the W&B App.\\n\\n1. Navigate to your W&B project on the W&B App.  \\n2. Select the sweeps icon on the left panel (broom image). \\n3. Next, select the **Create Sweep** button.\\n4. Click the **Configure Launch 🚀** button.\\n5. From the **Job** dropdown menu, select the name of your job and the job version you want to create a sweep from.\\n6. Select a queue to run the sweep on using the **Queue** dropdown menu.\\n8. Use the **Job Priority** dropdown to specify the priority of your launch job.  A launch job\\'s priority is set to \"Medium\" if the launch queue does not support prioritization.\\n8. (Optional) Configure override args for the run or sweep scheduler. For example, using the scheduler overrides, configure the number of concurrent runs the scheduler manages using `num_workers`.\\n9. (Optional) Select a project to save the sweep to using the **Destination Project** dropdown menu.\\n10. Click **Save**\\n11. Select **Launch Sweep**.\\n\\n![](/images/launch/create_sweep_with_launch.png)\\n\\n  </TabItem>\\n  <TabItem value=\"cli\">\\n\\nProgrammatically create a W&B Sweep with Launch with the W&B CLI.\\n\\n1.\\n-----------\\nSource ID: 6c7cf75d-8d90-424c-b644-1f9545b5f040\\n\\n---\\ndescription: Initialize a W&B Sweep\\ndisplayed_sidebar: default\\n---\\n\\nimport Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# Initialize sweeps\\n\\n<head>\\n  <title>Start a W&B Sweep</title>\\n</head>\\n\\nW&B uses a _Sweep Controller_ to manage sweeps on the cloud (standard), locally (local) across one or more machines. After a run completes, the sweep controller will issue a new set of instructions describing a new run to execute. These instructions are picked up by _agents_ who actually perform the runs. In a typical W&B Sweep, the controller lives on the W&B server. Agents live on _your_ machine(s).\\n\\nThe following code snippets demonstrate how to initialize sweeps with the CLI and within a Jupyter Notebook or Python script.\\n\\n:::caution\\n1. Before you initialize a sweep, make sure you have a sweep configuration defined either in a YAML file or a nested Python dictionary object in your script. For more information see, [Define sweep configuration](../../guides/sweeps/define-sweep-configuration.md).\\n2. Both the W&B Sweep and the W&B Run must be in the same project. Therefore, the name you provide when you initialize W&B ([`wandb.init`](../../ref/python/init.md)) must match the name of the project you provide when you initialize a W&B Sweep ([`wandb.sweep`](../../ref/python/sweep.md)).\\n:::\\n\\n<Tabs\\n  defaultValue=\"python\"\\n  values={[\\n    {label: \\'Python script or Jupyter Notebook\\', value: \\'python\\'},\\n    {label: \\'CLI\\', value: \\'cli\\'},\\n  ]}>\\n  <TabItem value=\"python\">\\n\\nUse the W&B SDK to initialize a sweep. Pass the sweep configuration dictionary to the `sweep` parameter. Optionally provide the name of the project for the project parameter (`project`) where you want the output of the W&B Run to be stored.  If the project is not specified, the run is put in an \"Uncategorized\" project.\\n-----------\\nSource ID: 0b77331c-f899-4ebe-ba04-b9c6b01a97ad\\n\\n```python\\nimport pprint\\n\\npprint.pprint(sweep_config)\\n```\\n\\nBut that\\'s not all of the configuration options!\\n\\nFor example, we also offer the option to `early_terminate` your runs with the [HyperBand](https://arxiv.org/pdf/1603.06560.pdf) scheduling algorithm. See more [here](https://docs.wandb.com/sweeps/configuration#stopping-criteria).\\n\\nYou can find a list of all configuration options [here](https://docs.wandb.com/library/sweeps/configuration)\\nand a big collection of examples in YAML format [here](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion).\\n\\n\\n\\n# Step 2️⃣. Initialize the Sweep\\n\\nOnce you\\'ve defined the search strategy, it\\'s time to set up something to implement it.\\n\\nThe clockwork taskmaster in charge of our Sweep is known as the _Sweep Controller_.\\nAs each run completes, it will issue a new set of instructions\\ndescribing a new run to execute.\\nThese instructions are picked up by _agents_\\nwho actually perform the runs.\\n\\nIn a typical Sweep, the Controller lives on _our_ machine,\\nwhile the agents who complete runs live on _your_ machine(s),\\nlike in the diagram below.\\nThis division of labor makes it super easy to scale up Sweeps\\nby just adding more machines to run agents!\\n\\n<img src=\"https://i.imgur.com/zlbw3vQ.png\" alt=\"sweeps-diagram\" width=\"500\"/>\\n\\nWe can wind up a Sweep Controller by calling `wandb.sweep` with the appropriate `sweep_config` and `project` name.\\n\\nThis function returns a `sweep_id` that we will later user to assign agents to this Controller.\\n\\n> _Side Note_: on the command line, this function is replaced with\\n```python\\nwandb sweep config.yaml\\n```\\n[Learn more about using Sweeps in the command line ➡](https://docs.wandb.ai/guides/sweeps/walkthrough)\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': True, 'feedback': 'The generated answer correctly explains how to run sweeps in parallel by launching multiple agents. It provides a clear step-by-step guide on initializing a sweep and starting multiple agents, which aligns with the retrieved context. However, it lacks details on running agents on multiple CPUs within the same machine or using Jupyter Notebooks, which are also relevant methods for parallelization.'}}, 'model_latency': 50.602949142456055}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 2, 'completion_tokens': 470, 'prompt_tokens': 5149, 'total_tokens': 5619}, 'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 93, 'prompt_tokens': 5425, 'total_tokens': 5518}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='b643803b-0d26-4835-b06c-1e6af765037a', project_id='ayut/llamaindex-weave', parent_id='3e851ecb-28f6-4bce-941c-ab60ddd90905', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='zTMb0xzdwy2RUNETg5mD2ybdF0F899rYgIJUBs574ek', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='S6Ns3HTYXGPLBqFxPRmUaxXH6UrfujrE8kL7bN6I8V8', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'QPl3QIGcbj06cGvsYqvMJvFMIlUPXyBrKehVVUGp4Vo'])}, id='3621b4c7-7a8a-4d49-99b5-bb8b389255a5', output={'model_output': {'response': 'To transfer runs from one project to another, including from a team project to a non-team project, you can use the `wandb.Api()` to interact with your runs. Here\\'s a suggested workaround:\\n\\n1. Ensure all the runs data is stored locally in your `wandb` directory.\\n\\n2. Use the `wandb.Api()` to fetch the runs from your team project. Loop over these runs to access the config and summary of each run.\\n\\n3. Use this data to create new runs in your personal project with `wandb.init()`. Set the entity to your personal account and the project to your personal project. Log the config and summary data to these new runs.\\n\\n4. Use `wandb sync` to sync these new runs to the cloud.\\n\\nHere\\'s a sample code:\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\nteam_runs = api.runs(\"team_entity/team_project\")\\n\\nfor run in team_runs:\\n    config = run.config\\n    summary = run.summary\\n\\n    wandb.init(entity=\"personal_entity\", project=\"personal_project\")\\n    wandb.config.update(config)\\n    wandb.log(summary)\\n    wandb.finish()\\n```\\n\\nReplace `\"team_entity/team_project\"` with your team entity and project, and `\"personal_entity/personal_project\"` with your personal entity and project.\\n\\nThis workaround may not work perfectly for all scenarios. For instance, it won\\'t copy any files (like model weights) associated with the runs. You\\'ll need to handle those separately. Also, this will create new runs in your personal project, not exactly \"move\" the runs from the team project.', 'context_str': 'Source ID: 6b334ba6-9049-45fc-bd89-bb47c3cb2fb2\\n\\n---\\ndisplayed_sidebar: default\\n---\\n\\n# Manage Runs\\n\\n### Move runs to a team\\n\\nOn the project page:\\n\\n1. Click the table tab to expand the runs table\\n2. Click the checkbox to select all runs\\n3. Click **Move**: the destination project can be in your personal account or any team that you\\'re a member of.\\n\\n![](/images/app_ui/demo_move_runs.gif)\\n\\n### Send new runs to a team\\n\\nIn your script, set the entity to your team. \"Entity\" just means your username or team name. Create an entity (personal account or team account) in the web app before sending runs there.\\n\\n```python\\nwandb.init(entity=\"example-team\")\\n```\\n\\nYour **default entity** is updated when you join a team. This means that on your [settings page](https://app.wandb.ai/settings), you\\'ll see that the default location to create a new project is now the team you\\'ve just joined. Here\\'s an example of what that [settings page](https://app.wandb.ai/settings) section looks like:\\n\\n![](/images/app_ui/send_new_runs_to_team.png)\\n-----------\\nSource ID: 81fe9292-033b-4f9a-9586-0239e0b3959b\\n\\n[](/images/experiments/sample_terminal_output.png)\\n\\nAnd once you\\'re ready, just run a sync command to send that folder to the cloud.\\n\\n```shell\\nwandb sync wandb/dryrun-folder-name\\n```\\n\\n![](/images/experiments/sample_terminal_output_cloud.png)\\n\\n### What is the difference between wandb.init modes?\\n\\nModes can be \"online\", \"offline\" or \"disabled\", and default to online.\\n\\n`online`(default): In this mode, the client sends data to the wandb server.\\n\\n`offline`: In this mode, instead of sending data to the wandb server, the client will store data on your local machine which can be later synced with the [`wandb sync`](../../ref/cli/wandb-sync.md) command.\\n\\n`disabled`: In this mode, the client returns mocked objects and prevents all network communication. The client will essentially act like a no-op. In other words, all logging is entirely disabled. However, stubs out of all the API methods are still callable. This is usually used in tests.\\n\\n### My run\\'s state is \"crashed\" on the UI but is still running on my machine. What do I do to get my data back?\\n\\nYou most likely lost connection to your machine while training. You can recover your data by running [`wandb sync [PATH_TO_RUN]`](../../ref/cli/wandb-sync.md). The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.\\n\\n### `LaunchError: Permission denied`\\n\\nIf you\\'re getting the error message `Launch Error: Permission denied`, you don\\'t have permissions to log to the project you\\'re trying to send runs to. This might be for a few different reasons.\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n-----------\\nSource ID: 03022aa8-05af-40ff-8818-634ae64fb3c1\\n\\nIf you want to export all of the data on a large run, you can use the `run.scan_history()` method. For more details see the [API Reference](https://docs.wandb.ai/ref/python/public-api).\\n\\n### Querying Multiple Runs\\n\\n<Tabs\\ndefaultValue=\"dataframes_csvs\"\\nvalues={[\\n{label: \\'Dataframes and CSVs\\', value: \\'dataframes_csvs\\'},\\n{label: \\'MongoDB Style\\', value: \\'mongoDB\\'},\\n]}>\\n<TabItem value=\"dataframes_csvs\">\\n\\nThis example script finds a project and outputs a CSV of runs with name, configs and summary stats. Replace `<entity>` and `<project>` with your W&B entity and the name of your project, respectively.\\n\\n```python\\nimport pandas as pd\\nimport wandb\\n\\napi = wandb.Api()\\nentity, project = \"<entity>\", \"<project>\"\\nruns = api.runs(entity + \"/\" + project)\\n\\nsummary_list, config_list, name_list = [], [], []\\nfor run in runs:\\n    # .summary contains output keys/values for\\n    # metrics such as accuracy.\\n    #  We call ._json_dict to omit large files\\n    summary_list.append(run.summary._json_dict)\\n\\n    # .config contains the hyperparameters.\\n    #  We remove special values that start with _.\\n    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\\n\\n    # .name is the human-readable name of the run.\\n    name_list.append(run.name)\\n\\nruns_df = pd.DataFrame(\\n    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\\n)\\n\\nruns_df.to_csv(\"project.csv\")\\n```\\n\\n  </TabItem>\\n  <TabItem value=\"mongoDB\">\\n\\nThe W&B API also provides a way for you to query across runs in a project with api.runs(). The most common use case is exporting runs data for custom analysis. The query interface is the same as the one [MongoDB uses](https://docs.mongodb.com/manual/reference/operator/query).\\n-----------\\nSource ID: 7c3e3c68-9eb6-4afe-9144-fd94ec6ddb09\\n\\nThese privileges enable you to effectively administer and maintain the W&B instance.\\n\\n| Permissions              | View-Only | Team Member | Team Admin | System Admin | \\n| ------------------------ | --------- | ----------- | ---------- | ------------ |\\n| Configure system settings|           |             |            | X            |\\n| Create/delete teams      |           |             |            | X            |\\n| View activity dashboard  |           |             |            | X            |\\n\\n### Team service account behavior\\n\\n* When you configure a team in your training environment, you can use a service account from that team to log runs in either of private or public projects within that team. Additionally, you can attribute those runs to a user if **WANDB_USERNAME** or **WANDB_USER_EMAIL** variable exists in your environment and the referenced user is part of that team.\\n* When you **do not** configure a team in your training environment and use a service account, the runs log to the named project within that service account\\'s parent team. In this case as well, you can attribute the runs to a user if **WANDB_USERNAME** or **WANDB_USER_EMAIL** variable exists in your environment and the referenced user is part of the service account\\'s parent team.\\n* A service account can not log runs to a private project in a team different from its parent team, but it can log runs to public projects in other teams.\\n\\n#### Add social badges to your intro\\n\\nIn your Intro, type `/` and choose Markdown and paste the markdown snippet that renders your badge. Once you convert it to WYSIWYG, you can resize it.\\n\\n [![Twitter: @weights_biases](https://img.shields.io/twitter/follow/weights\\\\_biases?style=social)](https://twitter.com/intent/follow?screen\\\\_name=weights\\\\_biases)\\n\\nFor example, to add a Twitter follow badge, add `[![Twitter: @weights_biase](https://img.shields.io/twitter/follow/weights_biases?style=social)](https://twitter.com/intent/follow?screen_name=weights_biases` replacing `weights_biases` with your Twitter username.\\n\\n## Team trials\\n\\nSee the [pricing page](https://wandb.ai/site/pricing) for more information on W&B plans.\\n-----------\\nSource ID: 15b22255-beec-4562-9d57-0470f8a4411c\\n\\nReplace `<entity>` and `<project>` with your W&B entity and the name of your project, respectively.\\n\\n```python\\nimport pandas as pd\\nimport wandb\\n\\napi = wandb.Api()\\nentity, project = \"<entity>\", \"<project>\"\\nruns = api.runs(entity + \"/\" + project)\\n\\nsummary_list, config_list, name_list = [], [], []\\nfor run in runs:\\n    # .summary contains the output keys/values\\n    #  for metrics such as accuracy.\\n    #  We call ._json_dict to omit large files\\n    summary_list.append(run.summary._json_dict)\\n\\n    # .config contains the hyperparameters.\\n    #  We remove special values that start with _.\\n    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\\n\\n    # .name is the human-readable name of the run.\\n    name_list.append(run.name)\\n\\nruns_df = pd.DataFrame(\\n    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\\n)\\n\\nruns_df.to_csv(\"project.csv\")\\n```\\n\\n### Get the starting time for a run\\n\\nThis code snippet retrieves the time at which the run was created.\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\n\\nrun = api.run(\"entity/project/run_id\")\\nstart_time = run.created_at\\n```\\n\\n### Upload files to a finished run\\n\\nThe code snippet below uploads a selected file to a finished run.\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\n\\nrun = api.run(\"entity/project/run_id\")\\nrun.upload_file(\"file_name.extension\")\\n```\\n\\n### Download a file from a run\\n\\nThis finds the file \"model-best.h5\" associated with with run ID uxte44z7 in the cifar project and saves it locally.\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\n\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nrun.file(\"model-best.h5\").download()\\n```\\n\\n### Download all files from a run\\n\\nThis finds all files associated with a run and saves them locally.\\n\\n```python\\nimport wandb\\n\\napi = wandb.Api()\\n\\nrun = api.run(\"<entity>/<project>/<run_id>\")\\nfor file in run.files():\\n    file.download()\\n```\\n\\n### Get runs from a specific sweep\\n\\nThis snippet downloads all the runs associated with a particular sweep.\\n-----------\\nSource ID: 806ba135-3076-48e0-93af-800b3554a0d4\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n\\n### Does W&B uses the `multiprocessing` library?\\n\\nYes, W&B uses the `multiprocessing` library. If you see an error message such as:\\n\\n```\\nAn attempt has been made to start a new process before the current process \\nhas finished its bootstrapping phase.\\n```\\n\\nThis might mean that you might need to add an entry point protection `if name == main`. Note that you would only need to add this entry point protection in case you\\'re trying to run W&B directly from the script.\\n-----------\\nSource ID: 2a3261a4-394e-463a-b49c-3f36161f57ea\\n\\nThe team mane must be unique. Team names can not be changed.\\n* **Team type** - Select either the **Work** or **Academic** button.\\n* **Company/Organization** - Provide the name of the team’s company or organization. Choose the dropdown menu to select a company or organization. You can optionally provide a new organization.\\n\\n:::info\\nOnly administrative accounts can create a team.\\n:::\\n\\n### Beta features\\n\\nWithin the **Beta Features** section you can optionally enable fun add-ons and sneak previews of new products in development. Select the toggle switch next to the beta feature you want to enable.\\n\\n### Alerts\\n\\nGet notified when your runs crash, finish, or set custom alerts with [wandb.alert()](../../runs/alert.md). Receive notifications either through Email or Slack. Toggle the switch next to the event type you want to receive alerts from.\\n\\n* **Runs finished**: whether a Weights and Biases run successfully finished.\\n* **Run crashed**: notification if a run has failed to finish.\\n\\nFor more information about how to set up and manage alerts, see [Send alerts with wandb.alert](../../runs/alert.md).\\n\\n### Personal GitHub integration\\n\\nConnect a personal Github account. To connect a Github account:\\n\\n1. Select the **Connect Github** button. This will redirect you to an open authorization (OAuth) page.\\n2. Select the organization to grant access in the **Organization access** section.\\n3. Select **Authorize** **wandb**.\\n\\n### Delete your account\\n\\nSelect the **Delete Account** button to delete your account.\\n\\n:::caution\\nAccount deletion can not be reversed.\\n:::\\n\\n### Storage\\n\\nThe **Storage** section describes the total memory usage the your account has consumed on the Weights and Biases servers. The default storage plan is 100GB. For more information about storage and pricing, see the [Pricing](https://wandb.ai/site/pricing) page.\\n-----------\\nSource ID: c633b770-26c7-4548-848d-39e4a50961a6\\n\\nThe type of the particular artifact selected in the left-hand column is highlighted.\\n\\nClick the Explode toggle to view all of the individual artifact versions and the specific runs that connect them.\\n\\n### Action History Audit tab\\n\\n![](/images/app_ui/action_history_audit_tab_1.png)\\n\\n![](/images/app_ui/action_history_audit_tab_2.png)\\n\\nThe action history audit tab shows all of the alias actions and membership changes for a Collection so you can audit the entire evolution of the resource.\\n\\n### Versions tab\\n\\n![](/images/app_ui/versions_tab.png)\\n\\nThe versions tab shows all versions of the artifact as well as columns for each of the numeric values of the Run History at the time of logging the version. This allows you to compare performance and quickly identify versions of interest.\\n\\n## Project Defaults\\n\\nYou can change your project default settings _manually_ in your User Settings at `/settings`.\\n\\n* **Default location to create new projects**: This is set to your own personal entity by default. By clicking on the dropdown, you can switch between your personal entity and the teams you\\'re part of.\\n* **Default project privacy in your personal account**: This is set to \\'Private\\' by default. In other words, your projects will be private and can only be accessed by you.\\n* **Enable code saving in your personal account**: This is turned off by default. You can turn this on to save the main script or notebook to W&B.\\n\\n:::note\\nThese settings can also be specified by passing arguments to \\n[`wandb.init`](../../../ref/python/init.md).\\n:::\\n\\n![](/images/app_ui/project_defaults.png)\\n\\n## Frequently Asked Questions\\n\\n### How can I delete projects?\\n\\nYou can delete your project by clicking the three dots on the right of the overview tab.\\n\\n![](/images/app_ui/howto_delete_project.gif)\\n\\nIf the project is empty (i.e. it has no runs), you can delete it by clicking the dropdown menu in the top-right and selecting \"Delete project\".\\n\\n![](/images/app_ui/howto_delete_project_2.png)\\n\\n### Where are the privacy settings for projects? How can I make a project public or private?\\n\\nClick the lock in the navigation bar at the top of the page to change project privacy settings. You can edit who can view or submit runs to your project. These settings include all runs and reports in the project.\\n-----------\\nSource ID: ccaab8d2-ef32-414a-a11c-589af192eaca\\n\\n### Tools for Collaboration\\n\\nUse W&B to organize complex machine learning projects. It\\'s easy to share a link to W&B, and you can use private teams to have everyone sending results to a shared project. We also support collaboration via reports— add interactive visualizations and describe your work in markdown. This is a great way to keep a work log, share findings with your supervisor, or present findings to your lab.\\n\\n## Dashboard FAQ\\n\\n### I accidentally deleted a panel in W&B, how do I undo it?\\n\\nTo undo a change in your workspace, click the \"undo\" button at the bottom of the page.\\n\\n![](/images/track/demo_how_to_undo_deleting_a_panel.gif)\\n\\n### How to sort by more than one column in the runs table?\\n\\nTo sort by more than 1 column in your runs table, click on \"Sort\" and then \"Add another field\".\\n\\n![](/images/track/sort_columns.gif)\\n-----------\\nSource ID: f6b316d4-ca23-4bab-a159-a4ed1fa75b25\\n\\nname_list.append(run.name)\\n\\nruns_df = pd.DataFrame(\\n    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\\n)\\n\\nruns_df.to_csv(\"project.csv\")\\n```\\n\\n  </TabItem>\\n  <TabItem value=\"mongoDB\">\\n\\nThe W&B API also provides a way for you to query across runs in a project with api.runs(). The most common use case is exporting runs data for custom analysis. The query interface is the same as the one [MongoDB uses](https://docs.mongodb.com/manual/reference/operator/query).\\n\\n```python\\nruns = api.runs(\\n    \"username/project\",\\n    {\"$or\": [{\"config.experiment_name\": \"foo\"}, {\"config.experiment_name\": \"bar\"}]},\\n)\\nprint(f\"Found {len(runs)} runs\")\\n```\\n\\n  </TabItem>\\n</Tabs>\\n\\nCalling `api.runs` returns a `Runs` object that is iterable and acts like a list. By default the object loads 50 runs at a time in sequence as required, but you can change the number loaded per page with the `per_page` keyword argument.\\n\\n`api.runs` also accepts an `order` keyword argument. The default order is `-created_at`, specify `+created_at` to get results in ascending order. You can also sort by config or summary values e.g. `summary.val_acc` or `config.experiment_name`\\n\\n### Error Handling\\n\\nIf errors occur while talking to W&B servers a `wandb.CommError` will be raised. The original exception can be introspected via the `exc` attribute.\\n\\n### Get the latest git commit through the API\\n\\nIn the UI, click on a run and then click the Overview tab on the run page to see the latest git commit. It\\'s also in the file `wandb-metadata.json` . Using the public API, you can get the git hash with `run.commit`.\\n\\n## Frequently Asked Questions\\n\\n### How do I export data to visualize in matplotlib or seaborn?\\n\\nCheck out our [API examples](../../ref/python/public-api/README.md) for some common export patterns. You can also click the download button on a custom plot or on the expanded runs table to download a CSV from your browser.\\n\\n### How do I get a run\\'s name and ID during a run?\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': True, 'feedback': \"The generated answer provides a clear and relevant solution to the user's query about transferring runs from a team project to a personal project using the W&B API. It includes a step-by-step guide and a sample code snippet, which aligns well with the retrieved context. However, it does not address the issue of being redirected to the billing page, which is a critical part of the user's problem.\"}}, 'model_latency': 64.1725161075592}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 2, 'completion_tokens': 716, 'prompt_tokens': 5155, 'total_tokens': 5871}, 'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 98, 'prompt_tokens': 5365, 'total_tokens': 5463}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='84d8480b-3e96-4df3-a46f-172d4d2576a9', project_id='ayut/llamaindex-weave', parent_id='4a72b196-7fe8-4392-9c7f-3d5d53bc4bd8', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='i6ViYYADIXKh9Bw5nIgU2WZQIM82sF2aMBrPNAgtLXg', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='9VXZSu0kVXEMgtOfwj9YEPN2I1LZqyBwKG3FzYxMKrw', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'QPl3QIGcbj06cGvsYqvMJvFMIlUPXyBrKehVVUGp4Vo'])}, id='e03bc36c-ac54-4f0a-96ee-e6b0e985ebdc', output={'model_output': {'response': 'To transfer your runs from a team project to a personal project in Weights & Biases (W&B), you can use the `wandb sync` command to sync your local runs to a new project. Since you are unable to access the runs via the GUI due to the billing page redirection, you can follow these steps:\\n\\n1. **Locate Your Local Runs**: Ensure you have the runs stored locally. They should be in a directory like `wandb/dryrun-folder-name`.\\n\\n2. **Sync Runs to Personal Project**:\\n   - Open your terminal.\\n   - Use the `wandb sync` command to sync the runs to your personal project. You need to specify the entity (your personal account) and the project name. Here is an example command:\\n     ```shell\\n     wandb sync --entity your-username --project your-personal-project wandb/dryrun-folder-name\\n     ```\\n   - Replace `your-username` with your W&B username and `your-personal-project` with the name of your personal project.\\n\\n3. **Verify the Sync**: After running the command, check your personal project on the W&B web app to ensure the runs have been successfully transferred.\\n\\nBy following these steps, you can move your runs from the team project to your personal project without needing to access the GUI. This method leverages the local storage of your runs and the `wandb sync` command to achieve the transfer.', 'context_str': 'Source ID: 6b334ba6-9049-45fc-bd89-bb47c3cb2fb2\\n\\n---\\ndisplayed_sidebar: default\\n---\\n\\n# Manage Runs\\n\\n### Move runs to a team\\n\\nOn the project page:\\n\\n1. Click the table tab to expand the runs table\\n2. Click the checkbox to select all runs\\n3. Click **Move**: the destination project can be in your personal account or any team that you\\'re a member of.\\n\\n![](/images/app_ui/demo_move_runs.gif)\\n\\n### Send new runs to a team\\n\\nIn your script, set the entity to your team. \"Entity\" just means your username or team name. Create an entity (personal account or team account) in the web app before sending runs there.\\n\\n```python\\nwandb.init(entity=\"example-team\")\\n```\\n\\nYour **default entity** is updated when you join a team. This means that on your [settings page](https://app.wandb.ai/settings), you\\'ll see that the default location to create a new project is now the team you\\'ve just joined. Here\\'s an example of what that [settings page](https://app.wandb.ai/settings) section looks like:\\n\\n![](/images/app_ui/send_new_runs_to_team.png)\\n-----------\\nSource ID: 81fe9292-033b-4f9a-9586-0239e0b3959b\\n\\n[](/images/experiments/sample_terminal_output.png)\\n\\nAnd once you\\'re ready, just run a sync command to send that folder to the cloud.\\n\\n```shell\\nwandb sync wandb/dryrun-folder-name\\n```\\n\\n![](/images/experiments/sample_terminal_output_cloud.png)\\n\\n### What is the difference between wandb.init modes?\\n\\nModes can be \"online\", \"offline\" or \"disabled\", and default to online.\\n\\n`online`(default): In this mode, the client sends data to the wandb server.\\n\\n`offline`: In this mode, instead of sending data to the wandb server, the client will store data on your local machine which can be later synced with the [`wandb sync`](../../ref/cli/wandb-sync.md) command.\\n\\n`disabled`: In this mode, the client returns mocked objects and prevents all network communication. The client will essentially act like a no-op. In other words, all logging is entirely disabled. However, stubs out of all the API methods are still callable. This is usually used in tests.\\n\\n### My run\\'s state is \"crashed\" on the UI but is still running on my machine. What do I do to get my data back?\\n\\nYou most likely lost connection to your machine while training. You can recover your data by running [`wandb sync [PATH_TO_RUN]`](../../ref/cli/wandb-sync.md). The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.\\n\\n### `LaunchError: Permission denied`\\n\\nIf you\\'re getting the error message `Launch Error: Permission denied`, you don\\'t have permissions to log to the project you\\'re trying to send runs to. This might be for a few different reasons.\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': True, 'feedback': \"The generated answer provides a clear and actionable method to transfer runs from a team project to a personal project using the `wandb sync` command. It correctly addresses the user's issue of being unable to access the GUI due to billing restrictions and offers a solution that leverages local storage and command-line tools. The steps are detailed and relevant to the user's query.\"}, 'compare_length_within_95_percentile': {'length_within_95_percentile': False}, 'check_code_block_presence': {'code_block_presense': True, 'has_code_block_gt': True, 'has_code_block_gen': True}, 'check_bullet_points_presence': {'bullet_points_presense': True, 'has_bullet_points_gt': True, 'has_bullet_points_gen': True}}, 'model_latency': 18.334946870803833}, exception=None, summary={'usage': {'gpt-4o-2024-05-13': {'requests': 2, 'completion_tokens': 386, 'prompt_tokens': 2882, 'total_tokens': 3268}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='b643803b-0d26-4835-b06c-1e6af765037a', project_id='ayut/llamaindex-weave', parent_id='3e851ecb-28f6-4bce-941c-ab60ddd90905', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='zTMb0xzdwy2RUNETg5mD2ybdF0F899rYgIJUBs574ek', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='S6Ns3HTYXGPLBqFxPRmUaxXH6UrfujrE8kL7bN6I8V8', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'AvYBAU93iLfXj0wJGt4bmRUi6c4uIa3zpYqopwHHhJg'])}, id='14fbcf47-6e21-481e-9507-5acb1a2931be', output={'model_output': {'response': 'To organize/name/group your W&B runs when doing hyperparameter tuning with cross-validation, you can use the following approach:\\n\\n1. **Define the Sweep:** Create a dictionary or a YAML file that specifies the parameters to search through, the search strategy, the optimization metric, etc. This is where you define the hyperparameters to sweep over and the type of sweep to use.\\n\\n2. **Initialize the Sweep:** Use the `wandb.sweep(sweep_config)` command to initialize the sweep.\\n\\n3. **Run the Sweep Agent:** Use the `wandb.agent(sweep_id, function=train)` command to run the sweep agent.\\n\\nFor each run, you can log the average score across all the runs that are part of a CV set using `wandb.log({\"average_score\": average_score})`. \\n\\nTo visualize the results, W&B provides automatic generation of useful plots like the Parallel Coordinates Plot and the Hyperparameter Importance Plot. The Parallel Coordinates Plot maps hyperparameter values to model metrics, which is useful for honing in on combinations of hyperparameters that led to the best model performance. The Hyperparameter Importance Plot shows which hyperparameter values had the biggest impact on your metrics.\\n\\nTo see the best CV score across the whole hyperparam sweep, you can use the W&B dashboard to sort your runs by the metric of interest and find the run with the best score. \\n\\nRemember, both the sweep and the run must be in the same project. Therefore, the name you provide when you initialize W&B must match the name of the project you provide when you initialize a sweep.', 'context_str': 'Source ID: 504c1a19-8b4e-452a-a8a5-ce9d5d90deb5\\n\\n```python\\n# Log the ROC curve to W&B\\nvalYpreds_2d = np.array([1 - valYpreds, valYpreds])  # W&B expects a 2d array\\ny_val_arr = y_val.values\\nd = 0\\nwhile len(valYpreds_2d.T) > 10000:\\n    d += 1\\n    valYpreds_2d = valYpreds_2d[::1, ::d]\\n    y_val_arr = y_val_arr[::d]\\n\\nrun.log(\\n    {\\n        \"ROC_Curve\": wandb.plot.roc_curve(\\n            y_val_arr,\\n            valYpreds_2d.T,\\n            labels=[\"no_default\", \"loan_default\"],\\n            classes_to_plot=[1],\\n        )\\n    }\\n)\\n```\\n\\n#### Finish the W&B Run\\n\\n\\n```python\\nrun.finish()\\n```\\n\\nNow that we\\'ve trained a single model, lets try and optimize its performance by running a Hyperparameter Sweep.\\n\\n# HyperParameter Sweep\\n\\nWeights and Biases also enables you to do hyperparameter sweeps, either with our own [Sweeps functionality](https://docs.wandb.ai/guides/sweeps/python-api) or with our [Ray Tune integration](https://docs.wandb.ai/guides/sweeps/advanced-sweeps/ray-tune). See [our docs](https://docs.wandb.ai/guides/sweeps/python-api) for a full guide of how to use more advanced hyperparameter sweeps options.\\n\\n**[Click Here](https://wandb.ai/morgan/credit_score_sweeps/sweeps/iuppbs45)** to check out the results of a 1000 run sweep generated using this notebook\\n\\n#### Define the Sweep Config\\nFirst we define the hyperparameters to sweep over as well as the type of sweep to use, we\\'ll do a random search over the learning_rate, gamma, min_child_weights and easrly_stopping_rounds\\n-----------\\nSource ID: 23e4ce89-93b0-48da-89bb-dbf39a4ae0aa\\n\\n[credit_scorecard](/images/tutorials/credit_scorecard/credit_scorecard.png)\\n\\n**Run a Hyperparameter Sweep to Find the Best HyperParameters**\\n\\nWeights and Biases also enables you to do hyperparameter sweeps, either with our own [Sweeps functionality](https://docs.wandb.ai/guides/sweeps) or with our [Ray Tune integration](https://docs.wandb.ai/guides/sweeps/advanced-sweeps/ray-tune). See our docs for a full guide of how to use more advanced hyperparameter sweeps options.\\n\\n![credit_scorecard_2](/images/tutorials/credit_scorecard/credit_scorecard_2.png)\\n\\n# Setup\\n\\n\\n```bash\\n!pip install -qq wandb>=0.13.10 dill\\n!pip install -qq xgboost>=1.7.4 scikit-learn>=1.2.1\\n```\\n-----------\\nSource ID: 2a9bddd7-db13-4cbc-9345-6620332bcf6f\\n\\n---\\nslug: /guides/sweeps\\ndescription: Hyperparameter search and model optimization with W&B Sweeps\\ndisplayed_sidebar: default\\n---\\nimport { CTAButtons } from \\'@site/src/components/CTAButtons/CTAButtons.tsx\\';\\n\\n\\n# Tune Hyperparameters\\n\\n<CTAButtons productLink=\"https://wandb.ai/stacey/deep-drive/workspace?workspace=user-lavanyashukla\" colabLink=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb\"/>\\n\\n<head>\\n  <title>Tune Hyperparameters with Sweeps</title>\\n</head>\\n\\nUse W&B Sweeps to automate hyperparameter search and visualize rich, interactive experiment tracking. Pick from popular search methods such as Bayesian, grid search, and random to search the hyperparameter space. Scale and parallelize sweep across one or more machines.\\n\\n![Draw insights from large hyperparameter tuning experiments with interactive dashboards.](/images/sweeps/intro_what_it_is.png)\\n\\n### How it works\\nCreate a sweep with two [W&B CLI](../../ref/cli/README.md) commands:\\n\\n\\n1. Initialize a sweep\\n\\n```bash\\nwandb sweep --project <propject-name> <path-to-config file>\\n```\\n\\n2. Start the sweep agent\\n\\n```bash\\nwandb agent <sweep-ID>\\n```\\n\\n:::tip\\nThe preceding code snippet, and the colab linked on this page, show how to initialize and create a sweep with wht W&B CLI. See the Sweeps [Walkthrough](./walkthrough.md) for a step-by-step outline of the W&B Python SDK commands to use to define a sweep configuration, initialize a sweep, and start a sweep.\\n:::\\n-----------\\nSource ID: 817cddac-932e-45dd-874c-1fe3306a7e8f\\n\\n```python\\nwandb.agent(sweep_id, train, count=5)\\n```\\n\\n# 👀 Visualize Sweep Results\\n\\n\\n\\n## 🔀 Parallel Coordinates Plot\\nThis plot maps hyperparameter values to model metrics. It’s useful for honing in on combinations of hyperparameters that led to the best model performance.\\n\\n![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png)\\n\\n\\n## 📊 Hyperparameter Importance Plot\\nThe hyperparameter importance plot surfaces which hyperparameters were the best predictors of your metrics.\\nWe report feature importance (from a random forest model) and correlation (implicitly a linear model).\\n\\n![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png)\\n\\nThese visualizations can help you save both time and resources running expensive hyperparameter optimizations by honing in on the parameters (and value ranges) that are the most important, and thereby worthy of further exploration.\\n\\n\\n# 🧤 Get your hands dirty with sweeps\\n\\nWe created a simple training script and [a few flavors of sweep configs](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion) for you to play with. We highly encourage you to give these a try.\\n\\nThat repo also has examples to help you try more advanced sweep features like [Bayesian Hyperband](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla), and [Hyperopt](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla).\\n-----------\\nSource ID: 674d1c6b-4960-4659-a73c-7d0b9fc75be2\\n\\n```python\\nwandb.agent(sweep_id, train, count=25)\\n```\\n\\n## Visualize your results\\n\\n\\nNow that your sweep is finished, it\\'s time to look at the results.\\n\\nWeights & Biases will generate a number of useful plots for you automatically.\\n\\n### Parallel coordinates plot\\n\\nThis plot maps hyperparameter values to model metrics. It’s useful for honing in on combinations of hyperparameters that led to the best model performance.\\n\\nThis plot seems to indicate that using a tree as our learner slightly,\\nbut not mind-blowingly,\\noutperforms using a simple linear model as our learner.\\n\\n![sweeps_xgboost](/images/tutorials/xgboost_sweeps/sweeps_xgboost2.png)\\n\\n### Hyperparameter importance plot\\n\\nThe hyperparameter importance plot shows which hyperparameter values had the biggest impact\\non your metrics.\\n\\nWe report both the correlation (treating it as a linear predictor)\\nand the feature importance (after training a random forest on your results)\\nso you can see which parameters had the biggest effect\\nand whether that effect was positive or negative.\\n\\nReading this chart, we see quantitative confirmation \\nof the trend we noticed in the parallel coordinates chart above:\\nthe largest impact on validation accuracy came from the choice of\\nlearner, and the `gblinear` learners were generally worse than `gbtree` learners.\\n\\n![sweeps_xgboost](/images/tutorials/xgboost_sweeps/sweeps_xgboost3.png)\\n\\nThese visualizations can help you save both time and resources running expensive hyperparameter optimizations by honing in on the parameters (and value ranges) that are the most important, and thereby worthy of further exploration.\\n-----------\\nSource ID: 9b400c25-66c4-4f66-861e-c7a19d3419f7\\n\\n## Set up your training code\\nDefine a training function that takes in hyperparameter values from `wandb.config` and uses them to train a model and return metrics.\\n\\nOptionally provide the name of the project where you want the output of the W&B Run to be stored (project parameter in [`wandb.init`](../../ref/python/init.md)). If the project is not specified, the run is put in an \"Uncategorized\" project.\\n\\n:::tip\\nBoth the sweep and the run must be in the same project. Therefore, the name you provide when you initialize W&B must match the name of the project you provide when you initialize a sweep.\\n:::\\n\\n```python\\n# 1: Define objective/training function\\ndef objective(config):\\n    score = config.x**3 + config.y\\n    return score\\n\\n\\ndef main():\\n    wandb.init(project=\"my-first-sweep\")\\n    score = objective(wandb.config)\\n    wandb.log({\"score\": score})\\n```\\n\\n## Define the search space with a sweep configuration\\nWithin a dictionary, specify what hyperparameters you want to sweep over and. For more information about configuration options, see [Define sweep configuration](./define-sweep-configuration.md).\\n\\nThe proceeding example demonstrates a sweep configuration that uses a random search (`\\'method\\':\\'random\\'`). The sweep will randomly select a random set of values listed in the configuration for the batch size, epoch, and the learning rate.\\n\\nThroughout the sweeps, W&B will maximize the metric specified in the metric key (`metric`). In the following example, W&B will maximize (`\\'goal\\':\\'maximize\\'`) the validation accuracy (`\\'val_acc\\'`).\\n-----------\\nSource ID: 2157d488-b638-4266-aa1e-4bb76f5ed2e0\\n\\n```python\\nwandb.finish()\\n```\\n\\n# Visualize Results\\n\\nClick on the **project page** link above to see your results automatically visualized.\\n\\n<img src=\"https://imgur.com/S6lwSig.png\" alt=\"Viz\" />\\n\\n\\n# Sweep 101\\n\\nUse Weights & Biases Sweeps to automate hyperparameter optimization and explore the space of possible models.\\n\\n## [Check out Hyperparameter Optimization with XGBoost  using W&B Sweep $\\\\rightarrow$](http://wandb.me/xgb-colab)\\n\\nRunning a hyperparameter sweep with Weights & Biases is very easy. There are just 3 simple steps:\\n\\n1. **Define the sweep:** We do this by creating a dictionary or a [YAML file](https://docs.wandb.com/library/sweeps/configuration) that specifies the parameters to search through, the search strategy, the optimization metric et all.\\n\\n2. **Initialize the sweep:** \\n`sweep_id = wandb.sweep(sweep_config)`\\n\\n3. **Run the sweep agent:** \\n`wandb.agent(sweep_id, function=train)`\\n\\nAnd voila! That\\'s all there is to running a hyperparameter sweep!\\n\\n<img src=\"https://imgur.com/SVtMfa2.png\" alt=\"Sweep Result\" />\\n-----------\\nSource ID: 34d8757b-191d-4d75-bc83-f62653e8017c\\n\\n```python\\n!pip install wandb -qU\\n```\\n\\n\\n```python\\n\\nimport wandb\\nwandb.login()\\n```\\n\\n## 1. Define the Sweep\\n\\nWeights & Biases sweeps give you powerful levers to configure your sweeps exactly how you want them, with just a few lines of code. The sweeps config can be defined as\\n[a dictionary or a YAML file](https://docs.wandb.ai/guides/sweeps/configuration).\\n\\nLet\\'s walk through some of them together:\\n*   **Metric** – This is the metric the sweeps are attempting to optimize. Metrics can take a `name` (this metric should be logged by your training script) and a `goal` (`maximize` or `minimize`). \\n*   **Search Strategy** – Specified using the `\"method\"` key. We support several different search strategies with sweeps. \\n  *   **Grid Search** – Iterates over every combination of hyperparameter values.\\n  *   **Random Search** – Iterates over randomly chosen combinations of hyperparameter values.\\n  *   **Bayesian Search** – Creates a probabilistic model that maps hyperparameters to probability of a metric score, and chooses parameters with high probability of improving the metric. The objective of Bayesian optimization is to spend more time in picking the hyperparameter values, but in doing so trying out fewer hyperparameter values.\\n*   **Parameters** – A dictionary containing the hyperparameter names, and discrete values, a range, or distributions from which to pull their values on each iteration.\\n\\nYou can find a list of all configuration options [here](https://docs.wandb.com/library/sweeps/configuration).\\n-----------\\nSource ID: b6436ddb-a96d-4e50-a582-a8215694d031\\n\\n---\\ndescription: Compare results across machine learning experiments\\ndisplayed_sidebar: default\\n---\\n\\n# Parallel Coordinates\\n\\nParallel coordinates charts summarize the relationship between large numbers of hyperparameters and model metrics at a glance.\\n\\n![](/images/app_ui/parallel_coordinates.gif)\\n\\n* **Axes**: Different hyperparameters from [`wandb.config`](../../../../guides/track/config.md) and metrics from [`wandb.log`](../../../../guides/track/log/intro.md).\\n* **Lines**: Each line represents a single run. Mouse over a line to see a tooltip with details about the run. All lines that match the current filters will be shown, but if you turn off the eye, lines will be grayed out.\\n\\n## Panel Settings\\n\\nConfigure these features in the panel settings— click the edit button in the upper right corner of the panel.\\n\\n* **Tooltip**: On hover, a legend shows up with info on each run\\n* **Titles**: Edit the axis titles to be more readable\\n* **Gradient**: Customize the gradient to be any color range you like\\n* **Log scale**: Each axis can be set to view on a log scale independently\\n* **Flip axis**: Switch the axis direction— this is useful when you have both accuracy and loss as columns\\n\\n[See it live →](https://app.wandb.ai/example-team/sweep-demo/reports/Zoom-in-on-Parallel-Coordinates-Charts--Vmlldzo5MTQ4Nw)\\n-----------\\nSource ID: 016e8fdd-0be2-4046-923c-0fc8d344212d\\n\\n- Capture the best eval metric in `wandb.summary` when `define_metric=True` (default).\\n\\n### Arguments\\n`log_model`: (boolean) if True save and upload the model to Weights & Biases Artifacts\\n\\n`log_feature_importance`: (boolean) if True log a feature importance bar plot\\n\\n`importance_type`: (str) one of {weight, gain, cover, total_gain, total_cover} for tree model. weight for linear model.\\n\\n`define_metric`: (boolean) if True (default) capture model performance at the best step, instead of the last step, of training in your `wandb.summary`.\\n\\n\\nYou can find the source code for WandbCallback [here](https://github.com/wandb/wandb/blob/main/wandb/integration/xgboost/xgboost.py)\\n\\n:::info\\nLooking for more working code examples? Check out [our repository of examples on GitHub](https://github.com/wandb/examples/tree/master/examples/boosting-algorithms) or try out a [Colab notebook](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/boosting/Credit\\\\_Scorecards\\\\_with\\\\_XGBoost\\\\_and\\\\_W%26B.ipynb)\\n:::\\n\\n## Tuning your hyperparameters with Sweeps\\n\\nAttaining the maximum performance out of models requires tuning hyperparameters, like tree depth and learning rate. Weights & Biases includes [Sweeps](../sweeps/), a powerful toolkit for configuring, orchestrating, and analyzing large hyperparameter testing experiments.\\n\\n:::info\\nTo learn more about these tools and see an example of how to use Sweeps with XGBoost, check out [this interactive Colab notebook](http://wandb.me/xgb-sweeps-colab) or try this XGBoost & Sweeps [python script here](https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-xgboost/xgboost\\\\_tune.py)\\n:::\\n\\n![tl;dr: trees outperform linear learners on this classification dataset.](/images/integrations/xgboost_sweeps_example.png)\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': False, 'feedback': 'The generated answer provides a general approach to organizing W&B runs during hyperparameter tuning with cross-validation. It mentions defining the sweep, initializing it, and running the sweep agent, which are relevant steps. However, it lacks specific details on using W&B features like projects, groups, tags, and notes to organize runs effectively. It also does not address how to group runs by hyperparameter configuration or how to manually calculate and log custom metrics for average and best CV scores.'}}, 'model_latency': 36.19626498222351}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 1, 'completion_tokens': 317, 'prompt_tokens': 3771, 'total_tokens': 4088}, 'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 115, 'prompt_tokens': 4947, 'total_tokens': 5062}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/Evaluation.predict_and_score:NmwfShfFmgAhDGLXrF6Xn02T9MIAsCXBUcifCjyKpOM', trace_id='b643803b-0d26-4835-b06c-1e6af765037a', project_id='ayut/llamaindex-weave', parent_id='3e851ecb-28f6-4bce-941c-ab60ddd90905', inputs={'self': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset-evaluation', digest='zTMb0xzdwy2RUNETg5mD2ybdF0F899rYgIJUBs574ek', extra=[]), 'model': ObjectRef(entity='ayut', project='llamaindex-weave', name='SimpleRAGPipeline', digest='S6Ns3HTYXGPLBqFxPRmUaxXH6UrfujrE8kL7bN6I8V8', extra=[]), 'example': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'qmDvdZkKvs8uBQodEPfTWNBIolWxcJGTeYLMXd6E0pc'])}, id='f5e092ea-f903-44d2-83bf-ee7fc8b27c63', output={'model_output': {'response': 'To switch between different W&B accounts on the same machine, you can use different API keys. You can store both API keys in a file on your machine and add code to your repos to switch between them. Here is an example:\\n\\n```python\\nif os.path.exists(\"~/keys.json\"):\\n    os.environ[\"WANDB_API_KEY\"] = json.loads(\"~/keys.json\")[\"work_account\"]\\n```\\n\\nIn this example, the API keys are stored in a file named `keys.json` in your home directory. The key for your work account is stored under the key `\"work_account\"` in the JSON file. You can add a similar line for your personal account, like so:\\n\\n```python\\nif os.path.exists(\"~/keys.json\"):\\n    os.environ[\"WANDB_API_KEY\"] = json.loads(\"~/keys.json\")[\"personal_account\"]\\n```\\n\\nYou can switch between accounts by changing the key used in the `json.loads()` function. This way, you can avoid checking your secret key into a source control system, which is potentially dangerous.\\n\\nYou can find your API keys in your settings on the W&B website. Remember to store your API keys securely and never check them into version control.', 'context_str': 'Source ID: c3825f38-8719-4ed1-9b69-c8a89bc74170\\n\\nArguments passed to `wandb.init` take precedence over the environment. You could call `wandb.init(dir=os.getenv(\"WANDB_DIR\", my_default_override))` if you want to have a default other than the system default when the environment variable isn\\'t set.\\n\\n### Turn off logging\\n\\nThe command `wandb offline` sets an environment variable, `WANDB_MODE=offline` . This stops any data from syncing from your machine to the remote wandb server. If you have multiple projects, they will all stop syncing logged data to W&B servers.\\n\\nTo quiet the warning messages:\\n\\n```python\\nimport logging\\n\\nlogger = logging.getLogger(\"wandb\")\\nlogger.setLevel(logging.WARNING)\\n```\\n\\n### Multiple wandb users on shared machines\\n\\nIf you\\'re using a shared machine and another person is a wandb user, it\\'s easy to make sure your runs are always logged to the proper account. Set the WANDB\\\\_API\\\\_KEY environment variable to authenticate. If you source it in your env, when you log in you\\'ll have the right credentials, or you can set the environment variable from your script.\\n\\nRun this command `export WANDB_API_KEY=X` where X is your API key. When you\\'re logged in, you can find your API key at [wandb.ai/authorize](https://app.wandb.ai/authorize).\\n-----------\\nSource ID: e886d6e3-d551-460c-8769-6d223c395c68\\n\\n# wandb login\\n\\n**Usage**\\n\\n`wandb login [OPTIONS] [KEY]...`\\n\\n**Summary**\\n\\nLogin to Weights & Biases\\n\\n**Options**\\n\\n| **Option** | **Description** |\\n| :--- | :--- |\\n| --cloud | Login to the cloud instead of local |\\n| --host | Login to a specific instance of W&B |\\n| --relogin | Force relogin if already logged in. |\\n| --anonymously | Log in anonymously |\\n| --verify | Verify login credentials |\\n-----------\\nSource ID: 840d9bea-5310-4a47-892d-cba238d04565\\n\\nSelect service and click create to add a service account.\\n\\n![Create a service account on your team settings page for automated jobs](/images/technical_faq/what_is_service_account.png)\\n\\n### How can I rotate or revoke access?\\n\\nBoth personal and service account keys can be rotated or revoked. Simply create a new API Key or Service Account user and reconfigure your scripts to use the new key. Once all processes are reconfigured, you can remove the old API key from your profile or team.\\n\\n### How do I switch between accounts on the same machine?\\n\\nIf you have two W&B accounts working from the same machine, you\\'ll need a nice way to switch between your different API keys. You can store both API keys in a file on your machine then add code like the following to your repos. This is to avoid checking your secret key into a source control system, which is potentially dangerous.\\n\\n```python\\nif os.path.exists(\"~/keys.json\"):\\n    os.environ[\"WANDB_API_KEY\"] = json.loads(\"~/keys.json\")[\"work_account\"]\\n```\\n\\n### Is there a dark mode?\\n\\nYes. To enable dark mode:\\n\\n1. Navigate to your account settings at [https://wandb.ai/settings](https://wandb.ai/settings).\\n2. Scroll to the **Beta Features** section.\\n3. Toggle the **Night mode** option.\\n\\n### Can I disable wandb when testing my code?\\n\\nBy using `wandb.init(mode=\"disabled\")` or by setting `WANDB_MODE=disabled` you will make wandb act like a NOOP which is perfect for testing your code.\\n\\n**Note**: Setting `wandb.init(mode=“disabled”)` does not prevent `wandb` from saving artifacts to `WANDB_CACHE_DIR`\\n-----------\\nSource ID: bffb5ebf-f95b-4554-922b-23222e594cc9\\n\\n6. **Tools for collaboration**: Use W&B to organize complex machine learning projects. It\\'s easy to share a link to W&B, and you can use private teams to have everyone send results to a shared project. We also support collaboration via reports— add interactive visualizations and describe your work in markdown. This is a great way to keep a work log, share findings with your supervisor, or present findings to your lab.\\n\\nGet started with a [free account](http://app.wandb.ai)\\n\\n### How does wandb stream logs and writes to disk?\\n\\nW&B queues in memory but also [write the events to disk](https://github.com/wandb/wandb/blob/7cc4dd311f3cdba8a740be0dc8903075250a914e/wandb/sdk/internal/datastore.py) asynchronously to handle failures and for the `WANDB_MODE=offline` case where you can sync the data after it\\'s been logged.\\n\\nIn your terminal, you can see a path to the local run directory. This directory will contain a `.wandb` file that is the datastore above. If you\\'re also logging images, we write them to `media/images` in that directory before uploading them to cloud storage.\\n\\n### How to get multiple charts with different selected runs?\\n\\nWith wandb reports the procedure is as follows:\\n\\n* Have multiple panel grids.\\n* Add filters to filter the run sets of each panel grid. This will help in selecting the runs that you want to portray in the respective panels.\\n* Create the charts you want in the panel grids.\\n\\n### How is access to the API controlled?\\n\\nFor simplicity, W&B uses API keys for authorization when accessing the API. You can find your API keys in your [settings](https://app.wandb.ai/settings). Your API key should be stored securely and never checked into version control. In addition to personal API keys, you can add Service Account users to your team.\\n\\n### Does W&B support SSO for Multi-tenant?\\n\\nYes, W&B supports setting up Single Sign-On (SSO) for the Multi-tenant offering via Auth0. W&B support SSO integration with any OIDC compliant identity provider(ex: Okta, AzureAD etc.).\\n-----------\\nSource ID: fe4f259a-6eac-4e21-8975-458f99930b43\\n\\nYou can find your API keys in your [settings](https://app.wandb.ai/settings). Your API key should be stored securely and never checked into version control. In addition to personal API keys, you can add Service Account users to your team.\\n\\n### Does W&B support SSO for Multi-tenant?\\n\\nYes, W&B supports setting up Single Sign-On (SSO) for the Multi-tenant offering via Auth0. W&B support SSO integration with any OIDC compliant identity provider(ex: Okta, AzureAD etc.). If you have an OIDC provider, please follow the steps below:\\n\\n* Create a `Single Page Application (SPA)` on your Identity Provider.\\n* Set `grant_type` to `implicit` flow.\\n* Set the callback URI to `https://wandb.auth0.com/login/callback`.\\n\\n**What W&B needs?**\\n\\nOnce you have the above setup, contact your customer success manager(CSM) and let us know the `Client ID` and `Issuer URL` associated with the application.\\n\\nWe\\'ll then set up an Auth0 connection with the above details and enable SSO.\\n\\n### What is a service account, and why is it useful?\\n\\nA service account (Enterprise-only feature) is an API key that has permissions to write to your team, but is not associated with a particular user. Among other things, service accounts are useful for tracking automated jobs logged to wandb, like periodic retraining, nightly builds, and so on. If you\\'d like, you can associate a username with one of these machine-launched runs with the [environment variable](../track/environment-variables.md) `WANDB_USERNAME`.\\n\\nRefer to [Team Service Account Behavior](../app/features/teams.md#team-service-account-behavior) for more information.\\n\\nYou can get the API key in your Team Settings page `/teams/<your-team-name>` where you invite new team members. Select service and click create to add a service account.\\n\\n![Create a service account on your team settings page for automated jobs](/images/technical_faq/what_is_service_account.png)\\n\\n### How can I rotate or revoke access?\\n\\nBoth personal and service account keys can be rotated or revoked. Simply create a new API Key or Service Account user and reconfigure your scripts to use the new key. Once all processes are reconfigured, you can remove the old API key from your profile or team.\\n-----------\\nSource ID: 81fe9292-033b-4f9a-9586-0239e0b3959b\\n\\n[](/images/experiments/sample_terminal_output.png)\\n\\nAnd once you\\'re ready, just run a sync command to send that folder to the cloud.\\n\\n```shell\\nwandb sync wandb/dryrun-folder-name\\n```\\n\\n![](/images/experiments/sample_terminal_output_cloud.png)\\n\\n### What is the difference between wandb.init modes?\\n\\nModes can be \"online\", \"offline\" or \"disabled\", and default to online.\\n\\n`online`(default): In this mode, the client sends data to the wandb server.\\n\\n`offline`: In this mode, instead of sending data to the wandb server, the client will store data on your local machine which can be later synced with the [`wandb sync`](../../ref/cli/wandb-sync.md) command.\\n\\n`disabled`: In this mode, the client returns mocked objects and prevents all network communication. The client will essentially act like a no-op. In other words, all logging is entirely disabled. However, stubs out of all the API methods are still callable. This is usually used in tests.\\n\\n### My run\\'s state is \"crashed\" on the UI but is still running on my machine. What do I do to get my data back?\\n\\nYou most likely lost connection to your machine while training. You can recover your data by running [`wandb sync [PATH_TO_RUN]`](../../ref/cli/wandb-sync.md). The path to your run will be a folder in your `wandb` directory corresponding to the Run ID of the run in progress.\\n\\n### `LaunchError: Permission denied`\\n\\nIf you\\'re getting the error message `Launch Error: Permission denied`, you don\\'t have permissions to log to the project you\\'re trying to send runs to. This might be for a few different reasons.\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n-----------\\nSource ID: 806ba135-3076-48e0-93af-800b3554a0d4\\n\\n1. You aren\\'t logged in on this machine. Run [`wandb login`](../../ref/cli/wandb-login.md) on the command line.\\n2. You\\'ve set an entity that doesn\\'t exist. \"Entity\" should be your username or the name of an existing team. If you need to create a team, go to our [Subscriptions page](https://app.wandb.ai/billing).\\n3. You don\\'t have project permissions. Ask the creator of the project to set the privacy to **Open** so you can log runs to this project.\\n\\n### Does W&B uses the `multiprocessing` library?\\n\\nYes, W&B uses the `multiprocessing` library. If you see an error message such as:\\n\\n```\\nAn attempt has been made to start a new process before the current process \\nhas finished its bootstrapping phase.\\n```\\n\\nThis might mean that you might need to add an entry point protection `if name == main`. Note that you would only need to add this entry point protection in case you\\'re trying to run W&B directly from the script.\\n-----------\\nSource ID: ef872964-4438-4ada-a626-d079e7423440\\n\\n|\\n| **WANDB\\\\_USER\\\\_EMAIL**      | The email of a member of your team associated with the run. This can be used along with a service account API key to enable attribution of automated runs to members of your team.            |\\n\\n## Singularity Environments\\n\\nIf you\\'re running containers in [Singularity](https://singularity.lbl.gov/index.html) you can pass environment variables by pre-pending the above variables with **SINGULARITYENV\\\\_**. More details about Singularity environment variables can be found [here](https://singularity.lbl.gov/docs-environment-metadata#environment).\\n\\n## Running on AWS\\n\\nIf you\\'re running batch jobs in AWS, it\\'s easy to authenticate your machines with your W&B credentials. Get your API key from your [settings page](https://app.wandb.ai/settings), and set the WANDB\\\\_API\\\\_KEY environment variable in the [AWS batch job spec](https://docs.aws.amazon.com/batch/latest/userguide/job\\\\_definition\\\\_parameters.html#parameters).\\n\\n## Common Questions\\n\\n### Automated runs and service accounts\\n\\nIf you have automated tests or internal tools that launch runs logging to W&B, create a **Service Account** on your team settings page. This will allow you to use a service API key for your automated jobs. If you want to attribute service account jobs to a specific user, you can use the **WANDB\\\\_USERNAME** or **WANDB\\\\_USER\\\\_EMAIL** environment variables.\\n\\n![Create a service account on your team settings page for automated jobs](/images/track/common_questions_automate_runs.png)\\n\\nThis is useful for continuous integration and tools like TravisCI or CircleCI if you\\'re setting up automated unit tests.\\n\\n### Do environment variables overwrite the parameters passed to wandb.init()?\\n\\nArguments passed to `wandb.init` take precedence over the environment. You could call `wandb.init(dir=os.getenv(\"WANDB_DIR\", my_default_override))` if you want to have a default other than the system default when the environment variable isn\\'t set.\\n\\n### Turn off logging\\n\\nThe command `wandb offline` sets an environment variable, `WANDB_MODE=offline` . This stops any data from syncing from your machine to the remote wandb server. If you have multiple projects, they will all stop syncing logged data to W&B servers.\\n-----------\\nSource ID: 5ae39c9b-9b4b-4dbc-873e-3dbcc3829e33\\n\\nCalling `wandb.log` more than a few times per second. This is due to a small latency added to the training loop every time `wandb.log` is called.\\n\\n:::info\\nIs frequent logging slowing your training runs down? Check out [this Colab](http://wandb.me/log-hf-colab) for methods to get better performance by changing your logging strategy.\\n:::\\n\\nW&B does not assert any limits beyond rate limiting. The W&B Python SDK automatically completes an exponential \"backoff\" and \"retry\" requests that exceed limits. W&B Python SDK responds with a “Network failure” on the command line. For unpaid accounts, W&B may reach out in extreme cases where usage exceeds reasonable thresholds.\\n\\n## Rate limits\\n\\nW&B SaaS Cloud API implements a rate limit to maintain system integrity and ensure availability. This measure prevents any single user from monopolizing available resources in the shared infrastructure, ensuring that the service remains accessible to all users. You may encounter a lower rate limit for a variety of reasons. \\n\\n:::note\\nRate limits are subject to change.\\n:::\\n\\nThe `wandb.log` calls in your script utilize a metrics logging API to log your training data to W&B. This API is engaged through either online or [offline syncing](../../ref/cli/wandb-sync.md). In either case, it imposes a rate limit quota limit in a rolling time window. This includes limits on total request size and request rate, where latter refers to the number of requests in a time duration. \\n\\nRate limits are applied to each W&B project. So if you have 3 projects in a team, each project has its own rate limit quota. Users on [Teams and Enterprise plans](https://wandb.ai/site/pricing) have higher rate limits than those on the Free plan.\\n-----------\\nSource ID: ecd590a2-7874-45a4-99cd-f539c135e86b\\n\\n```toml\\n[project]\\nname = \"my_awesome_lib\"\\nversion = \"0.1.0\"\\ndependencies = [\\n    \"torch\",\\n    \"sklearn\"\\n]\\n\\n[project.optional-dependencies]\\ndev = [\\n    \"wandb\"\\n]\\n```\\n\\n### User Login\\n\\nThere are a few ways for your users to log in to W&B:\\n\\n<Tabs\\n  defaultValue=\"bash\"\\n  values={[\\n    {label: \\'Bash\\', value: \\'bash\\'},\\n    {label: \\'Notebook\\', value: \\'notebook\\'},\\n    {label: \\'Environment Variable\\', value: \\'environment\\'},\\n  ]}>\\n  <TabItem value=\"bash\">\\nLog into W&B with a bash command in a terminal\\n\\n```bash\\nwandb login $MY_WANDB_KEY\\n```\\n  </TabItem>\\n  <TabItem value=\"notebook\">\\nIf they\\'re in a Jupyter or Colab notebook, log into W&B like so\\n\\n```python\\nimport wandb\\nwandb.login\\n```\\n  </TabItem>\\n  <TabItem value=\"environment\">\\n\\nSet a [W&B environment variable](../track/environment-variables.md) for the API key\\n\\n```bash\\nexport WANDB_API_KEY=$YOUR_API_KEY\\n```\\n\\nor\\n\\n```\\nos.environ[\\'WANDB_API_KEY\\'] = \"abc123...\"\\n```\\n  </TabItem>\\n</Tabs>\\n\\n\\nIf a user is using wandb for the first time without following any of the steps mentioned above, they will automatically be prompted to login when your script calls `wandb.init`\\n\\n### Starting A wandb Run\\n\\nA W&B Run is a unit of computation logged by W&B. Typically you associate a single W&B Run per training experiment.\\n\\nInitialize W&B and start a Run within your code with:\\n\\n```python\\nwandb.init()\\n```\\n\\nOptionally you can provide a name for their project, or let the user set it themselves with parameter such as `wandb_project` in your code along with the username or team name, such as `wandb_entity` , for the entity parameter:\\n\\n```python\\nwandb.init(project=wandb_project, entity=wandb_entity)\\n```\\n\\n#### Where To Place `wandb.init`?\\n\\nYour library should create W&B Run as early as possible because any output in your console, including error messages, are logged as part of the W&B Run.\\n-----------\\n'}, 'scores': {'get_answer_correctness': {'answer_correctness': False, 'feedback': \"The generated answer provides a method to switch between different W&B accounts by using different API keys stored in a JSON file. However, it does not address the specific issue of the user wanting to switch between a company's W&B instance and the public W&B cloud. The user needs to specify the host when logging in, which is not mentioned in the generated answer. The retrieved context does mention using different API keys and setting environment variables, but it also lacks the specific instruction to use the --host option.\"}}, 'model_latency': 27.109462022781372}, exception=None, summary={'usage': {'gpt-4-0613': {'requests': 1, 'completion_tokens': 240, 'prompt_tokens': 4016, 'total_tokens': 4256}, 'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 121, 'prompt_tokens': 5037, 'total_tokens': 5158}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/get_answer_correctness:coqEhYScawOF0zn7uvYjH4jkYJf6ssw4w685ILU3UZc', trace_id='84d8480b-3e96-4df3-a46f-172d4d2576a9', project_id='ayut/llamaindex-weave', parent_id='1033da0f-a282-4c04-8806-fb82fd7423d1', inputs={'question': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'mlET8KFu2uTZdIToTnQOqFymVxJMgB8mI4mmexZcWxQ', 'key', 'question']), 'answer': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'mlET8KFu2uTZdIToTnQOqFymVxJMgB8mI4mmexZcWxQ', 'key', 'answer']), 'model_output': {'response': \"It seems like you're encountering a `ServiceStartTimeoutError` with W&B, which indicates that the W&B service is not starting within the default timeout period. You've already tried increasing the timeout to 300 seconds and reinstalling W&B, but the issue persists. Here are a few additional steps you can take to troubleshoot and potentially resolve this issue:\\n\\n1. **Check Network Connectivity**: Ensure that your network connection is stable. Network issues can sometimes cause delays in starting the W&B service. If your network is flaky, consider running your training in offline mode and syncing the files later from a machine with a stable internet connection.\\n\\n2. **Update SSL Certificates**: If you're running the script on an Ubuntu server, try updating your SSL certificates by running `update-ca-certificates`. This can help resolve any SSL-related issues that might be causing the service to hang.\\n\\n3. **Local CAs Configuration**: If you're behind a corporate firewall, you might need to set up local CAs. You can do this by exporting the CA bundle:\\n   ```bash\\n   export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\\n   ```\\n\\n4. **Check for Rate Limits**: Ensure that you are not hitting any rate limits imposed by W&B. The W&B Python SDK automatically handles exponential backoff and retries, but excessive logging or API calls can still cause delays. Review your logging strategy and reduce the frequency of `wandb.log` calls if necessary.\\n\\n5. **Run in Offline Mode**: If the issue persists, try running your script in offline mode by setting the environment variable `WANDB_MODE=offline`. This will store metrics locally on your hard drive, and you can sync the data later using `wandb sync DIRECTORY`.\\n\\n6. **Increase Timeout Further**: Although you've already tried increasing the timeout to 300 seconds, you might want to try setting it even higher as a temporary measure to see if the service eventually starts.\\n\\n7. **Check System Resources**: Ensure that your system has enough resources (CPU, memory) to start the W&B service. Resource constraints can sometimes cause delays in service startup.\\n\\nIf none of these steps resolve the issue, consider reaching out to W&B support for further assistance. They may be able to provide more specific guidance based on your environment and usage patterns.\", 'context_str': 'Source ID: d6a17db4-0f19-497e-91d6-e7f7e84158e6\\n\\n### How do I kill a job with wandb?\\n\\nPress `Ctrl+D` on your keyboard to stop a script that is instrumented with wandb.\\n\\n### How do I deal with network issues?\\n\\nIf you\\'re seeing SSL or network errors:`wandb: Network error (ConnectionError), entering retry loop`. You can try a couple of different approaches to solving this issue:\\n\\n1. Upgrade your SSL certificate. If you\\'re running the script on an Ubuntu server, run `update-ca-certificates` We can\\'t sync training logs without a valid SSL certificate because it\\'s a security vulnerability.\\n2. If your network is flaky, run training in [offline mode](../track/launch.md) and sync the files to us from a machine that has Internet access.\\n3. Try running [W&B Private Hosting](../hosting/intro.md), which operates on your machine and doesn\\'t sync files to our cloud servers.\\n\\n`SSL CERTIFICATE_VERIFY_FAILED`: this error could be due to your company\\'s firewall. You can set up local CAs and then use:\\n\\n`export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt`\\n\\n### What happens if internet connection is lost while I\\'m training a model?\\n\\nIf our library is unable to connect to the internet it will enter a retry loop and keep attempting to stream metrics until the network is restored. During this time your program is able to continue running.\\n\\nIf you need to run on a machine without internet, you can set `WANDB_MODE=offline` to only have metrics stored locally on your hard drive. Later you can call `wandb sync DIRECTORY` to have the data streamed to our server.\\n-----------\\nSource ID: 5ae39c9b-9b4b-4dbc-873e-3dbcc3829e33\\n\\nCalling `wandb.log` more than a few times per second. This is due to a small latency added to the training loop every time `wandb.log` is called.\\n\\n:::info\\nIs frequent logging slowing your training runs down? Check out [this Colab](http://wandb.me/log-hf-colab) for methods to get better performance by changing your logging strategy.\\n:::\\n\\nW&B does not assert any limits beyond rate limiting. The W&B Python SDK automatically completes an exponential \"backoff\" and \"retry\" requests that exceed limits. W&B Python SDK responds with a “Network failure” on the command line. For unpaid accounts, W&B may reach out in extreme cases where usage exceeds reasonable thresholds.\\n\\n## Rate limits\\n\\nW&B SaaS Cloud API implements a rate limit to maintain system integrity and ensure availability. This measure prevents any single user from monopolizing available resources in the shared infrastructure, ensuring that the service remains accessible to all users. You may encounter a lower rate limit for a variety of reasons. \\n\\n:::note\\nRate limits are subject to change.\\n:::\\n\\nThe `wandb.log` calls in your script utilize a metrics logging API to log your training data to W&B. This API is engaged through either online or [offline syncing](../../ref/cli/wandb-sync.md). In either case, it imposes a rate limit quota limit in a rolling time window. This includes limits on total request size and request rate, where latter refers to the number of requests in a time duration. \\n\\nRate limits are applied to each W&B project. So if you have 3 projects in a team, each project has its own rate limit quota. Users on [Teams and Enterprise plans](https://wandb.ai/site/pricing) have higher rate limits than those on the Free plan.\\n-----------\\n'}}, id='cdc2d56e-313a-4568-9840-73cf86a53807', output={'answer_correctness': True, 'feedback': \"The generated answer addresses the user's issue by providing multiple troubleshooting steps, including checking network connectivity, updating SSL certificates, configuring local CAs, checking for rate limits, running in offline mode, increasing the timeout further, and checking system resources. These suggestions are relevant and align with the retrieved context. However, it does not mention ensuring the correct setting of the `_service_wait` parameter, which is a crucial step.\"}, exception=None, summary={'usage': {'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 103, 'prompt_tokens': 2074, 'total_tokens': 2177}}}, display_name=None, attributes={}, _children=[], _feedback=None)),\n",
       " TraceObject(Call(op_name='weave:///ayut/llamaindex-weave/op/get_answer_correctness:coqEhYScawOF0zn7uvYjH4jkYJf6ssw4w685ILU3UZc', trace_id='84d8480b-3e96-4df3-a46f-172d4d2576a9', project_id='ayut/llamaindex-weave', parent_id='9d1b0e14-a55b-4ce3-bebe-582a4915676d', inputs={'question': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'pty9a1MIYZi3zCuukLCCjJ5EXpWrfAkMwvbukQUXJj8', 'key', 'question']), 'answer': ObjectRef(entity='ayut', project='llamaindex-weave', name='eval_data_subset', digest='HJgMIvtD3UMFwDouX8BUp1KJgKfUTtUwJdXS3VjzpMI', extra=['attr', 'rows', 'id', 'pty9a1MIYZi3zCuukLCCjJ5EXpWrfAkMwvbukQUXJj8', 'key', 'answer']), 'model_output': {'response': 'If you want to submit a W&B (Weights & Biases) Report to a conference and need to anonymize the data, you can use the Anonymous Mode feature provided by W&B. This allows you to log and visualize data without requiring a W&B account, which can help in maintaining anonymity.\\n\\nTo enable Anonymous Mode, you can initialize your W&B run with the `anonymous=\"allow\"` parameter. Here’s how you can do it:\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n\\n### Key Points about Anonymous Mode:\\n\\n1. **Auto-create Temporary Account**: If someone runs your script and you have set `anonymous=\"allow\"`, W&B will automatically create a new anonymous account if no account is already signed in. This temporary account will be used to log the results.\\n\\n2. **Log Results Quickly**: Users can run and re-run the script, and see the results in the W&B dashboard UI. These anonymous runs will be available for 7 days.\\n\\n3. **Claim Data**: Users can claim the data by saving it to a real account if they find the results valuable. If not claimed, the data will be deleted after 7 days.\\n\\n4. **Sensitive Links**: Anonymous run links are sensitive and allow anyone to view and claim the results for 7 days. Share these links only with trusted individuals.\\n\\n5. **Existing Accounts**: If a user with an existing W&B account runs your script, their results will be logged to their account as usual, even if `anonymous=\"allow\"` is set.\\n\\n6. **Limitations**:\\n   - **No Persistent Data**: Data in anonymous accounts is only saved for 7 days.\\n   - **No Artifact Logging**: You cannot log artifacts in anonymous runs.\\n   - **No Profile or Settings Pages**: Certain UI pages are not available for anonymous users.\\n\\nIf you need to share results publicly while hiding the author\\'s identity, it is recommended to contact W&B support at support@wandb.com to discuss your specific use case.\\n\\nBy using Anonymous Mode, you can ensure that your data remains anonymized, making it suitable for submission to conferences or other public forums.', 'context_str': 'Source ID: 2c843dea-4f42-4ce4-a434-5fe9473b20a8\\n\\n---\\ndescription: Log and visualize data without a W&B account\\ndisplayed_sidebar: default\\n---\\n\\n# Anonymous Mode\\n\\nAre you publishing code that you want anyone to be able to run easily? Use Anonymous Mode to let someone run your code, see a W&B dashboard, and visualize results without needing to create a W&B account first.\\n\\nAllow results to be logged in Anonymous Mode with `wandb.init(`**`anonymous=\"allow\"`**`)`\\n\\n:::info\\n**Publishing a paper?** Please [cite W&B](https://docs.wandb.ai/company/academics#bibtex-citation), and if you have questions about how to make your code accessible while using W&B, reach out to us at support@wandb.com.\\n:::\\n\\n### How does someone without an account see results?\\n\\nIf someone runs your script and you have to set `anonymous=\"allow\"`:\\n\\n1. **Auto-create temporary account:** W&B checks for an account that\\'s already signed in. If there\\'s no account, we automatically create a new anonymous account and save that API key for the session.\\n2. **Log results quickly:** The user can run and re-run the script, and automatically see results show up in the W&B dashboard UI. These unclaimed anonymous runs will be available for 7 days.\\n3. **Claim data when it\\'s useful**: Once the user finds valuable results in W&B, they can easily click a button in the banner at the top of the page to save their run data to a real account. If they don\\'t claim a run, it will be deleted after 7 days.\\n\\n:::caution\\n**Anonymous run links are sensitive**. These links allow anyone to view and claim the results of an experiment for 7 days, so make sure to only share links with people you trust. If you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n-----------\\nSource ID: e514fe51-060e-4acd-a4b0-4436888dd1a4\\n\\nIf you\\'re trying to share results publicly, but hide the author\\'s identity, please contact us at support@wandb.com to share more about your use case.\\n:::\\n\\n### What happens to users with existing accounts?\\n\\nIf you set `anonymous=\"allow\"` in your script, we will check to make sure there\\'s not an existing account first, before creating an anonymous account. This means that if a W&B user finds your script and runs it, their results will be logged correctly to their account, just like a normal run.\\n\\n### What are features that aren\\'t available to anonymous users?\\n\\n*   **No persistent data**: Runs are only saved for 7 days in an anonymous account. Users can claim anonymous run data by saving it to a real account.\\n\\n\\n![](@site/static/images/app_ui/anon_mode_no_data.png)\\n\\n*   **No artifact logging**: Runs will print a warning on the command line that you can\\'t log an artifact to an anonymous run.\\n\\n![](@site/static/images/app_ui/anon_example_warning.png)\\n\\n* **No profile or settings pages**: Certain pages aren\\'t available in the UI, because they\\'re only useful for real accounts.\\n\\n## Example usage\\n\\n[Try the example notebook](http://bit.ly/anon-mode) to see how anonymous mode works.\\n\\n```python\\nimport wandb\\n\\n# Start a run allowing anonymous accounts\\nwandb.init(anonymous=\"allow\")\\n\\n# Log results from your training loop\\nwandb.log({\"acc\": 0.91})\\n\\n# Mark the run as finished\\nwandb.finish()\\n```\\n-----------\\n'}}, id='6b9129e4-3240-4039-ac13-5c79b6c03b49', output={'answer_correctness': False, 'feedback': 'The generated answer correctly explains the use of Anonymous Mode in W&B to help anonymize data, including how to set it up and its key points. However, it does not mention the need for manual anonymization of sensitive data or adjusting privacy settings, which are also important steps for ensuring data anonymity for conference submissions. The retrieved context supports the explanation of Anonymous Mode but does not cover all aspects of anonymizing data for conference submissions.'}, exception=None, summary={'usage': {'gpt-4o-2024-05-13': {'requests': 1, 'completion_tokens': 107, 'prompt_tokens': 1928, 'total_tokens': 2035}}}, display_name=None, attributes={}, _children=[], _feedback=None))]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_calls = []\n",
    "\n",
    "for call in calls:\n",
    "    if call.feedback.feedbacks:\n",
    "        for feedback in call.feedback.feedbacks:\n",
    "            if feedback.feedback_type==\"wandb.note.1\":\n",
    "                if feedback.payload[\"note\"] == \"few-shot\":\n",
    "                    few_shot_calls.append(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(few_shot_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\n",
    "\n",
    "for call in few_shot_calls:\n",
    "    question = call.inputs[\"example\"][\"question\"]\n",
    "    reference_answer = call.inputs[\"example\"][\"answer\"]\n",
    "    generated_answer = call.output[\"model_output\"][\"response\"]\n",
    "    score = 3 if not call.output[\"scores\"][\"get_answer_correctness\"][\"answer_correctness\"] else 1\n",
    "    feeback = call.output[\"scores\"][\"get_answer_correctness\"][\"feedback\"]\n",
    "\n",
    "    few_shot_prompt += f\"Question: \\n{question}\\n Reference Answer: \\n{reference_answer}\\n Generated Answer: \\n{generated_answer}\\n Score: \\n{score}\\n Feedback: \\n{feeback}\\n\"\n",
    "    few_shot_prompt = few_shot_prompt.replace(\"{\", \"\").replace(\"}\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: \\nI\\'m getting Internal Server Error for url: https://api.wandb.ai/graphql when trying to download an artifact with the following code \\n```\\nprocessed_data_at = run.use_artifact(f\\'params.PROCESSED_DATA_AT:latest\\')\\nprocessed_dataset_dir = Path(processed_data_at.download())\\n```\\n Reference Answer: \\nAn \"Internal Server Error\" typically indicates that there\\'s a problem on the server side of the application you\\'re trying to interact with—in this case, the W&B (Weights & Biases) API. Here are some steps you can take to troubleshoot and potentially resolve the issue:\\n\\n1. **Check W&B Status**: Before diving into debugging, check if W&B is experiencing any known issues by visiting their status page. If there\\'s a known outage or issue, it might be the cause of the error, and you\\'ll have to wait until it\\'s resolved.\\n\\n2. **Retry the Request**: Sometimes, intermittent server issues can cause this error. Try running your code again after a short wait to see if the issue resolves itself.\\n\\n3. **Review Your Code**: Double-check the artifact name and ensure that it\\'s correctly formatted and exists in your W&B project. The `params.PROCESSED_DATA_AT` variable should contain the correct artifact name.\\n\\n4. **API Limits**: If you\\'re making a lot of requests in a short period, you might be hitting rate limits. Review the W&B documentation to see if there are any rate limits that you might be exceeding.\\n\\n5. **Authentication**: Ensure that you\\'re properly authenticated with W&B. If your authentication token is missing or incorrect, it could lead to errors. You can re-authenticate using the `wandb login` command.\\n\\n6. **W&B Version**: Check if you\\'re using an outdated version of the W&B client library. If so, update to the latest version using `pip install --upgrade wandb`.\\n\\n7. **Error Logs**: Look for any additional error messages or logs that might provide more context about the error. Sometimes, the W&B client will output more detailed error information in the console.\\n\\n8. **Contact Support**: If none of the above steps work, reach out to W&B support with details of the error, including the full traceback and any relevant logs. They might be able to provide more specific guidance or information about the issue.\\n\\nHere\\'s an example of how you might handle exceptions and retry the download in your code:\\n\\n```python\\nfrom pathlib import Path\\nimport wandb\\nimport time\\n\\n# Initialize your W&B run\\nrun = wandb.init()\\n\\n# Attempt to download the artifact with retries\\nmax_retries = 3\\nfor attempt in range(max_retries):\\n    try:\\n        processed_data_at = run.use_artifact(f\\'params.PROCESSED_DATA_AT:latest\\')\\n        processed_dataset_dir = Path(processed_data_at.download())\\n        break  # If the download is successful, break out of the loop\\n    except Exception as e:\\n        print(f\"Attempt attempt+1 failed with error: e\")\\n        if attempt < max_retries - 1:\\n            time.sleep(2**attempt)  # Exponential backoff\\n        else:\\n            raise  # Re-raise the exception if all retries fail\\n\\n# Close the W&B run\\nrun.finish()\\n```\\n\\nRemember to replace `params.PROCESSED_DATA_AT` with the actual variable or string that contains your artifact name.\\n Generated Answer: \\nThe \"Internal Server Error\" you\\'re encountering might be due to several reasons. Here are a few things you can check:\\n\\n1. **Artifact Name**: Ensure that the artifact name you\\'re using in `run.use_artifact(f\\'params.PROCESSED_DATA_AT:latest\\')` is correct and exists in your W&B project.\\n\\n2. **Bucket Configuration**: If your artifact is stored in an external bucket (like AWS S3, GCP, or Azure), make sure that the CORS configuration of your bucket allows `app.wandb.ai`. Also, if your bucket has object versioning enabled, W&B will retrieve the object version corresponding to the state of the file at the time an artifact was logged.\\n\\n3. **Credentials**: W&B uses the default mechanism to look for credentials based on the cloud provider you use. Make sure your credentials are correctly set up.\\n\\n4. **Server Issues**: The error might be due to temporary server issues. You can try again after some time.\\n\\nIf the issue persists, it would be helpful to provide more details or contact W&B support for further assistance.\\n Score: \\n1\\n Feedback: \\nThe generated answer addresses several potential causes for the \\'Internal Server Error\\' and provides actionable steps to troubleshoot the issue. It mentions checking the artifact name, bucket configuration, credentials, and potential server issues, which are relevant to the user\\'s problem. However, it could be more comprehensive by including steps like checking W&B status, retrying the request, reviewing API limits, and ensuring proper authentication, which are also important troubleshooting steps.\\nQuestion: \\ni am trying to figure out the best way to organize/name/group my wandb runs when doing hyperparam tuning with cross-validation.\\n\\nideally, i\\'d like to be able to see the average score across all the runs that are part of a CV set. and then see the best CV score across the whole hyperparam sweep. (i am using optuna, not wandb, to manage the hyperparam sweep)\\n\\nis there a recommended approach for this?\\n Reference Answer: \\nWhen using W&B (Weights & Biases) in conjunction with Optuna for hyperparameter tuning with cross-validation, you can organize your runs effectively by leveraging W&B\\'s features such as projects, groups, tags, and notes. Here\\'s a recommended approach to achieve your goals:\\n\\n1. **Projects**: Use a dedicated project for your hyperparameter sweep. This will allow you to compare all runs within the same context.\\n   ```python\\n   wandb.init(project=\"your_hyperparam_sweep_project\")\\n   ```\\n\\n2. **Groups**: Group your runs by the hyperparameter configuration. Each group can represent one complete set of cross-validation folds for a particular hyperparameter set. This way, you can easily compare different configurations.\\n   ```python\\n   wandb.init(group=f\"config-config_id\")\\n   ```\\n   Here, `config_id` could be a unique identifier for each hyperparameter configuration generated by Optuna.\\n\\n3. **Tags**: Use tags to mark runs with specific characteristics, such as the fold number or whether it\\'s part of the best-performing CV set.\\n   ```python\\n   wandb.init(tags=[f\"fold-fold_number\", \"best_cv_score\"])\\n   ```\\n\\n4. **Notes**: Add notes to each run to describe any particularities or observations that might be relevant when reviewing the results.\\n\\n5. **Reports**: Create reports to summarize the findings of your hyperparameter sweep, including tables or graphs that show the average score across all CV sets and the best CV score.\\n\\n6. **Custom Metrics**: Since you want to see the average score across all runs in a CV set and the best CV score across the whole sweep, you can calculate these metrics manually and log them as custom metrics in W&B.\\n   ```python\\n   wandb.log(\"average_cv_score\": avg_score, \"best_cv_score\": best_score)\\n   ```\\n\\n7. **Result Aggregation**: To see the average score across all runs that are part of a CV set, you can use W&B\\'s grouping feature in the UI to aggregate results. For example, you can group by the hyperparameter configuration and then average the performance metric across the folds.\\n\\n8. **Analysis**: To find the best CV score across the entire hyperparameter sweep, you can use W&B\\'s query and filtering capabilities in the UI to sort the runs by performance and select the top-performing configurations.\\n\\nBy following these steps, you can effectively organize and analyze your runs in W&B while using Optuna for the hyperparameter sweep. This setup will help you track and compare the performance of different hyperparameter sets and cross-validation folds, leading to more informed decisions about model selection.\\n Generated Answer: \\nTo organize/name/group your W&B runs when doing hyperparameter tuning with cross-validation, you can use the following approach:\\n\\n1. **Define the Sweep:** Create a dictionary or a YAML file that specifies the parameters to search through, the search strategy, the optimization metric, etc. This is where you define the hyperparameters to sweep over and the type of sweep to use.\\n\\n2. **Initialize the Sweep:** Use the `wandb.sweep(sweep_config)` command to initialize the sweep.\\n\\n3. **Run the Sweep Agent:** Use the `wandb.agent(sweep_id, function=train)` command to run the sweep agent.\\n\\nFor each run, you can log the average score across all the runs that are part of a CV set using `wandb.log(\"average_score\": average_score)`. \\n\\nTo visualize the results, W&B provides automatic generation of useful plots like the Parallel Coordinates Plot and the Hyperparameter Importance Plot. The Parallel Coordinates Plot maps hyperparameter values to model metrics, which is useful for honing in on combinations of hyperparameters that led to the best model performance. The Hyperparameter Importance Plot shows which hyperparameter values had the biggest impact on your metrics.\\n\\nTo see the best CV score across the whole hyperparam sweep, you can use the W&B dashboard to sort your runs by the metric of interest and find the run with the best score. \\n\\nRemember, both the sweep and the run must be in the same project. Therefore, the name you provide when you initialize W&B must match the name of the project you provide when you initialize a sweep.\\n Score: \\n3\\n Feedback: \\nThe generated answer provides a general approach to organizing W&B runs during hyperparameter tuning with cross-validation. It mentions defining the sweep, initializing it, and running the sweep agent, which are relevant steps. However, it lacks specific details on using W&B features like projects, groups, tags, and notes to organize runs effectively. It also does not address how to group runs by hyperparameter configuration or how to manually calculate and log custom metrics for average and best CV scores.\\n'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 452.08it/s]\n",
      "2024/07/10 18:50:02 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720621202&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=t3VQZS1MVipMLiEWhN9Tq%2FrJ4caBwcVTfSvGlqjjz8cK%2FzWLD%2FJqmMgNXobHGXN3gSdX6H85GlS10gfNw2hp1pOfTfRxDip3aCbQpn1CU2HAScfFK6rVWElozrSjVowOXaZawvXr0VzNKn0hWm35TA%2FKKyduQP3%2FMaSS4aIAKQfh7hgO%2F4tdydX5rhhxHAD4zPI2ImkchrCBaV9fclMscR3v4jnypVgEao0cz6uRUZrURFcSsLrVrAFkzb5h%2Br4aIvwSlNiogEyW7tWu9x5wOD1zmfU1X88Ng7qOxIk0zdipzUvKW5EoaPgGL%2FDHxEUs3GRLhB%2BHNJXCs58j3W788A%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'get_answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compare_length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_code_block_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'code_block_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.85</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_bullet_points_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'bullet_points_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.592189240455628</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'get_answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m20\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compare_length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.05\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_code_block_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'code_block_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m17\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.85\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m19\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_bullet_points_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'bullet_points_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m20\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m14.592189240455628\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/52df3995-4bbe-4304-8483-8ca83e626e5d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_answer_correctness': {'answer_correctness': {'true_count': 20,\n",
       "   'true_fraction': 1.0}},\n",
       " 'compare_length_within_95_percentile': {'length_within_95_percentile': {'true_count': 1,\n",
       "   'true_fraction': 0.05}},\n",
       " 'check_code_block_presence': {'code_block_presense': {'true_count': 17,\n",
       "   'true_fraction': 0.85},\n",
       "  'has_code_block_gt': {'true_count': 16, 'true_fraction': 0.8},\n",
       "  'has_code_block_gen': {'true_count': 19, 'true_fraction': 0.95}},\n",
       " 'check_bullet_points_presence': {'bullet_points_presense': {'true_count': 18,\n",
       "   'true_fraction': 0.9},\n",
       "  'has_bullet_points_gt': {'true_count': 18, 'true_fraction': 0.9},\n",
       "  'has_bullet_points_gen': {'true_count': 20, 'true_fraction': 1.0}},\n",
       " 'model_latency': {'mean': 14.592189240455628}}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import evaluator\n",
    "\n",
    "await evaluator.evaluate(rag_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 380/380 [00:00<00:00, 461.64it/s]\n",
      "2024/07/10 19:01:22 [DEBUG] GET https://storage.googleapis.com/wandb-production.appspot.com/ayut/llamaindex-weave/ya1e93nn/artifact/946347886/wandb_manifest.json?Expires=1720621882&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=l27moAxnRYLiKMMfd95sMzLKGX67dz%2FEeh6u325HyJhYuWuycfeK%2F5nGS6CylNDuTfIcy3pJPbigeO61Ul9g5EAQ544PaPbi6WK69F6d3e5JRZENfYtx8r7N6YEFU4xlbEi4zsXhcti4bBUttTQH1qBPToapGjBcjf271eqWlZs4u9yr5tjwGnOQH1tVYjYI4uJn5f2DbUAAE%2FZJv4E01xItfpBWOzNqBzytk1XnkXcUnFayqGtkfm4sBAcBfjeFTY5SWSIzBnuI7%2BG%2BZF6N8rtFEIX%2F29du2KerePhlp9eQnvZWJSIXCDDieYOKdqNphfMg5YLzC5uDJ%2BKOCCRG9A%3D%3D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Chroma Index to: data/chroma_db\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = SimpleRAGPipeline()\n",
    "rag_pipeline.build_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m11\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m12\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m13\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m14\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m15\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m16\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m17\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m18\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m19\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'OpenAI' object has no attribute 'agenerate_text'\n",
      "{\n",
      "    \"reason\": \"The generated answer provides a clear and relevant approach to organizing W&B runs during hyperparameter tuning with cross-validation. It suggests using the `group` parameter in `wandb.init()` to group related runs, which directly addresses the user's need to organize runs by cross-validation folds or hyperparameter sets. Additionally, it mentions using the W&B dashboard to sort and analyze runs, and it includes an example of integrating Optuna with W&B, which is pertinent since the user is using Optuna for hyperparameter optimization. The answer is practical and actionable, covering the key aspects of the user's query.\",\n",
      "    \"score\": 3,\n",
      "    \"decision\": correct\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m20\u001b[0m of \u001b[1;36m20\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'get_answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'compare_length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'length_within_95_percentile'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_code_block_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'code_block_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_code_block_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'check_bullet_points_presence'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'bullet_points_presense'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gt'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'has_bullet_points_gen'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.090890181064605</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'get_answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m14\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.7\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'compare_length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'length_within_95_percentile'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_code_block_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'code_block_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.55\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_code_block_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.55\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'check_bullet_points_presence'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'bullet_points_presense'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.55\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gt'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m18\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'has_bullet_points_gen'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m9\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.45\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m17.090890181064605\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/ayut/llamaindex-weave/r/call/491be5e0-15a5-4aa8-9225-3836b4490e0f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'get_answer_correctness': {'answer_correctness': {'true_count': 14,\n",
       "   'true_fraction': 0.7}},\n",
       " 'compare_length_within_95_percentile': {'length_within_95_percentile': {'true_count': 0,\n",
       "   'true_fraction': 0.0}},\n",
       " 'check_code_block_presence': {'code_block_presense': {'true_count': 11,\n",
       "   'true_fraction': 0.55},\n",
       "  'has_code_block_gt': {'true_count': 16, 'true_fraction': 0.8},\n",
       "  'has_code_block_gen': {'true_count': 11, 'true_fraction': 0.55}},\n",
       " 'check_bullet_points_presence': {'bullet_points_presense': {'true_count': 11,\n",
       "   'true_fraction': 0.55},\n",
       "  'has_bullet_points_gt': {'true_count': 18, 'true_fraction': 0.9},\n",
       "  'has_bullet_points_gen': {'true_count': 9, 'true_fraction': 0.45}},\n",
       " 'model_latency': {'mean': 17.090890181064605}}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import evaluator\n",
    "\n",
    "await evaluator.evaluate(rag_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
